var documenterSearchIndex = {"docs":
[{"location":"manual/installation/#Manual:-Installation","page":"Installation","title":"Manual: Installation","text":"To install the ModelPredictiveControl package, run this command in the Julia REPL:\n\nusing Pkg; Pkg.activate(); Pkg.add(\"ModelPredictiveControl\")\n\nDoing so will install the package to default Julia environnement, that is, accessible anywhere. To facilitate sharing of code and reproducibility of results, it is recommended to install packages in a project environnement. To generate a new project named MPCproject with this package in the current working directory, write this in the REPL:\n\nusing Pkg; Pkg.generate(\"MPCproject\"); Pkg.activate(\".\"); Pkg.add(\"ModelPredictiveControl\")\n\nNote that the construction of linear models typically requires ss or tf functions, it is thus advised to load the package with:\n\nusing ModelPredictiveControl, ControlSystemsBase","category":"section"},{"location":"internals/predictive_control/#Functions:-PredictiveController-Internals","page":"Predictive Controllers","title":"Functions: PredictiveController Internals","text":"Pages = [\"predictive_control.md\"]\n\nThe prediction methodology of this module is mainly based on Maciejowski textbook [1].\n\n[1]: Maciejowski, J. 2000, \"Predictive control : with constraints\", 1st ed., Prentice Hall,  ISBN 978-0201398236.","category":"section"},{"location":"internals/predictive_control/#Controller-Construction","page":"Predictive Controllers","title":"Controller Construction","text":"","category":"section"},{"location":"internals/predictive_control/#Update-Quadratic-Optimization","page":"Predictive Controllers","title":"Update Quadratic Optimization","text":"","category":"section"},{"location":"internals/predictive_control/#Solve-Optimization-Problem","page":"Predictive Controllers","title":"Solve Optimization Problem","text":"","category":"section"},{"location":"internals/predictive_control/#ModelPredictiveControl.move_blocking","page":"Predictive Controllers","title":"ModelPredictiveControl.move_blocking","text":"move_blocking(Hp::Int, Hc::Vector{Int}) -> nb\n\nGet the move blocking vector nb from the Hc argument, and modify it to match Hp.\n\nThis feature is also known as manipulated variable blocking. The argument Hc is interpreted as the move blocking vector nb. It specifies the length of each step (or \"block\") in the mathbfΔU vector, to customize the pattern (in time steps, thus strictly positive integers):\n\n    mathbfn_b = beginbmatrix n_1  n_2  cdots  n_H_c endbmatrix\n\nThe vector that includes all the manipulated input increments mathbfΔu is then defined as:\n\nmathbfΔU = beginbmatrix\n    mathbfΔu(k + 0)                                  01em\n    mathbfΔu(k + _i=1^1 n_i)                      01em\n    mathbfΔu(k + _i=1^2 n_i)                      01em\n    vdots                                              01em\n    mathbfΔu(k + _i=1^H_c-1 n_i)   \nendbmatrix\n\nThe provided nb vector is modified to ensure sum(nb) == Hp:\n\nIf sum(nb) < Hp, a new element is pushed to nb with the value Hp - sum(nb).\nIf sum(nb) > Hp, the intervals are truncated until sum(nb) == Hp. For example, if Hp = 10 and nb = [1, 2, 3, 6, 7], then nb is truncated to [1, 2, 3, 4].\n\n\n\n\n\nmove_blocking(Hp::Int, Hc::Int) -> nb\n\nConstruct a move blocking vector nb that match the provided Hp and Hc integers.\n\nThe vector is filled with 1s, except for the last element which is Hp - Hc + 1.\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.init_ZtoΔU","page":"Predictive Controllers","title":"ModelPredictiveControl.init_ZtoΔU","text":"init_ZtoΔU(estim::StateEstimator, transcription::TranscriptionMethod, Hp, Hc) -> PΔu\n\nInit decision variables to input increments over H_c conversion matrix PΔu.\n\nThe conversion from the decision variables mathbfZ to mathbfΔU, the input increments over H_c, is computed by:\n\nmathbfΔU = mathbfP_Δu mathbfZ\n\nin which mathbfP_Δu is defined in the Extended Help section.\n\nExtended Help\n\ndetails: Extended Help\nFollowing the decision variable definition of the TranscriptionMethod, the conversion matrix mathbfP_Δu, we have:mathbfP_Δu = mathbfI if transcription is a SingleShooting\nmathbfP_Δu = beginsmallmatrixmathbfI  mathbf0 endsmallmatrix if transcription is a MultipleShootingThe matrix is store as as SparseMatrixCSC to support both cases efficiently.\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.init_ZtoU","page":"Predictive Controllers","title":"ModelPredictiveControl.init_ZtoU","text":"init_ZtoU(estim, transcription, Hp, Hc, nb) -> Pu, Tu\n\nInit decision variables to inputs over H_p conversion matrices.\n\nThe conversion from the decision variables mathbfZ to mathbfU, the manipulated inputs over H_p, is computed by:\n\nmathbfU = mathbfP_u mathbfZ + mathbfT_u mathbfu(k-1)\n\nThe mathbfP_u and mathbfT_u matrices are defined in the Extended Help section.\n\nExtended Help\n\ndetails: Extended Help\nWith n_i, the ith element of the mathbfn_b vector defined in move_blocking documentation, we introduce the mathbfQ(n_i) matrix of size (nu*ni, nu):mathbfQ(n_i) =       beginbmatrix\n    mathbfI          \n    mathbfI          \n    vdots              \n    mathbfI          endbmatrix            The mathbfU vector and the conversion matrices are defined as:mathbfU = beginbmatrix\n    mathbfu(k + 0)                                                                   \n    mathbfu(k + 1)                                                                   \n    vdots                                                                              \n    mathbfu(k + H_p - 1)                                                             endbmatrix  quad\nmathbfP_u^ = beginbmatrix\n    mathbfQ(n_1)          mathbf0             cdots     mathbf0            \n    mathbfQ(n_2)          mathbfQ(n_2)        cdots     mathbf0            \n    vdots                   vdots                 ddots     vdots                \n    mathbfQ(n_H_c)      mathbfQ(n_H_c)    cdots     mathbfQ(n_H_c)   endbmatrix  quad\nmathbfT_u = beginbmatrix\n    mathbfI                                                                          \n    mathbfI                                                                          \n    vdots                                                                              \n    mathbfI                                                                          endbmatrixand, depending on the transcription method, we have:mathbfP_u = mathbfP_u^ if transcription is a SingleShooting\nmathbfP_u = beginsmallmatrixmathbfP_u^  mathbf0 endsmallmatrix if transcription is a MultipleShootingThe conversion matrices are stored as SparseMatrixCSC since it was benchmarked that it is generally more performant than normal dense matrices, even for small nu, Hp and  Hc values. Using Bool element type and BitMatrix is also slower.\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.init_predmat","page":"Predictive Controllers","title":"ModelPredictiveControl.init_predmat","text":"init_predmat(\n    model::LinModel, estim, transcription::SingleShooting, Hp, Hc\n) -> E, G, J, K, V, ex̂, gx̂, jx̂, kx̂, vx̂\n\nConstruct the prediction matrices for LinModel and SingleShooting.\n\nThe model predictions are evaluated from the deviation vectors (see setop!), the decision variable mathbfZ (see TranscriptionMethod), and:\n\nbeginaligned\n    mathbfŶ_0 = mathbfE Z + mathbfG d_0(k) + mathbfJ D̂_0 \n                                 + mathbfK x̂_0(k) + mathbfV u_0(k-1) \n                                 + mathbfB        + mathbfŶ_s                      \n                 = mathbfE Z + mathbfF\nendaligned\n\nin which mathbfx̂_0(k) = mathbfx̂_i(k) - mathbfx̂_op, with i = k if  estim.direct==true, otherwise i = k - 1. The predicted outputs mathbfŶ_0 and measured disturbances mathbfD̂_0 respectively include mathbfŷ_0(k+j) and  mathbfd̂_0(k+j) values with j=1 to H_p, and input increments mathbfΔU, mathbfΔu(k+j) from j=0 to H_c-1. The vector mathbfB contains the contribution for non-zero state mathbfx̂_op and state update mathbff̂_op operating points (for linearization at non-equilibrium point, see linearize). The stochastic predictions mathbfŶ_s=0 if estim is not a InternalModel, see init_stochpred. The method also computes similar matrices for the predicted terminal state at k+H_p:\n\nbeginaligned\n    mathbfx̂_0(k+H_p) = mathbfe_x̂ Z  + mathbfg_x̂ d_0(k)   + mathbfj_x̂ D̂_0 \n                                           + mathbfk_x̂ x̂_0(k) + mathbfv_x̂ u_0(k-1)\n                                           + mathbfb_x̂                                 \n                        = mathbfe_x̂ Z  + mathbff_x̂\nendaligned\n\nThe matrices mathbfE G J K V B e_x̂ g_x̂ j_x̂ k_x̂ v_x̂ b_x̂ are defined in the Extended Help section. The mathbfF and mathbff_x̂ vectors are  recalculated at each control period k, see initpred! and linconstraint!.\n\nExtended Help\n\ndetails: Extended Help\nUsing the augmented matrices mathbfÂ B̂_u Ĉ B̂_d D̂_d in estim (see  augment_model), and the function mathbfW(j) = _i=0^j mathbfÂ^i, the prediction matrices are computed by :beginaligned\nmathbfE = beginbmatrix\n    mathbfĈ W(0)mathbfB̂_u      mathbf0                       cdots  mathbf0                                        \n    mathbfĈ W(1)mathbfB̂_u      mathbfĈ W(0)mathbfB̂_u      cdots  mathbf0                                        \n    vdots                           vdots                           ddots  vdots                                            \n    mathbfĈ W(H_p-1)mathbfB̂_u  mathbfĈ W(H_p-2)mathbfB̂_u  cdots  mathbfĈ W(H_p-H_c+1)mathbfB̂_u endbmatrix \nmathbfG = beginbmatrix\n    mathbfĈmathbfÂ^0 mathbfB̂_d      \n    mathbfĈmathbfÂ^1 mathbfB̂_d      \n    vdots                                    \n    mathbfĈmathbfÂ^H_p-1 mathbfB̂_d endbmatrix \nmathbfJ = beginbmatrix\n    mathbfD̂_d                               mathbf0                                 cdots  mathbf0    \n    mathbfĈmathbfÂ^0 mathbfB̂_d      mathbfD̂_d                               cdots  mathbf0    \n    vdots                                     vdots                                     ddots  vdots       \n    mathbfĈmathbfÂ^H_p-2 mathbfB̂_d  mathbfĈmathbfÂ^H_p-3 mathbfB̂_d  cdots  mathbfD̂_d endbmatrix \nmathbfK = beginbmatrix\n    mathbfĈmathbfÂ^1        \n    mathbfĈmathbfÂ^2        \n    vdots                          \n    mathbfĈmathbfÂ^H_p      endbmatrix \nmathbfV = beginbmatrix\n    mathbfĈ W(0)mathbfB̂_u     \n    mathbfĈ W(1)mathbfB̂_u     \n    vdots                          \n    mathbfĈ W(H_p-1)mathbfB̂_u endbmatrix \nmathbfB = beginbmatrix\n    mathbfĈ W(0)                 \n    mathbfĈ W(1)                 \n    vdots                          \n    mathbfĈ W(H_p-1)             endbmatrix   mathbfbig(f̂_op - x̂_opbig) \nendalignedFor the terminal constraints, the matrices are computed with:beginaligned\nmathbfe_x̂ = beginbmatrix \n                    mathbfW(H_p-1)mathbfB̂_u  \n                    mathbfW(H_p-2)mathbfB̂_u  \n                    cdots  \n                    mathbfW(H_p-H_c+1)mathbfB̂_u endbmatrix \nmathbfg_x̂ = mathbfÂ^H_p-1 mathbfB̂_d \nmathbfj_x̂ = beginbmatrix \n                    mathbfÂ^H_p-2 mathbfB̂_d  \n                    mathbfÂ^H_p-3 mathbfB̂_d  \n                    cdots  \n                    mathbf0 \n                endbmatrix \nmathbfk_x̂ = mathbfÂ^H_p \nmathbfv_x̂ = mathbfW(H_p-1)mathbfB̂_u \nmathbfb_x̂ = mathbfW(H_p-1)    mathbfbig(f̂_op - x̂_opbig)\nendaligned\n\n\n\n\n\ninit_predmat(\n    model::LinModel, estim, transcription::MultipleShooting, Hp, Hc\n) -> E, G, J, K, V, B, ex̂, gx̂, jx̂, kx̂, vx̂, bx̂\n\nConstruct the prediction matrices for LinModel and MultipleShooting.\n\nThey are defined in the Extended Help section.\n\nExtended Help\n\ndetails: Extended Help\nThey are all appropriately sized zero matrices mathbf0, except for:beginaligned\nmathbfE   = beginsmallmatrixmathbf0  mathbfE^ endsmallmatrix    \nmathbfE^ = textdiagmathbf(ĈĈĈ)                                     \nmathbfJ   = textdiagmathbf(D̂_dD̂_dD̂_d)                               \nmathbfe_x̂ = beginsmallmatrixmathbf0  mathbfIendsmallmatrix   \nendaligned\n\n\n\n\n\ninit_predmat(model::NonLinModel, estim, transcription::SingleShooting, Hp, Hc)\n\nReturn empty matrices for SingleShooting of NonLinModel\n\n\n\n\n\ninit_predmat(model::NonLinModel, estim, transcription::TranscriptionMethod, Hp, Hc)\n\nReturn the terminal state matrices for NonLinModel and other TranscriptionMethod.\n\nThe output prediction matrices are all empty matrices. The terminal state matrices are given in the Extended Help section.\n\nExtended Help\n\ndetails: Extended Help\nThe terminal state matrices all appropriately sized zero matrices mathbf0, except for mathbfe_x̂ = beginsmallmatrixmathbf0  mathbfIendsmallmatrix\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.init_defectmat","page":"Predictive Controllers","title":"ModelPredictiveControl.init_defectmat","text":"init_defectmat(model::LinModel, estim, transcription::MultipleShooting, Hp, Hc)\n\nInit the matrices for computing the defects over the predicted states. \n\nAn equation similar to the prediction matrices (see  init_predmat) computes the defects over the predicted states:\n\nbeginaligned\n    mathbfŜ = mathbfE_ŝ Z + mathbfG_ŝ d_0(k)  + mathbfJ_ŝ D̂_0 \n                                 + mathbfK_ŝ x̂_0(k)  + mathbfV_ŝ u_0(k-1) \n                                 + mathbfB_ŝ                                         \n               = mathbfE_ŝ Z + mathbfF_ŝ\nendaligned\n\nThey are forced to be mathbfŜ = 0 using the optimization equality constraints. The matrices mathbfE_ŝ G_ŝ J_ŝ K_ŝ V_ŝ B_ŝ are defined in the Extended Help section.\n\nExtended Help\n\ndetails: Extended Help\nThe matrices are computed by:beginaligned\nmathbfE_ŝ = beginbmatrix\n    mathbfB̂_u  mathbf0    cdots  mathbf0    -mathbfI   mathbf0  cdots   mathbf0    mathbf0      \n    mathbfB̂_u  mathbfB̂_u  cdots  mathbf0     mathbfÂ  -mathbfI  cdots   mathbf0    mathbf0      \n    vdots        vdots        ddots  vdots         vdots       vdots      ddots   vdots        vdots          \n    mathbfB̂_u  mathbfB̂_u  cdots  mathbfB̂_u   mathbf0   mathbf0  cdots   mathbfÂ   -mathbfI      endbmatrix \nmathbfG_ŝ = beginbmatrix\n    mathbfB̂_d  mathbf0  vdots  mathbf0                                                          endbmatrix \nmathbfJ_ŝ = beginbmatrix\n    mathbf0    mathbf0    cdots  mathbf0    mathbf0                                            \n    mathbfB̂_d  mathbf0    cdots  mathbf0    mathbf0                                            \n    vdots        vdots        ddots  vdots        vdots                                                \n    mathbf0    mathbf0    cdots  mathbfB̂_d  mathbf0                                            endbmatrix \nmathbfK_ŝ = beginbmatrix\n    mathbfÂ  mathbf0  vdots  mathbf0                                                            endbmatrix \nmathbfV_ŝ = beginbmatrix\n    mathbfB̂_u  mathbfB̂_u  vdots  mathbfB̂_u                                                      endbmatrix \nmathbfB_ŝ = beginbmatrix\n    mathbff̂_op - x̂_op  mathbff̂_op - x̂_op  vdots  mathbff̂_op - x̂_op                  endbmatrix\nendaligned\n\n\n\n\n\ninit_defectmat(model::SimModel, estim, transcription::TranscriptionMethod, Hp, Hc)\n\nReturn empty matrices for all other cases (N/A).\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.relaxU","page":"Predictive Controllers","title":"ModelPredictiveControl.relaxU","text":"relaxU(Pu, C_umin, C_umax, nϵ) -> A_Umin, A_Umax, P̃u\n\nAugment manipulated inputs constraints with slack variable ϵ for softening.\n\nDenoting the decision variables augmented with the slack variable mathbfZ̃ = beginsmallmatrix mathbfZ  ϵ endsmallmatrix, it returns the augmented conversion matrix mathbfP̃_u, similar to the one described at init_ZtoU. It also returns the mathbfA matrices for the inequality constraints:\n\nbeginbmatrix \n    mathbfA_U_min  \n    mathbfA_U_max \nendbmatrix mathbfZ̃ \nbeginbmatrix\n    - mathbfU_min + T_u u(k-1) \n    + mathbfU_max - T_u u(k-1)\nendbmatrix\n\nin which mathbfU_min and mathbfU_max vectors respectively contains mathbfu_min and mathbfu_max repeated H_p times.\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.relaxΔU","page":"Predictive Controllers","title":"ModelPredictiveControl.relaxΔU","text":"relaxΔU(PΔu, C_Δumin, C_Δumax, ΔUmin, ΔUmax, nϵ) -> A_ΔŨmin, A_ΔŨmax, ΔŨmin, ΔŨmax, P̃Δu\n\nAugment input increments constraints with slack variable ϵ for softening.\n\nDenoting the decision variables augmented with the slack variable  mathbfZ̃ = beginsmallmatrix mathbfZ  ϵ endsmallmatrix, it returns the augmented conversion matrix mathbfP̃_Δu, similar to the one described at init_ZtoΔU, but extracting the input increments augmented with the slack variable mathbfΔŨ = beginsmallmatrix mathbfΔU  ϵ endsmallmatrix = mathbfP̃_Δu Z̃. Also, knowing that 0  ϵ  , it also returns the augmented bounds  mathbfΔŨ_min = beginsmallmatrix mathbfΔU_min  0 endsmallmatrix and mathbfΔŨ_max = beginsmallmatrix mathbfΔU_min   endsmallmatrix, and the mathbfA matrices for the inequality constraints:\n\nbeginbmatrix \n    mathbfA_ΔŨ_min  \n    mathbfA_ΔŨ_max\nendbmatrix mathbfZ̃ \nbeginbmatrix\n    - mathbfΔŨ_min \n    + mathbfΔŨ_max\nendbmatrix\n\nNote that strictly speaking, the lower bound on the slack variable ϵ is a decision variable bound, which is more precise than a linear inequality constraint. However, it is more convenient to treat it as a linear inequality constraint since the optimizer OSQP.jl does not support pure bounds on the decision variables.\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.relaxŶ","page":"Predictive Controllers","title":"ModelPredictiveControl.relaxŶ","text":"relaxŶ(E, C_ymin, C_ymax, nϵ) -> A_Ymin, A_Ymax, Ẽ\n\nAugment linear output prediction constraints with slack variable ϵ for softening.\n\nDenoting the decision variables augmented with the slack variable  mathbfZ̃ = beginsmallmatrix mathbfZ  ϵ endsmallmatrix, it returns the  mathbfẼ matrix that appears in the linear model prediction equation  mathbfŶ_0 = Ẽ Z̃ + F, and the mathbfA matrices for the inequality constraints:\n\nbeginbmatrix \n    mathbfA_Y_min  \n    mathbfA_Y_max\nendbmatrix mathbfZ̃ \nbeginbmatrix\n    - mathbf(Y_min - Y_op) + F \n    + mathbf(Y_max - Y_op) - F \nendbmatrix\n\nin which mathbfY_min Y_max and mathbfY_op vectors respectively contains mathbfy_min y_max and mathbfy_op repeated H_p times.\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.relaxterminal","page":"Predictive Controllers","title":"ModelPredictiveControl.relaxterminal","text":"relaxterminal(ex̂, c_x̂min, c_x̂max, nϵ) -> A_x̂min, A_x̂max, ẽx̂\n\nAugment terminal state constraints with slack variable ϵ for softening.\n\nDenoting the decision variables augmented with the slack variable  mathbfZ̃ = beginsmallmatrix mathbfZ  ϵ endsmallmatrix, it returns the  mathbfẽ_x̂ matrix that appears in the terminal state equation  mathbfx̂_0(k + H_p) = mathbfẽ_x̂ Z̃ + f_x̂, and the mathbfA matrices for  the inequality constraints:\n\nbeginbmatrix \n    mathbfA_x̂_min  \n    mathbfA_x̂_max\nendbmatrix mathbfZ̃ \nbeginbmatrix\n    - mathbf(x̂_min - x̂_op) + f_x̂ \n    + mathbf(x̂_max - x̂_op) - f_x̂\nendbmatrix\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.init_quadprog","page":"Predictive Controllers","title":"ModelPredictiveControl.init_quadprog","text":"init_quadprog(\n    model::LinModel, transcriptions::TranscriptionMethod, weights::ControllerWeights, \n    Ẽ, P̃Δu, P̃u; warn_cond=1e6\n) -> H̃\n\nInit the quadratic programming Hessian H̃ for MPC.\n\nThe matrix appear in the quadratic general form:\n\n    J = min_mathbfZ̃ frac12mathbfZ̃ H̃ Z̃ + mathbfq̃ Z̃ + r \n\nThe Hessian matrix is constant if the model and weights are linear and time invariant (LTI): \n\n    mathbfH̃ = 2 (   mathbfẼ      mathbfM_H_p mathbfẼ \n                     + mathbfP̃_Δu mathbfÑ_H_c mathbfP̃_Δu \n                     + mathbfP̃_u  mathbfL_H_p mathbfP̃_u     )\n\nin which mathbfẼ, mathbfP̃_Δu and mathbfP̃_u matrices are defined at relaxŶ, relaxΔU and relaxU documentation, respectively. The vector mathbfq̃ and scalar r need recalculation each control period k, see initpred!. r does not impact the minima position. It is thus useless at optimization but required to evaluate the minimal J value. A @warn will be displayed if the condition number cond(H̃) > warn_cond and transcription is a SingleShooting  (warn_cond=Inf for no warning).\n\n\n\n\n\nReturn empty matrix if model is not a LinModel.\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.init_stochpred","page":"Predictive Controllers","title":"ModelPredictiveControl.init_stochpred","text":"init_stochpred(estim::InternalModel, Hp) -> Ks, Ps\n\nInit the stochastic prediction matrices for InternalModel.\n\nKs and Ps matrices are defined as:\n\n    mathbfŶ_s = mathbfK_s x̂_s(k) + mathbfP_s ŷ_s(k)\n\nCurrent stochastic outputs mathbfŷ_s(k) comprises the measured outputs  mathbfŷ_s^m(k) = mathbfy^m(k) - mathbfŷ_d^m(k) and unmeasured  mathbfŷ_s^u(k) = mathbf0. See [2].\n\n[2]: Desbiens, A., D. Hodouin & É. Plamondon. 2000, \"Global predictive control: a unified control structure for decoupling setpoint tracking, feedforward compensation and  disturbance rejection dynamics\", IEE Proceedings - Control Theory and Applications,  vol. 147, no 4, https://doi.org/10.1049/ip-cta:20000443, p. 465–475, ISSN 1350-2379.\n\n\n\n\n\nReturn empty matrices if estim is not a InternalModel.\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.init_matconstraint_mpc","page":"Predictive Controllers","title":"ModelPredictiveControl.init_matconstraint_mpc","text":"init_matconstraint_mpc(\n    model::LinModel, transcription::TranscriptionMethod, nc::Int,\n    i_Umin, i_Umax, i_ΔŨmin, i_ΔŨmax, i_Ymin, i_Ymax, i_x̂min, i_x̂max, \n    args...\n) -> i_b, i_g, A, Aeq, neq\n\nInit i_b, i_g, neq, and A and Aeq matrices for the all the MPC constraints.\n\nThe linear and nonlinear constraints are respectively defined as:\n\nbeginaligned \n    mathbfA Z̃         mathbfb            \n    mathbfA_eq Z̃   = mathbfb_eq      \n    mathbfg(Z̃)        mathbf0           \n    mathbfg_eq(Z̃)  = mathbf0           \nendaligned\n\nThe argument nc is the number of custom nonlinear inequality constraints in mathbfg_c. i_b is a BitVector including the indices of mathbfb that are finite numbers. i_g is a similar vector but for the indices of mathbfg. The method also returns the mathbfA A_eq matrices and neq if args is provided. In such a  case, args  needs to contain all the inequality and equality constraint matrices:  A_Umin, A_Umax, A_ΔŨmin, A_ΔŨmax, A_Ymin, A_Ymax, A_x̂min, A_x̂max, A_ŝ. The integer neq is the number of nonlinear equality constraints in mathbfg_eq.\n\n\n\n\n\nInit i_b without output & terminal constraints if NonLinModel and SingleShooting.\n\n\n\n\n\nInit i_b without output constraints if NonLinModel and other TranscriptionMethod.\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.get_nonlinobj_op-Tuple{NonLinMPC, JuMP.GenericModel}","page":"Predictive Controllers","title":"ModelPredictiveControl.get_nonlinobj_op","text":"get_nonlinobj_op(mpc::NonLinMPC, optim::JuMP.GenericModel{JNT}) -> J_op\n\nReturn the nonlinear operator for the objective of mpc NonLinMPC.\n\nIt is based on the splatting syntax. This method is really intricate and that's because of:\n\nThese functions are used inside the nonlinear optimization, so they must be type-stable and as efficient as possible. All the function outputs and derivatives are cached and updated in-place if required to use the efficient value_and_gradient!.\nThe splatting syntax for objective functions implies the use of Vararg{T,N} (see the performance tip) and memoization to avoid redundant computations. This is already complex, but it's even worse knowing that the automatic differentiation tools do not support splatting.\nThe signature of gradient and hessian functions is not the same for univariate (nZ̃ == 1) and multivariate (nZ̃ > 1) operators in JuMP. Both must be defined.\n\n\n\n\n\n","category":"method"},{"location":"internals/predictive_control/#ModelPredictiveControl.get_nonlincon_oracle-Tuple{NonLinMPC, JuMP.GenericModel}","page":"Predictive Controllers","title":"ModelPredictiveControl.get_nonlincon_oracle","text":"get_nonlincon_oracle(mpc::NonLinMPC, optim) -> g_oracle, geq_oracle\n\nReturn the nonlinear constraint oracles for NonLinMPC mpc.\n\nReturn g_oracle and geq_oracle, the inequality and equality VectorNonlinearOracle for the two respective constraints. Note that g_oracle only includes the non-Inf inequality constraints, thus it must be re-constructed if they change. This method is really intricate because the oracles are used inside the nonlinear optimization, so they must be type-stable and as efficient as possible. All the function outputs and derivatives are  ached and updated in-place if required to use the efficient value_and_jacobian!.\n\n\n\n\n\n","category":"method"},{"location":"internals/predictive_control/#ModelPredictiveControl.initpred!-Tuple{PredictiveController, LinModel, Vararg{Any, 5}}","page":"Predictive Controllers","title":"ModelPredictiveControl.initpred!","text":"initpred!(mpc::PredictiveController, model::LinModel, d, lastu, D̂, R̂y, R̂u) -> nothing\n\nInit linear model prediction matrices F, q̃, r and current estimated output ŷ.\n\nSee init_predmat and init_quadprog for the definition of the matrices. They are computed with these equations using in-place operations:\n\nbeginaligned\n    mathbfF       = mathbfG d_0(k) + mathbfJ D̂_0 + mathbfK x̂_0(k) \n                            + mathbfV u_0(k-1) + mathbfB + mathbfŶ_s           \n    mathbfC_y     = mathbfF + mathbfY_op - mathbfR̂_y                     \n    mathbfC_u     = mathbfT_umathbfu(k-1)  - mathbfR̂_u                     \n    mathbfq̃       = 2    (mathbfM_H_p mathbfẼ)   mathbfC_y \n                            + (mathbfL_H_p mathbfP̃_U) mathbfC_u            \n    r                =     mathbfC_y  mathbfM_H_p mathbfC_y \n                          + mathbfC_u  mathbfL_H_p mathbfC_u\nendaligned\n\n\n\n\n\n","category":"method"},{"location":"internals/predictive_control/#ModelPredictiveControl.linconstraint!-Tuple{PredictiveController, LinModel, TranscriptionMethod}","page":"Predictive Controllers","title":"ModelPredictiveControl.linconstraint!","text":"linconstraint!(mpc::PredictiveController, model::LinModel)\n\nSet b vector for the linear model inequality constraints (mathbfA Z̃  b).\n\nAlso init mathbff_x̂ = mathbfg_x̂ d_0(k) + mathbfj_x̂ D̂_0 + mathbfk_x̂ x̂_0(k) +  mathbfv_x̂ u_0(k-1) + mathbfb_x̂ vector for the terminal constraints, see init_predmat.\n\n\n\n\n\n","category":"method"},{"location":"internals/predictive_control/#ModelPredictiveControl.linconstrainteq!","page":"Predictive Controllers","title":"ModelPredictiveControl.linconstrainteq!","text":"linconstrainteq!(\n    mpc::PredictiveController, model::LinModel, transcription::MultipleShooting\n)\n\nSet beq vector for the linear model equality constraints (mathbfA_eq Z̃ = b_eq).\n\nAlso init mathbfF_ŝ = mathbfG_ŝ d_0(k) + mathbfJ_ŝ D̂_0 + mathbfK_ŝ x̂_0(k) +  mathbfV_ŝ u_0(k-1) + mathbfB_ŝ, see init_defectmat.\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.optim_objective!-Tuple{PredictiveController}","page":"Predictive Controllers","title":"ModelPredictiveControl.optim_objective!","text":"optim_objective!(mpc::PredictiveController) -> Z̃\n\nOptimize the objective function of mpc PredictiveController and return the solution Z̃.\n\nIf first warm-starts the solver with set_warmstart!. It then calls  JuMP.optimize!(mpc.optim) and extract the solution. A failed optimization prints an  @error log in the REPL and returns the warm-start value. A failed optimization also prints getinfo results in the debug log if activated.\n\n\n\n\n\n","category":"method"},{"location":"internals/predictive_control/#ModelPredictiveControl.set_warmstart!","page":"Predictive Controllers","title":"ModelPredictiveControl.set_warmstart!","text":"set_warmstart!(mpc::PredictiveController, ::SingleShooting, Z̃var) -> Z̃s\n\nSet and return the warm-start value of Z̃var for SingleShooting transcription.\n\nIf supported by mpc.optim, it warm-starts the solver at:\n\nmathbfZ̃_s = \nbeginbmatrix\n    mathbfΔu(k+0k-1)         \n    mathbfΔu(k+1k-1)         \n    vdots                      \n    mathbfΔu(k+H_c-2k-1)    \n    mathbf0                  \n    ϵ(k-1)\nendbmatrix\n\nwhere mathbfΔu(k+jk-1) is the input increment for time k+j computed at the  last control period k-1, and ϵ(k-1), the slack variable of the last control period.\n\n\n\n\n\nset_warmstart!(mpc::PredictiveController, ::TranscriptionMethod, Z̃var) -> Z̃s\n\nSet and return the warm-start value of Z̃var for other TranscriptionMethod.\n\nIt warm-starts the solver at:\n\nmathbfZ̃_s =\nbeginbmatrix\n    mathbfΔu(k+0k-1)         \n    mathbfΔu(k+1k-1)         \n    vdots                      \n    mathbfΔu(k+H_c-2k-1)    \n    mathbf0                  \n    mathbfx̂_0(k+1k-1)       \n    mathbfx̂_0(k+2k-1)       \n    vdots                      \n    mathbfx̂_0(k+H_p-1k-1)   \n    mathbfx̂_0(k+H_p-1k-1)   \n    ϵ(k-1)\nendbmatrix\n\nwhere mathbfx̂_0(k+jk-1) is the predicted state for time k+j computed at the last control period k-1, expressed as a deviation from the operating point  mathbfx̂_op.\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.predict!","page":"Predictive Controllers","title":"ModelPredictiveControl.predict!","text":"predict!(\n    Ŷ0, x̂0end, _ , _ , _ ,\n    mpc::PredictiveController, model::LinModel, transcription::TranscriptionMethod, \n    _ , Z̃\n) -> Ŷ0, x̂0end\n\nCompute the predictions Ŷ0, terminal states x̂0end if model is a LinModel.\n\nThe method mutates Ŷ0 and x̂0end vector arguments. The x̂end vector is used for the terminal constraints applied on mathbfx̂_0(k+H_p). The computations are identical for any TranscriptionMethod if the model is linear:\n\nbeginaligned\nmathbfŶ_0        = mathbfẼ Z̃   + mathbfF \nmathbfx̂_0(k+H_p) = mathbfẽ_x̂ Z̃ + mathbff_x̂\nendaligned\n\n\n\n\n\npredict!(\n    Ŷ0, x̂0end, X̂0, Û0, K0,\n    mpc::PredictiveController, model::NonLinModel, transcription::SingleShooting,\n    U0, _\n) -> Ŷ0, x̂0end\n\nCompute vectors if model is a NonLinModel and for SingleShooting.\n\nThe method mutates Ŷ0, x̂0end, X̂0, Û0 and K0 arguments. The augmented model of f̂! and ĥ! functions is called recursively in a for loop:\n\nbeginaligned\nmathbfx̂_0(k+1) = mathbff̂Big(mathbfx̂_0(k) mathbfu_0(k) mathbfd̂_0(k) Big) \nmathbfŷ_0(k)   = mathbfĥBig(mathbfx̂_0(k) mathbfd̂_0(k) Big)\nendaligned\n\n\n\n\n\npredict!(\n    Ŷ0, x̂0end, _ , _ , _ , \n    mpc::PredictiveController, model::NonLinModel, transcription::TranscriptionMethod,\n    _ , Z̃\n) -> Ŷ0, x̂0end\n\nCompute vectors if model is a NonLinModel and other TranscriptionMethod.\n\nThe method mutates Ŷ0 and x̂0end arguments. The augmented output function ĥ!  is called multiple times in a for loop:\n\nmathbfŷ_0(k) = mathbfĥBig(mathbfx̂_0(k) mathbfd̂_0(k) Big)\n\nin which mathbfx̂_0 is the augmented state extracted from the decision variable Z̃.\n\n\n\n\n\nCompute the predictions but not the terminal states if mpc is an ExplicitMPC.\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.con_nonlinprog!","page":"Predictive Controllers","title":"ModelPredictiveControl.con_nonlinprog!","text":"con_nonlinprog!(\n    g, mpc::PredictiveController, model::LinModel, ::TranscriptionMethod, _ , _ , gc, ϵ\n) -> g\n\nNonlinear constrains when model is a LinModel.\n\nThe method mutates the g vectors in argument and returns it. Only the custom constraints gc are include in the g vector.\n\n\n\n\n\ncon_nonlinprog!(\n    g, mpc::PredictiveController, model::NonLinModel, ::TranscriptionMethod, x̂0end, Ŷ0, gc, ϵ\n) -> g\n\nNonlinear constrains when model is a NonLinModel with non-SingleShooting.\n\nThe method mutates the g vectors in argument and returns it. The output prediction and the custom constraints are include in the g vector.\n\n\n\n\n\ncon_nonlinprog!(\n    g, mpc::PredictiveController, model::NonLinModel, ::SingleShooting, x̂0end, Ŷ0, gc, ϵ\n) -> g\n\nNonlinear constrains when model is NonLinModel with SingleShooting.\n\nThe method mutates the g vectors in argument and returns it. The output prediction,  the terminal state and the custom constraints are include in the g vector.\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.con_nonlinprogeq!","page":"Predictive Controllers","title":"ModelPredictiveControl.con_nonlinprogeq!","text":"con_nonlinprogeq!(\n    geq, X̂0, Û0, K0\n    mpc::PredictiveController, model::NonLinModel, transcription::MultipleShooting, \n    U0, Z̃\n)\n\nNonlinear equality constrains for NonLinModel and MultipleShooting.\n\nThe method mutates the geq, X̂0, Û0 and K0 vectors in argument. The nonlinear  equality constraints geq only includes the augmented state defects, computed with:\n\nmathbfŝ(k+1) = mathbff̂Big(mathbfx̂_0(k) mathbfu_0(k) mathbfd̂_0(k)Big) \n                    - mathbfx̂_0(k+1)\n\nin which the augmented state mathbfx̂_0 are extracted from the decision variables  Z̃, and mathbff̂ is the augmented state function defined in f̂!.\n\n\n\n\n\ncon_nonlinprogeq!(\n    geq, X̂0, Û0, K0\n    mpc::PredictiveController, model::NonLinModel, transcription::TrapezoidalCollocation, \n    U0, Z̃\n)\n\nNonlinear equality constrains for NonLinModel and TrapezoidalCollocation.\n\nThe method mutates the geq, X̂0, Û0 and K0 vectors in argument. \n\nThe nonlinear equality constraints geq only includes the state defects. The deterministic and stochastic states are handled separately since collocation methods require continuous- time state-space models, and the stochastic model of the unmeasured disturbances is discrete-time. The deterministic and stochastic defects are respectively computed with:\n\nbeginaligned\nmathbfs_d(k+1) = mathbfx_0(k) - mathbfx_0(k+1) \n                      + 05 T_s (mathbfk_1 + mathbfk_2) \nmathbfs_s(k+1) = mathbfA_s x_s(k) - mathbfx_s(k+1)\nendaligned\n\nin which mathbfx_0 and mathbfx_s are the deterministic and stochastic states  extracted from the decision variables Z̃. The mathbfk coefficients are  evaluated from the continuous-time function model.f! and:\n\nbeginaligned\nmathbfk_1 = mathbffBig(mathbfx_0(k)   mathbfû_0(k)   mathbfd̂_0(k)  Big) \nmathbfk_2 = mathbffBig(mathbfx_0(k+1) mathbfû_0(k+h) mathbfd̂_0(k+1)Big) \nendaligned\n\nin which h is the hold order transcription.h and the disturbed input is:\n\nmathbfû_0(k) = mathbfu_0(k) + mathbfC_s_u x_s(k)\n\nthe mathbfA_s C_s_u matrices are defined in init_estimstoch doc.\n\n\n\n\n\nNo eq. constraints for other cases e.g. SingleShooting, returns geq unchanged.\n\n\n\n\n\n","category":"function"},{"location":"internals/predictive_control/#ModelPredictiveControl.getinput!","page":"Predictive Controllers","title":"ModelPredictiveControl.getinput!","text":"getinput!(mpc::PredictiveController, Z̃) -> u\n\nGet current manipulated input u from the solution Z̃, store it and return it.\n\nThe first manipulated input mathbfu(k) is extracted from the decision vector mathbfZ̃ and applied on the plant (from the receding horizon principle). It also stores u - mpc.estim.model.uop at mpc.lastu0.\n\n\n\n\n\n","category":"function"},{"location":"manual/mtk/#man_mtk","page":"ModelingToolkit","title":"Manual: ModelingToolkit Integration","text":"Pages = [\"mtk.md\"]","category":"section"},{"location":"manual/mtk/#Pendulum-Model","page":"ModelingToolkit","title":"Pendulum Model","text":"This example integrates the simple pendulum model of the last section in ModelingToolkit (MTK) framework and extracts appropriate f! and h! functions to construct a NonLinModel. An NonLinMPC is designed from this model and simulated to reproduce the results of the last section.\n\ndanger: Disclaimer\nThis simple example is not an official interface to ModelingToolkit.jl. It is provided as a basic starting template to combine both packages. There is no guarantee that it will work for all corner cases.\n\nWe first construct and instantiate the pendulum model:\n\nusing ModelPredictiveControl, ModelingToolkit\nusing ModelingToolkit: D_nounits as D, t_nounits as t, varmap_to_vars\n@mtkmodel Pendulum begin\n    @parameters begin\n        g = 9.8\n        L = 0.4\n        K = 1.2\n        m = 0.3\n    end\n    @variables begin\n        θ(t) # state\n        ω(t) # state\n        τ(t) # input\n        y(t) # output\n    end\n    @equations begin\n        D(θ)    ~ ω\n        D(ω)    ~ -g/L*sin(θ) - K/m*ω + τ/m/L^2\n        y       ~ θ * 180 / π\n    end\nend\n@named mtk_model = Pendulum()\nmtk_model = complete(mtk_model)\n\nWe than convert the MTK model to an input-output system:\n\nfunction generate_f_h(model, inputs, outputs)\n    (_, f_ip), x_sym, p_sym, io_sys = ModelingToolkit.generate_control_function(\n        model, inputs, split=false; outputs\n    )\n    if any(ModelingToolkit.is_alg_equation, equations(io_sys)) \n        error(\"Systems with algebraic equations are not supported\")\n    end\n    nu, nx, ny = length(inputs), length(x_sym), length(outputs)\n    function f!(ẋ, x, u, _ , p)\n        try\n            f_ip(ẋ, x, u, p, nothing)\n        catch err\n            if err isa MethodError\n                error(\"NonLinModel does not support a time argument t in the f function, \"*\n                      \"see the constructor docstring for a workaround.\")\n            else\n                rethrow()\n            end\n        end\n        return nothing\n    end\n    (_, h_ip) = ModelingToolkit.build_explicit_observed_function(\n        io_sys, outputs; inputs, return_inplace = true\n    )\n    u_nothing = fill(nothing, nu)\n    function h!(y, x, _ , p)\n        try\n            # MTK.jl supports a `u` argument in `h_ip` function but not this package. We set\n            # `u` as a vector of nothing and `h_ip` function will presumably throw an\n            # MethodError it this argument is used inside the function\n            h_ip(y, x, u_nothing, p, nothing)\n        catch err\n            if err isa MethodError\n                error(\"NonLinModel only support strictly proper systems (no manipulated \"*\n                      \"input argument u in the output function h)\")\n            else\n                rethrow()\n            end\n        end\n        return nothing\n    end\n    p = varmap_to_vars(defaults(io_sys), p_sym)\n    return f!, h!, p, x_sym, nu, nx, ny\nend\ninputs, outputs = [mtk_model.τ], [mtk_model.y]\nf!, h!, p, x_sym, nu, nx, ny = generate_f_h(mtk_model, inputs, outputs)\nx_sym\n\nSince MTK is an acausal modeling framework, we do not have the control on the state realization chosen by the package. The content of x_sym above shows it settled for the state vector mathbfx(t) = beginsmallmatrixω(t)  θ(t)endsmallmatrix, that is, the states of the last section in the reverse order. We can now construct a NonLinModel with this specific state realization:\n\nvu, vx, vy = [\"\\$τ\\$ (Nm)\"], [\"\\$ω\\$ (rad/s)\", \"\\$θ\\$ (rad)\"], [\"\\$θ\\$ (°)\"]\nTs = 0.1\nmodel = setname!(NonLinModel(f!, h!, Ts, nu, nx, ny; p); u=vu, x=vx, y=vy)\n\nWe also instantiate a plant model with a 25 % larger friction coefficient K:\n\n@named mtk_plant = Pendulum(K=1.25*defaults(mtk_model)[mtk_model.K])\nmtk_plant = complete(mtk_plant)\ninputs, outputs = [mtk_plant.τ], [mtk_plant.y]\nf2!, h2!, p2 = generate_f_h(mtk_plant, inputs, outputs)\nplant = setname!(NonLinModel(f2!, h2!, Ts, nu, nx, ny; p=p2), u=vu, x=vx, y=vy)","category":"section"},{"location":"manual/mtk/#Controller-Design","page":"ModelingToolkit","title":"Controller Design","text":"We can than reproduce the Kalman filter and the controller design of the last section by reversing the order of σQ vector, because of the different state realization:\n\nα=0.01; σQ=[1.0, 0.1]; σR=[5.0]; nint_u=[1]; σQint_u=[0.1]\nestim = UnscentedKalmanFilter(model; α, σQ, σR, nint_u, σQint_u)\nHp, Hc, Mwt, Nwt = 20, 2, [0.5], [2.5]\nnmpc = NonLinMPC(estim; Hp, Hc, Mwt, Nwt, Cwt=Inf)\numin, umax = [-1.5], [+1.5]\nnmpc = setconstraint!(nmpc; umin, umax)\n\nThe 180° setpoint response is identical:\n\nusing Plots\nN = 35\nusing JuMP; unset_time_limit_sec(nmpc.optim) # hide\nres_ry = sim!(nmpc, N, [180.0], plant=plant, x_0=[0, 0], x̂_0=[0, 0, 0])\nplot(res_ry)\nsavefig(\"plot1_MTK.svg\"); nothing # hide\n\n(Image: plot1_MTK)\n\nand also the output disturbance rejection:\n\nres_yd = sim!(nmpc, N, [180.0], plant=plant, x_0=[0, π], x̂_0=[0, π, 0], y_step=[10])\nplot(res_yd)\nsavefig(\"plot2_MTK.svg\"); nothing # hide\n\n(Image: plot2_MTK)","category":"section"},{"location":"manual/mtk/#Acknowledgement","page":"ModelingToolkit","title":"Acknowledgement","text":"Authored by 1-Bart-1 and baggepinnen, thanks for the contribution.","category":"section"},{"location":"public/plot_sim/#Functions:-Simulations-and-Plots","page":"Simulations and Plots","title":"Functions: Simulations and Plots","text":"Pages = [\"plot_sim.md\"]\n\nThis page documents the functions for quick plotting of open- and closed-loop simulations. They are generic to SimModel, StateEstimator and PredictiveController types. A SimResult instance must be created first with its constructor or by calling sim!. The results are then visualized with plot function from Plots.jl.","category":"section"},{"location":"public/plot_sim/#Quick-Simulations","page":"Simulations and Plots","title":"Quick Simulations","text":"","category":"section"},{"location":"public/plot_sim/#Simulation-Results","page":"Simulations and Plots","title":"Simulation Results","text":"","category":"section"},{"location":"public/plot_sim/#Plotting-Results","page":"Simulations and Plots","title":"Plotting Results","text":"The plot methods are based on Plots.jl package. To install it run using Pkg; Pkg.add(\"Plots\") in the Julia REPL.","category":"section"},{"location":"public/plot_sim/#ModelPredictiveControl.sim!","page":"Simulations and Plots","title":"ModelPredictiveControl.sim!","text":"sim!(\n    plant::SimModel, N::Int, u=plant.uop.+1, d=plant.dop; x_0=plant.xop, progress=true\n) -> res\n\nOpen-loop simulation of plant for N time steps, default to unit bump test on all inputs.\n\nThe manipulated inputs mathbfu and measured disturbances mathbfd are held constant at u and d values, respectively. The plant initial state mathbfx(0) is specified by x_0 keyword arguments. If progress is true, VS Code will display a progress percentage of the simulation. The function returns SimResult instances that can be visualized by calling plot on them. Note that the method mutates plant internal states.\n\nExamples\n\njulia> plant = NonLinModel((x,u,d,_)->0.1x+u+d, (x,_,_)->2x, 5, 1, 1, 1, 1, solver=nothing);\n\njulia> res = sim!(plant, 15, [0], [0], x_0=[1])\nSimulation results of NonLinModel with 15 time steps.\n\n\n\n\n\nsim!(\n    estim::StateEstimator,\n    N::Int,\n    u = estim.model.uop .+ 1,\n    d = estim.model.dop;\n    <keyword arguments>\n) -> res\n\nClosed-loop simulation of estim estimator for N steps, default to input bumps.\n\nSee Arguments for the available options. The noises are provided as standard deviations σ vectors. The simulated sensor and process noises of plant are specified by y_noise and x_noise arguments, respectively.\n\nArguments\n\ninfo: Info\nKeyword arguments with emphasis are non-Unicode alternatives.\n\nestim::StateEstimator : state estimator to simulate\nN::Int : simulation length in time steps\nu = estim.model.uop .+ 1 : manipulated input mathbfu value\nd = estim.model.dop : plant measured disturbance mathbfd value\nplant::SimModel = estim.model : simulated plant model\nu_step  = zeros(plant.nu) : step load disturbance on plant inputs mathbfu\nu_noise = zeros(plant.nu) : gaussian load disturbance on plant inputs mathbfu\ny_step  = zeros(plant.ny) : step disturbance on plant outputs mathbfy\ny_noise = zeros(plant.ny) : additive gaussian noise on plant outputs mathbfy\nd_step  = zeros(plant.nd) : step on measured disturbances mathbfd\nd_noise = zeros(plant.nd) : additive gaussian noise on measured dist. mathbfd\nx_noise = zeros(plant.nx) : additive gaussian noise on plant states mathbfx\nx_0 = plant.xop : plant initial state mathbfx(0)\nx̂_0 = nothing or xhat_0 : initial estimate mathbfx̂(0), initstate!  is used if nothing\nlastu = plant.uop : last plant input mathbfu for mathbfx̂ initialization\nprogress = true : display a progress percentage in VS Code if true\n\nExamples\n\njulia> model = LinModel(tf(3, [30, 1]), 0.5);\n\njulia> estim = KalmanFilter(model, σR=[0.5], σQ=[0.25], σQint_ym=[0.01], σPint_ym_0=[0.1]);\n\njulia> res = sim!(estim, 50, [0], y_noise=[0.5], x_noise=[0.25], x_0=[-10], x̂_0=[0, 0])\nSimulation results of KalmanFilter with 50 time steps.\n\n\n\n\n\nsim!(\n    mpc::PredictiveController, \n    N::Int,\n    ry = mpc.estim.model.yop .+ 1, \n    d  = mpc.estim.model.dop,\n    ru = mpc.estim.model.uop;\n    <keyword arguments>\n) -> res\n\nClosed-loop simulation of mpc controller for N steps, default to output setpoint bumps.\n\nThe output and manipulated input setpoints are held constant at ry and ru, respectively. The keyword arguments are identical to sim!(::StateEstimator, ::Int).\n\nExamples\n\njulia> model = LinModel([tf(3, [30, 1]); tf(2, [5, 1])], 4);\n\njulia> mpc = setconstraint!(LinMPC(model, Mwt=[0, 1], Nwt=[0.01], Hp=30), ymin=[0, -Inf]);\n\njulia> res = sim!(mpc, 25, [0, 0], y_noise=[0.1], y_step=[-10, 0])\nSimulation results of LinMPC with 25 time steps.\n\n\n\n\n\n","category":"function"},{"location":"public/plot_sim/#ModelPredictiveControl.SimResult","page":"Simulations and Plots","title":"ModelPredictiveControl.SimResult","text":"SimResult(obj::SimModel,             U_data, Y_data, D_data=[]; <keyword arguments>)\nSimResult(obj::StateEstimator,       U_data, Y_data, D_data=[]; <keyword arguments>)\nSimResult(obj::PredictiveController, U_data, Y_data, D_data=[]; <keyword arguments>)\n\nManually construct a SimResult to quickly plot obj simulations.\n\nExcept for obj, all the arguments should be matrices of N columns, where N is the  number of time steps. SimResult objects allow to quickly plot simulation results. Simply call plot on them.\n\nArguments\n\ninfo: Info\nKeyword arguments with emphasis are non-Unicode alternatives.\n\nobj : simulated SimModel/StateEstimator/PredictiveController\nU_data : manipulated inputs\nY_data : plant outputs\nD_data=[] : measured disturbances\nX_data=nothing : plant states\nX̂_data=nothing or Xhat_data : estimated states\nŶ_data=nothing or Yhat_data : estimated outputs\nRy_data=nothing : plant output setpoints\nRu_data=nothing : manipulated input setpoints\nplant=get_model(obj) : simulated plant model, default to obj internal plant model\n\nExamples\n\njulia> model = LinModel(tf(1, [1, 1]), 1.0);\n\njulia> N = 5; U_data = fill(1.0, 1, N); Y_data = zeros(1, N);\n\njulia> for i=1:N; updatestate!(model, U_data[:, i]); Y_data[:, i] = model(); end; Y_data\n1×5 Matrix{Float64}:\n 0.632121  0.864665  0.950213  0.981684  0.993262\n\njulia> res = SimResult(model, U_data, Y_data)\nSimulation results of LinModel with 5 time steps.\n\n\n\n\n\n","category":"type"},{"location":"public/plot_sim/#ModelPredictiveControl.plot_recipe","page":"Simulations and Plots","title":"ModelPredictiveControl.plot_recipe","text":"plot(res::SimResult{<:Real, <:SimModel}; <keyword arguments>)\n\nPlot the simulation results of a SimModel.\n\nArguments\n\ninfo: Info\nThe keyword arguments can be Bools, index ranges (2:4) or vectors ([1, 3]), to select the variables to plot.\n\nres::SimResult{<:Real, <:SimModel} : simulation results to plot\nploty=true : plot plant outputs mathbfy\nplotu=true : plot manipulated inputs mathbfu\nplotd=true : plot measured disturbances mathbfd if applicable\nplotx=false : plot plant states mathbfx\n\nExamples\n\njulia> res = sim!(LinModel(tf(2, [10, 1]), 2.0), 25);\n\njulia> using Plots; plot(res, plotu=false)\n\n(Image: plot_model)\n\n\n\n\n\nplot(res::SimResult{<:Real, <:StateEstimator}; <keyword arguments>)\n\nPlot the simulation results of a StateEstimator.\n\nArguments\n\ninfo: Info\nThe keyword arguments can be Bools, index ranges (2:4) or vectors ([1, 3]), to select the variables to plot. Keywords in emphasis are non-Unicode alternatives.\n\nres::SimResult{<:Real, <:StateEstimator} : simulation results to plot\nplotŷ=true or plotyhat : plot estimated outputs mathbfŷ\nplotx̂=false or plotxhat : plot estimated states mathbfx̂\nplotxwithx̂=false or plotxwithxhat : plot plant states mathbfx and estimated   states mathbfx̂ together\nplotx̂min=true or plotxhatmin : plot estimated state lower bounds mathbfx̂_min  if applicable\nplotx̂max=true or plotxhatmax : plot estimated state upper bounds mathbfx̂_max  if applicable\n<keyword arguments> of plot(::SimResult{<:Real, <:SimModel})\n\nExamples\n\njulia> res = sim!(KalmanFilter(LinModel(tf(3, [2.0, 1]), 1.0)), 25, [0], y_step=[1]);\n\njulia> using Plots; plot(res, plotu=false, plotŷ=true, plotxwithx̂=true)\n\n(Image: plot_estimator)\n\n\n\n\n\nplot(res::SimResult{<:Real, <:PredictiveController}; <keyword arguments>)\n\nPlot the simulation results of a PredictiveController.\n\nArguments\n\ninfo: Info\nThe keyword arguments can be Bools, index ranges (2:4) or vectors ([1, 3]), to select the variables to plot.\n\nres::SimResult{<:Real, <:PredictiveController} : simulation results to plot\nplotry=true : plot plant output setpoints mathbfr_y if applicable\nplotymin=true : plot predicted output lower bounds mathbfy_min if applicable\nplotymax=true : plot predicted output upper bounds mathbfy_max if applicable\nplotru=true : plot manipulated input setpoints mathbfr_u if applicable\nplotumin=true : plot manipulated input lower bounds mathbfu_min if applicable\nplotumax=true : plot manipulated input upper bounds mathbfu_max if applicable\n<keyword arguments> of plot(::SimResult{<:Real, <:SimModel})\n<keyword arguments> of plot(::SimResult{<:Real, <:StateEstimator})\n\nExamples\n\njulia> model = LinModel(tf(2, [5.0, 1]), 1.0);\n\njulia> res = sim!(setconstraint!(LinMPC(model), umax=[1.0]), 25, [0], u_step=[-1]);\n\njulia> using Plots; plot(res, plotŷ=true, plotry=true, plotumax=true, plotx̂=[2])\n\n(Image: plot_controller)\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#Functions:-StateEstimator-Internals","page":"State Estimators","title":"Functions: StateEstimator Internals","text":"Pages = [\"state_estim.md\"]","category":"section"},{"location":"internals/state_estim/#Estimator-Construction","page":"State Estimators","title":"Estimator Construction","text":"","category":"section"},{"location":"internals/state_estim/#Augmented-Model","page":"State Estimators","title":"Augmented Model","text":"","category":"section"},{"location":"internals/state_estim/#Update-Quadratic-Optimization","page":"State Estimators","title":"Update Quadratic Optimization","text":"","category":"section"},{"location":"internals/state_estim/#Solve-Optimization-Problem","page":"State Estimators","title":"Solve Optimization Problem","text":"","category":"section"},{"location":"internals/state_estim/#Remove-Operating-Points","page":"State Estimators","title":"Remove Operating Points","text":"","category":"section"},{"location":"internals/state_estim/#Init-Estimate","page":"State Estimators","title":"Init Estimate","text":"","category":"section"},{"location":"internals/state_estim/#Correct-Estimate","page":"State Estimators","title":"Correct Estimate","text":"","category":"section"},{"location":"internals/state_estim/#Update-Estimate","page":"State Estimators","title":"Update Estimate","text":"info: Info\nAll these methods assume that the u0, y0m and d0 arguments are deviation vectors from their respective operating points (see setop!). The associated equations in the documentation drops the mathbf0 in subscript to simplify the notation. Strictly speaking, the manipulated inputs, measured outputs, measured disturbances and estimated states should be denoted with mathbfu_0 y_0^m d_0 and mathbfx̂_0, respectively.","category":"section"},{"location":"internals/state_estim/#ModelPredictiveControl.init_estimstoch","page":"State Estimators","title":"ModelPredictiveControl.init_estimstoch","text":"init_estimstoch(model, i_ym, nint_u, nint_ym) -> As, Cs_u, Cs_y, nxs, nint_u, nint_ym\n\nInit stochastic model matrices from integrator specifications for state estimation.\n\nThe arguments nint_u and nint_ym specify how many integrators are added to each  manipulated input and measured outputs. The function returns the state-space matrices As,  Cs_u and Cs_y of the stochastic model:\n\nbeginaligned\nmathbfx_s(k+1)     = mathbfA_s x_s(k) + mathbfB_s e(k) \nmathbfy_s_u(k)   = mathbfC_s_u x_s(k) \nmathbfy_s_y(k)   = mathbfC_s_y x_s(k) \nendaligned\n\nwhere mathbfe(k) is an unknown zero mean white noise and mathbfA_s =  mathrmdiag(mathbfA_s_u A_s_y). The estimations does not use mathbfB_s, it is thus ignored. The function init_integrators builds the state-space matrices.\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.init_integrators","page":"State Estimators","title":"ModelPredictiveControl.init_integrators","text":"init_integrators(nint, ny, varname::String) -> A, C, nint\n\nCalc A, C state-space matrices from integrator specifications nint.\n\nThis function is used to initialize the stochastic part of the augmented model for the design of state estimators. The vector nint provides how many integrators (in series)  should be incorporated for each output. The argument should have ny element, except for nint=0 which is an alias for no integrator at all. The specific case of one integrator per output results in A = I and C = I. The estimation does not use the B matrix, it  is thus ignored. This function is called twice :\n\nfor the unmeasured disturbances at manipulated inputs mathbfu\nfor the unmeasured disturbances at measured outputs mathbfy^m\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.augment_model","page":"State Estimators","title":"ModelPredictiveControl.augment_model","text":"augment_model(\n    model::LinModel, As, Cs_u, Cs_y; verify_obsv=true\n) -> Â, B̂u, Ĉ, B̂d, D̂d, x̂op, f̂op\n\nAugment LinModel state-space matrices with stochastic ones As, Cs_u, Cs_y.\n\nIf mathbfx_0 is model.x0 state, and mathbfx_s, the states defined at init_estimstoch, we define an augmented state vector mathbfx̂_0 =   beginsmallmatrix mathbfx_0  mathbfx_s endsmallmatrix . The method returns the augmented matrices Â, B̂u, Ĉ, B̂d and D̂d:\n\nbeginaligned\n    mathbfx̂_0(k+1) = mathbfÂ x̂_0(k) + mathbfB̂_u u_0(k) + mathbfB̂_d d_0(k) \n    mathbfŷ_0(k)   = mathbfĈ x̂_0(k) + mathbfD̂_d d_0(k)\nendaligned\n\nAn error is thrown if the augmented model is not observable and verify_obsv == true. The augmented operating points mathbfx̂_op and mathbff̂_op are simply  mathbfx_op and mathbff_op vectors appended with zeros (see setop!).  See Extended Help for a detailed definition of the augmented matrices and vectors.\n\nExtended Help\n\ndetails: Extended Help\nUsing the As, Cs_u and Cs_y matrices of the stochastic model constructed in init_estimstoch), and model.A, model.Bu, model.Bd, model.C, model.Dd matrices, the state-space matrices of the augmented model are defined as follows:beginaligned\nmathbfÂ   =                                    beginbmatrix \n    mathbfA  mathbfB_u C_s_u               \n    mathbf0  mathbfA_s                      endbmatrix \nmathbfB̂_u =                                    beginbmatrix\n    mathbfB_u                                   \n    mathbf0                                     endbmatrix \nmathbfĈ   =                                    beginbmatrix\n    mathbfC  mathbfC_s_y                  endbmatrix \nmathbfB̂_d =                                    beginbmatrix \n    mathbfB_d                                   \n    mathbf0                                     endbmatrix \nmathbfD̂_d = mathbfD_d\nendalignedand the operating points of the augmented model are:beginaligned\n    mathbfx̂_op = beginbmatrix mathbfx_op  mathbf0 endbmatrix \n    mathbff̂_op = beginbmatrix mathbff_op  mathbf0 endbmatrix\nendaligned\n\n\n\n\n\naugment_model(\n    model::SimModel, As, Cs_u, Cs_y; verify_obsv=false\n) -> Â, B̂u, Ĉ, B̂d, D̂d, x̂op, f̂op\n\nReturn empty matrices, and x̂op & f̂op vectors, if model is not a LinModel.\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.init_ukf","page":"State Estimators","title":"ModelPredictiveControl.init_ukf","text":"init_ukf(nx̂, α, β, κ) -> nσ, γ, m̂, Ŝ\n\nCompute the UnscentedKalmanFilter constants from α β and κ.\n\nWith n_mathbfx̂ elements in the state vector mathbfx̂ and  n_σ = 2 n_mathbfx̂ + 1 sigma points, the scaling factor applied on standard deviation  matrices sqrtmathbfP̂ is:\n\n    γ = α sqrt n_mathbfx̂ + κ \n\nThe weight vector (n_σ  1) for the mean and the weight matrix (n_σ  n_σ) for the  covariance are respectively:\n\nbeginaligned\n    mathbfm̂ = beginbmatrix 1 - tfracn_mathbfx̂γ^2  tfrac12γ^2  tfrac12γ^2  cdots  tfrac12γ^2 endbmatrix \n    mathbfŜ = mathrmdiagbig( 2 - α^2 + β - tfracn_mathbfx̂γ^2  tfrac12γ^2  tfrac12γ^2  cdots  tfrac12γ^2 big)\nendaligned\n\nSee update_estimate!(::UnscentedKalmanFilter) for other details.\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.init_internalmodel","page":"State Estimators","title":"ModelPredictiveControl.init_internalmodel","text":"init_internalmodel(As, Bs, Cs, Ds) -> Âs, B̂s\n\nCalc stochastic model update matrices Âs and B̂s for InternalModel estimator.\n\nAs, Bs, Cs and Ds are the stochastic model matrices :\n\nbeginaligned\n    mathbfx_s(k+1) = mathbfA_s x_s(k) + mathbfB_s e(k) \n    mathbfy_s(k)   = mathbfC_s x_s(k) + mathbfD_s e(k)\nendaligned\n\nwhere mathbfe(k) is conceptual and unknown zero mean white noise. Its optimal estimation is mathbfê=0, the expected value. Thus, the Âs and B̂s matrices that  optimally update the stochastic estimate mathbfx̂_s are:\n\nbeginaligned\n    mathbfx̂_s(k+1) \n        = mathbf(A_s - B_s D_s^-1 C_s) x̂_s(k) + mathbf(B_s D_s^-1) ŷ_s(k) \n        = mathbfÂ_s x̂_s(k) + mathbfB̂_s ŷ_s(k)\nendaligned\n\nwith current stochastic outputs estimation mathbfŷ_s(k), composed of the measured  mathbfŷ_s^m(k) = mathbfy^m(k) - mathbfŷ_d^m(k) and unmeasured  mathbfŷ_s^u = 0 outputs. See [1].\n\n[1]: Desbiens, A., D. Hodouin & É. Plamondon. 2000, \"Global predictive control : a unified control structure for decoupling setpoint tracking, feedforward compensation and  disturbance rejection dynamics\", IEE Proceedings - Control Theory and Applications,  vol. 147, no 4, https://doi.org/10.1049/ip-cta:20000443, p. 465–475, ISSN 1350-2379.\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.init_predmat_mhe","page":"State Estimators","title":"ModelPredictiveControl.init_predmat_mhe","text":"init_predmat_mhe(\n    model::LinModel, He, i_ym, Â, B̂u, Ĉm, B̂d, D̂dm, x̂op, f̂op, p\n) -> E, G, J, B, ex̄, Ex̂, Gx̂, Jx̂, Bx̂\n\nConstruct the MovingHorizonEstimator prediction matrices for LinModel model.\n\nWe first introduce the deviation vector of the estimated state at arrival  mathbfx̂_0(k-N_k+p) = mathbfx̂_k(k-N_k+p) - mathbfx̂_op (see setop!), and the vector mathbfZ = beginsmallmatrix mathbfx̂_0(k-N_k+p)  mathbfŴ endsmallmatrix with the decision variables. Setting the constant p=0 produces an estimator in the current form, while the prediction form is obtained with p=1. The estimated sensor noises from time k-N_k+1 to k are computed by:\n\nbeginaligned\n    mathbfV̂ = mathbfY_0^m - Ŷ_0^m = mathbfE Z + G U_0 + J D_0 + Y_0^m + B     \n                                        = mathbfE Z + F\nendaligned\n\nin which mathbfU_0 and mathbfY_0^m respectively include the deviation values of the manipulated inputs mathbfu_0(k-j+p) from j=N_k to 1 and measured outputs mathbfy_0^m(k-j+1) from j=N_k to 1. The vector mathbfD_0 comprises one  additional measured disturbance if p=0, that is, it includes the deviation vectors mathbfd_0(k-j+1) from j=N_k+1-p to 1. The constant mathbfB is the contribution for non-zero state mathbfx̂_op and state update mathbff̂_op operating points (for linearization, see augment_model and linearize). The method also returns the matrices for the estimation error at arrival:\n\n    mathbfx̄ = mathbfx̂_0^(k-N_k+p) - mathbfx̂_0(k-N_k+p) = mathbfe_x̄ Z + f_x̄\n\nin which mathbfe_x̄ = beginsmallmatrix -mathbfI  mathbf0  cdots  mathbf0 endsmallmatrix, and mathbff_x̄ = mathbfx̂_0^(k-N_k+p). The latter is the deviation vector of the state at arrival, estimated at time k-N_k, i.e. mathbfx̂_0^(k-N_k+p) =  mathbfx̂_k-N_k(k-N_k+p) - mathbfx̂_op. Lastly, the estimates mathbfx̂_0(k-j+p) from j=N_k-1 to 0, also in deviation form, are computed with:\n\nbeginaligned\n    mathbfX̂_0  = mathbfE_x̂ Z + G_x̂ U_0 + J_x̂ D_0 + B_x̂ \n                  = mathbfE_x̂ Z + F_x̂\nendaligned\n\nThe matrices mathbfE G J B E_x̂ G_x̂ J_x̂ B_x̂ are defined in the Extended Help  section. The vectors mathbfF F_x̂ f_x̄ are recalculated at each discrete time step,  see initpred!(::MovingHorizonEstimator, ::LinModel) and linconstraint!(::MovingHorizonEstimator, ::LinModel).\n\nExtended Help\n\ndetails: Extended Help\nUsing the augmented process model matrices mathbfÂ B̂_u Ĉ^m B̂_d D̂_d^m, and the function mathbfS(j) = _i=0^j mathbfÂ^i, the prediction matrices for the sensor noises depend on the constant p. For p=0, the matrices are computed by (notice the minus signs after the equalities):beginaligned\nmathbfE = - beginbmatrix\n    mathbfĈ^mmathbfÂ^1                   mathbfĈ^mmathbfÂ^0                     cdots  mathbf0                                \n    mathbfĈ^mmathbfÂ^2                   mathbfĈ^mmathbfÂ^1                     cdots  mathbf0                                \n    vdots                                       vdots                                         ddots  vdots                                   \n    mathbfĈ^mmathbfÂ^H_e                 mathbfĈ^mmathbfÂ^H_e-1                 cdots  mathbfĈ^mmathbfÂ^0               endbmatrix \nmathbfG = - beginbmatrix\n    mathbfĈ^mmathbfÂ^0mathbfB̂_u       mathbf0                                     cdots  mathbf0                                \n    mathbfĈ^mmathbfÂ^1mathbfB̂_u       mathbfĈ^mmathbfÂ^0mathbfB̂_u         cdots  mathbf0                                \n    vdots                                       vdots                                         ddots  vdots                                   \n    mathbfĈ^mmathbfÂ^H_e-1mathbfB̂_u   mathbfĈ^mmathbfÂ^H_e-2mathbfB̂_u     cdots  mathbfĈ^mmathbfÂ^0mathbfB̂_u   endbmatrix \nmathbfJ = - beginbmatrix\n    mathbfĈ^mmathbfÂ^0mathbfB̂_d       mathbfD̂_d^m                                 cdots  mathbf0                                \n    mathbfĈ^mmathbfÂ^1mathbfB̂_d       mathbfĈ^mmathbfÂ^0mathbfB̂_d         cdots  mathbf0                                \n    vdots                                       vdots                                         ddots  vdots                                   \n    mathbfĈ^mmathbfÂ^H_e-1mathbfB̂_d   mathbfĈ^mmathbfÂ^H_e-2mathbfB̂_d     cdots  mathbfD̂_d^m                           endbmatrix \nmathbfB = - beginbmatrix\n    mathbfĈ^m S(0)                    \n    mathbfĈ^m S(1)                    \n    vdots                               \n    mathbfĈ^m S(H_e-1) endbmatrix  mathbfbig(f̂_op - x̂_opbig)\nendalignedor, for p=1, the matrices are given by:beginaligned\nmathbfE = - beginbmatrix\n    mathbfĈ^mmathbfÂ^0                   mathbf0                                     cdots  mathbf0    \n    mathbfĈ^mmathbfÂ^1                   mathbfĈ^mmathbfÂ^0                     cdots  mathbf0    \n    vdots                                       vdots                                         ddots  vdots       \n    mathbfĈ^mmathbfÂ^H_e-1               mathbfĈ^mmathbfÂ^H_e-2                 cdots  mathbf0   endbmatrix \nmathbfG = - beginbmatrix\n    mathbf0                                   mathbf0                                     cdots  mathbf0    \n    mathbfĈ^mmathbfÂ^0mathbfB̂_u       mathbf0                                     cdots  mathbf0    \n    vdots                                       vdots                                         ddots  vdots       \n    mathbfĈ^mmathbfÂ^H_e-2mathbfB̂_u   mathbfĈ^mmathbfÂ^H_e-3mathbfB̂_u     cdots  mathbf0   endbmatrix \nmathbfJ = - beginbmatrix\n    mathbfD̂_d^m                               mathbf0                                     cdots  mathbf0    \n    mathbfĈ^mmathbfÂ^0mathbfB̂_d       mathbfD̂_d^m                                 cdots  mathbf0    \n    vdots                                       vdots                                         ddots  vdots       \n    mathbfĈ^mmathbfÂ^H_e-2mathbfB̂_d   mathbfĈ^mmathbfÂ^H_e-3mathbfB̂_d     cdots  mathbfD̂_d^m endbmatrix \nmathbfB = - beginbmatrix\n    mathbf0                             \n    mathbfĈ^m S(0)                    \n    vdots                               \n    mathbfĈ^m S(H_e-2) endbmatrix  mathbfbig(f̂_op - x̂_opbig)\nendalignedThe matrices for the estimated states are computed by:beginaligned\nmathbfE_x̂ = beginbmatrix\n    mathbfÂ^1                       mathbfA^0                     cdots  mathbf0                   \n    mathbfÂ^2                       mathbfÂ^1                     cdots  mathbf0                    \n    vdots                               vdots                             ddots  vdots                       \n    mathbfÂ^H_e                     mathbfÂ^H_e-1                 cdots  mathbfÂ^0               endbmatrix \nmathbfG_x̂ = beginbmatrix\n    mathbfÂ^0mathbfB̂_u           mathbf0                         cdots  mathbf0                    \n    mathbfÂ^1mathbfB̂_u           mathbfÂ^0mathbfB̂_u         cdots  mathbf0                    \n    vdots                               vdots                             ddots  vdots                       \n    mathbfÂ^H_e-1mathbfB̂_u       mathbfÂ^H_e-2mathbfB̂_u     cdots  mathbfÂ^0mathbfB̂_u   endbmatrix \nmathbfJ_x̂^ = beginbmatrix\n    mathbfÂ^0mathbfB̂_d           mathbf0                         cdots  mathbf0                    \n    mathbfÂ^1mathbfB̂_d           mathbfÂ^0mathbfB̂_d         cdots  mathbf0                    \n    vdots                               vdots                             ddots  vdots                       \n    mathbfÂ^H_e-1mathbfB̂_d       mathbfÂ^H_e-2mathbfB̂_d     cdots  mathbfÂ^0mathbfB̂_d   endbmatrix   quad\nmathbfJ_x̂ = begincases\n    beginsmallmatrix mathbfJ_x̂^  mathbf0 endsmallmatrix      p=0                                   \n                         mathbfJ_x̂^                                      p=1                                   endcases   \nmathbfB_x̂ = beginbmatrix\n    mathbfS(0)                    \n    mathbfS(1)                    \n    vdots                           \n    mathbfS(H_e-1) endbmatrix  mathbfbig(f̂_op - x̂_opbig)\nendalignedAll these matrices are truncated when N_k  H_e (at the beginning).\n\n\n\n\n\nReturn empty matrices if model is not a LinModel, except for ex̄.\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.relaxarrival","page":"State Estimators","title":"ModelPredictiveControl.relaxarrival","text":"relaxarrival(\n    model::SimModel, nε, c_x̂min, c_x̂max, x̂min, x̂max, ex̄\n) -> A_x̃min, A_x̃max, x̃min, x̃max, ẽx̄\n\nAugment arrival state constraints with slack variable ε for softening the MHE.\n\nDenoting the MHE decision variable augmented with the slack variable mathbfZ̃ =  beginsmallmatrix ε  mathbfZ endsmallmatrix, it returns the mathbfẽ_x̄ matrix that appears in the estimation error at arrival equation mathbfx̄ = mathbfẽ_x̄ Z̃ + f_x̄. It also returns the augmented constraints mathbfx̃_min and mathbfx̃_max, and the mathbfA matrices for the inequality constraints:\n\nbeginbmatrix \n    mathbfA_x̃_min  \n    mathbfA_x̃_max\nendbmatrix mathbfZ̃ \nbeginbmatrix\n    - mathbf(x̃_min - x̃_op) \n    + mathbf(x̃_max - x̃_op)\nendbmatrix\n\nin which mathbfx̃_min = beginsmallmatrix 0  mathbfx̂_min endsmallmatrix,  mathbfx̃_max = beginsmallmatrix   mathbfx̂_max endsmallmatrix and mathbfx̃_op  = beginsmallmatrix 0  mathbfx̂_op  endsmallmatrix\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.relaxX̂","page":"State Estimators","title":"ModelPredictiveControl.relaxX̂","text":"relaxX̂(model::SimModel, nε, C_x̂min, C_x̂max, Ex̂) -> A_X̂min, A_X̂max, Ẽx̂\n\nAugment estimated state constraints with slack variable ε for softening the MHE.\n\nDenoting the MHE decision variable augmented with the slack variable mathbfZ̃ =  beginsmallmatrix ε  mathbfZ endsmallmatrix, it returns the mathbfẼ_x̂ matrix that appears in estimated states equation mathbfX̂ = mathbfẼ_x̂ Z̃ + F_x̂. It also returns the mathbfA matrices for the inequality constraints:\n\nbeginbmatrix \n    mathbfA_X̂_min  \n    mathbfA_X̂_max\nendbmatrix mathbfZ̃ \nbeginbmatrix\n    - mathbf(X̂_min - X̂_op) + F_x̂ \n    + mathbf(X̂_max - X̂_op) - F_x̂\nendbmatrix\n\nin which mathbfX̂_min X̂_max and mathbfX̂_op vectors respectively contains mathbfx̂_min x̂_max and mathbfx̂_op repeated H_e times.\n\n\n\n\n\nReturn empty matrices if model is not a LinModel\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.relaxŴ","page":"State Estimators","title":"ModelPredictiveControl.relaxŴ","text":"relaxŴ(model::SimModel, nε, C_ŵmin, C_ŵmax, nx̂) -> A_Ŵmin, A_Ŵmax\n\nAugment estimated process noise constraints with slack variable ε for softening the MHE.\n\nDenoting the MHE decision variable augmented with the slack variable mathbfZ̃ =  beginsmallmatrix ε  mathbfZ endsmallmatrix, it returns the mathbfA  matrices for the inequality constraints:\n\nbeginbmatrix \n    mathbfA_Ŵ_min  \n    mathbfA_Ŵ_max\nendbmatrix mathbfZ̃ \nbeginbmatrix\n    - mathbfŴ_min \n    + mathbfŴ_max\nendbmatrix\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.relaxV̂","page":"State Estimators","title":"ModelPredictiveControl.relaxV̂","text":"relaxV̂(model::SimModel, nε, C_v̂min, C_v̂max, E) -> A_V̂min, A_V̂max, Ẽ\n\nAugment estimated sensor noise constraints with slack variable ε for softening the MHE.\n\nDenoting the MHE decision variable augmented with the slack variable mathbfZ̃ =  beginsmallmatrix ε  mathbfZ endsmallmatrix, it returns the mathbfẼ matrix that appears in estimated sensor noise equation mathbfV̂ = mathbfẼ Z̃ + F. It also returns the mathbfA matrices for the inequality constraints:\n\nbeginbmatrix \n    mathbfA_V̂_min  \n    mathbfA_V̂_max\nendbmatrix mathbfZ̃ \nbeginbmatrix\n    - mathbfV̂_min + F \n    + mathbfV̂_max - F\nendbmatrix\n\n\n\n\n\nReturn empty matrices if model is not a LinModel\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.init_matconstraint_mhe","page":"State Estimators","title":"ModelPredictiveControl.init_matconstraint_mhe","text":"init_matconstraint_mhe(model::LinModel, \n    i_x̃min, i_x̃max, i_X̂min, i_X̂max, i_Ŵmin, i_Ŵmax, i_V̂min, i_V̂max, args...\n) -> i_b, i_g, A\n\nInit i_b, i_g and A matrices for the MHE linear inequality constraints.\n\nThe linear and nonlinear inequality constraints are respectively defined as:\n\nbeginaligned \n    mathbfA Z̃   mathbfb  \n    mathbfg(Z̃)  mathbf0\nendaligned\n\ni_b is a BitVector including the indices of mathbfb that are finite numbers.  i_g is a similar vector but for the indices of mathbfg (empty if model is a  LinModel). The method also returns the mathbfA matrix if args is provided. In such a case, args  needs to contain all the inequality constraint matrices:  A_x̃min, A_x̃max, A_X̂min, A_X̂max, A_Ŵmin, A_Ŵmax, A_V̂min, A_V̂max.\n\n\n\n\n\nInit i_b, A without state and sensor noise constraints if model is not a LinModel.\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.get_nonlinobj_op-Tuple{MovingHorizonEstimator, JuMP.GenericModel}","page":"State Estimators","title":"ModelPredictiveControl.get_nonlinobj_op","text":"get_nonlinobj_op(estim::MovingHorizonEstimator, optim) -> J_op\n\nReturn the nonlinear operator for the objective of estim MovingHorizonEstimator.\n\nIt is based on the splatting syntax. This method is really intricate and that's because of:\n\nThese functions are used inside the nonlinear optimization, so they must be type-stable and as efficient as possible. All the function outputs and derivatives are cached and updated in-place if required to use the efficient value_and_gradient!.\nThe splatting syntax for objective functions implies the use of Vararg{T,N} (see the performance tip) and memoization to avoid redundant computations. This is already complex, but it's even worse knowing that the automatic differentiation tools do not support splatting.\n\n\n\n\n\n","category":"method"},{"location":"internals/state_estim/#ModelPredictiveControl.get_nonlincon_oracle-Tuple{MovingHorizonEstimator, JuMP.GenericModel}","page":"State Estimators","title":"ModelPredictiveControl.get_nonlincon_oracle","text":"get_nonlincon_oracle(estim::MovingHorizonEstimator, optim) -> g_oracle, geq_oracle\n\nReturn the nonlinear constraint oracles for MovingHorizonEstimator estim.\n\nReturn g_oracle and geq_oracle, the inequality and equality VectorNonlinearOracle for the two respective constraints. Note that g_oracle only includes the non-Inf inequality constraints, thus it must be re-constructed if they change. This method is really intricate because the oracles are used inside the nonlinear optimization, so they must be type-stable and as efficient as possible. All the function outputs and derivatives are  ached and updated in-place if required to use the efficient value_and_jacobian!.\n\n\n\n\n\n","category":"method"},{"location":"internals/state_estim/#ModelPredictiveControl.f̂!","page":"State Estimators","title":"ModelPredictiveControl.f̂!","text":"f̂!(x̂0next, û0, k0, estim::StateEstimator, model::SimModel, x̂0, u0, d0) -> nothing\n\nMutating state function mathbff̂ of the augmented model.\n\nBy introducing an augmented state vector mathbfx̂_0 like in augment_model,  the function returns the next state of the augmented model, as deviation vectors:\n\nbeginaligned\n    mathbfx̂_0(k+1) = mathbff̂Big(mathbfx̂_0(k) mathbfu_0(k) mathbfd_0(k)Big) \n    mathbfŷ_0(k)   = mathbfĥBig(mathbfx̂_0(k) mathbfd_0(k)Big) \nendaligned\n\nwhere mathbfx̂_0(k+1) is stored in x̂0next argument. The method mutates x̂0next,  û0 and k0 in place. The argument û0 stores the disturbed input of the augmented model mathbfû_0, and k0, the intermediate stage values of model.solver, when applicable. The model parameter model.p is not included in the function signature for conciseness.  The operating points are handled inside mathbff̂. See Extended Help for details on  mathbfû_0 f̂ and mathbfĥ implementations.\n\nExtended Help\n\ndetails: Extended Help\nKnowing that the augmented state vector is defined as mathbfx̂_0 =  beginsmallmatrix mathbfx_0  mathbfx_s endsmallmatrix , the augmented model functions are:beginaligned\nmathbff̂Big(mathbfx̂_0(k) mathbfu_0(k) mathbfd_0(k)Big)  =               beginbmatrix\n    mathbffBig(mathbfx_0(k) mathbfû_0(k) mathbfd_0(k) mathbfpBig)   \n    mathbfA_s mathbfx_s(k)                                                        endbmatrix \n    + mathbff̂_op - mathbfx̂_op                                                 \nmathbfĥBig(mathbfx̂_0(k) mathbfd_0(k)Big)                   =\n    mathbfhBig(mathbfx_0(k) mathbfd_0(k) mathbfpBig) + mathbfy_s_y(k)\nendalignedin which:beginaligned\nmathbfû_0(k)     = mathbfu_0(k) + mathbfy_s_u(k)                            \nmathbfy_s_u(k) = mathbfC_s_u x_s(k)                                          \nmathbfy_s_y(k) = mathbfC_s_y x_s(k)\nendalignedThe mathbff and mathbfh functions above are in fact the f! and  h! methods, respectively. The operating points mathbfx̂_op f̂_op are computed by augment_model (almost always zeros in practice for  NonLinModel).\n\n\n\n\n\nf̂!(x̂0next, _ , _ , estim::StateEstimator, model::LinModel, x̂0, u0, d0) -> nothing\n\nUse the augmented model matrices and operating points if model is a LinModel.\n\nExtended Help\n\ndetails: Extended Help\nThis method computes:beginaligned\nmathbfx̂_0(k+1) = mathbfÂ x̂_0(k) + mathbfB̂_u u_0(k) + mathbfB̂_d d_0(k)\n                     + mathbff̂_op - mathbfx̂_op                                \nmathbfŷ_0(k)   = mathbfĈ x̂_0(k) + mathbfD̂_d d_0(k)\nendalignedwith the augmented matrices constructed by augment_model.\n\n\n\n\n\nf̂!(x̂0next, û0, k0, model::SimModel, As, Cs_u, f̂op, x̂op, x̂0, u0, d0)\n\nSame than f̂! for SimModel but without the estim argument.\n\n\n\n\n\nf̂!(x̂0next, _ , k0, estim::InternalModel, model::NonLinModel, x̂0, u0, d0)\n\nState function mathbff̂ of InternalModel for NonLinModel.\n\nIt calls f! directly since this estimator does not augment the states.\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.ĥ!","page":"State Estimators","title":"ModelPredictiveControl.ĥ!","text":"ĥ!(ŷ0, estim::StateEstimator, model::SimModel, x̂0, d0) -> nothing\n\nMutating output function mathbfĥ of the augmented model, see f̂!.\n\n\n\n\n\nĥ!(ŷ0, estim::StateEstimator, model::LinModel, x̂0, d0) -> nothing\n\nUse the augmented model matrices if model is a LinModel.\n\n\n\n\n\nĥ!(ŷ0, model::SimModel, Cs_y, x̂0, d0)\n\nSame than ĥ! for SimModel but without the estim argument.\n\n\n\n\n\nĥ!(ŷ0, estim::InternalModel, model::NonLinModel, x̂0, d0)\n\nOutput function mathbfĥ of InternalModel, it calls h!.\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.initpred!-Tuple{MovingHorizonEstimator, LinModel}","page":"State Estimators","title":"ModelPredictiveControl.initpred!","text":"initpred!(estim::MovingHorizonEstimator, model::LinModel) -> nothing\n\nInit quadratic optimization matrices F, fx̄, H̃, q̃, r for MovingHorizonEstimator.\n\nSee init_predmat_mhe for the definition of the vectors mathbfF f_x̄. It also inits estim.optim objective function, expressed as the quadratic general form:\n\n    J = min_mathbfZ̃ frac12mathbfZ̃ H̃ Z̃ + mathbfq̃ Z̃ + r \n\nin which mathbfZ̃ = beginsmallmatrix ε  mathbfZ endsmallmatrix. Note that r is useless at optimization but required to evaluate the objective minima J. The  Hessian mathbfH̃ matrix of the quadratic general form is not constant here because of the time-varying mathbfP̄ covariance . The computed variables are:\n\nbeginaligned\n    mathbfF       = mathbfG U_0 + mathbfJ D_0 + mathbfY_0^m + mathbfB       \n    mathbff_x̄     = mathbfx̂_0^(k-N_k+1)                                             \n    mathbfF_Z̃     = beginsmallmatrixmathbff_x̄  mathbfF endsmallmatrix   \n    mathbfẼ_Z̃     = beginsmallmatrixmathbfẽ_x̄  mathbfẼ endsmallmatrix   \n    mathbfM_N_k = mathrmdiag(mathbfP̄^-1 mathbfR̂_N_k^-1)               \n    mathbfÑ_N_k = mathrmdiag(C  mathbf0  mathbfQ̂_N_k^-1)               \n    mathbfH̃       = 2(mathbfẼ_Z̃ mathbfM_N_k mathbfẼ_Z̃ + mathbfÑ_N_k)   \n    mathbfq̃       = 2(mathbfM_N_k mathbfẼ_Z̃) mathbfF_Z̃                      \n            r        = mathbfF_Z̃ mathbfM_N_k mathbfF_Z̃\nendaligned\n\n\n\n\n\n","category":"method"},{"location":"internals/state_estim/#ModelPredictiveControl.linconstraint!-Tuple{MovingHorizonEstimator, LinModel}","page":"State Estimators","title":"ModelPredictiveControl.linconstraint!","text":"linconstraint!(estim::MovingHorizonEstimator, model::LinModel)\n\nSet b vector for the linear model inequality constraints (mathbfA Z̃  b) of MHE.\n\nAlso init mathbfF_x̂ = G_x̂ U_0 + J_x̂ D_0 + B_x̂ vector for the state constraints, see  init_predmat_mhe.\n\n\n\n\n\n","category":"method"},{"location":"internals/state_estim/#ModelPredictiveControl.optim_objective!-Tuple{MovingHorizonEstimator}","page":"State Estimators","title":"ModelPredictiveControl.optim_objective!","text":"optim_objective!(estim::MovingHorizonEstimator) -> Z̃\n\nOptimize objective of estim MovingHorizonEstimator and return the solution Z̃.\n\nIf first warm-starts the solver with set_warmstart_mhe!. It then calls  JuMP.optimize!(estim.optim) and extract the solution. A failed optimization prints an  @error log in the REPL and returns the warm-start value. A failed optimization also prints getinfo results in the debug log if activated.\n\n\n\n\n\n","category":"method"},{"location":"internals/state_estim/#ModelPredictiveControl.set_warmstart_mhe!","page":"State Estimators","title":"ModelPredictiveControl.set_warmstart_mhe!","text":"set_warmstart_mhe!(V̂, X̂0, estim::MovingHorizonEstimator, Z̃var) -> Z̃s\n\nSet and return the warm-start value of Z̃var for MovingHorizonEstimator.\n\nIf supported by estim.optim, it warm-starts the solver at:\n\nmathbfZ̃_s = \nbeginbmatrix\n    ε_k-1                         \n    mathbfx̂_k-1(k-N_k+p)        \n    mathbfŵ_k-1(k-N_k+p+0)      \n    mathbfŵ_k-1(k-N_k+p+1)      \n    vdots                          \n    mathbfŵ_k-1(k-p-2)         \n    mathbf0                      \nendbmatrix\n\nwhere ε(k-1), mathbfx̂_k-1(k-N_k+p) and mathbfŵ_k-1(k-j) are respectively the slack variable, the arrival state estimate and the process noise estimates computed at the last time step k-1. If the objective function is not finite at this point, all the process noises mathbfŵ_k-1(k-j) are warm-started at zeros. The method mutates all the arguments.\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.predict_mhe!","page":"State Estimators","title":"ModelPredictiveControl.predict_mhe!","text":"predict_mhe!(V̂, X̂0, _, _, _, estim::MovingHorizonEstimator, model::LinModel, Z̃) -> V̂, X̂0\n\nCompute the V̂ vector and X̂0 vectors for the MovingHorizonEstimator and LinModel.\n\nThe function mutates V̂ and X̂0 vector arguments. The vector V̂ is the estimated sensor noises from k-N_k+1 to k. The X̂0 vector is estimated states from k-N_k+2 to  k+1. The computations are (by truncating the matrices when N_k < H_e):\n\nbeginaligned\nmathbfV̂   = mathbfẼ Z̃   + mathbfF     \nmathbfX̂_0 = mathbfẼ_x̂ Z̃ + mathbfF_x̂\nendaligned\n\n\n\n\n\npredict_mhe!(V̂, X̂0, û0, k0, ŷ0, estim::MovingHorizonEstimator, model::SimModel, Z̃) -> V̂, X̂0\n\nCompute the vectors when model is not a LinModel.\n\nThe function mutates V̂, X̂0, û0 and ŷ0 vector arguments. The augmented model of f̂! and ĥ! is called recursively in a for loop from j=1 to N_k, and by adding the estimated process noise mathbfŵ.\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.con_nonlinprog_mhe!","page":"State Estimators","title":"ModelPredictiveControl.con_nonlinprog_mhe!","text":"con_nonlinprog_mhe!(g, estim::MovingHorizonEstimator, model::SimModel, X̂0, V̂, ε) -> g\n\nCompute nonlinear constrains g in-place for MovingHorizonEstimator.\n\n\n\n\n\nNo nonlinear constraints if model is a LinModel, return g unchanged.\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.remove_op!","page":"State Estimators","title":"ModelPredictiveControl.remove_op!","text":"remove_op!(estim::StateEstimator, ym, d, u=nothing) -> y0m, d0, u0\n\nRemove operating pts on measured outputs ym, disturbances d and inputs u (if provided).\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.init_estimate!","page":"State Estimators","title":"ModelPredictiveControl.init_estimate!","text":"init_estimate!(estim::StateEstimator, model::LinModel, y0m, d0, u0)\n\nInit estim.x̂0 estimate with the steady-state solution if model is a LinModel.\n\nUsing u0, y0m and d0 arguments (deviation values, see setop!), the steadystate problem combined to the equality constraint mathbfŷ_0^m = mathbfy_0^m engenders the following system to solve:\n\nbeginbmatrix\n    mathbfI - mathbfÂ                         \n    mathbfĈ^m\nendbmatrix mathbfx̂_0 =\nbeginbmatrix\n    mathbfB̂_u u_0 + B̂_d d_0 + f̂_op - x̂_op    \n    mathbfy_0^m - D̂_d^m d_0\nendbmatrix\n\nin which mathbfĈ^m D̂_d^m are the rows of estim.Ĉ, estim.D̂d  that correspond to  measured outputs mathbfy^m.\n\n\n\n\n\ninit_estimate!(estim::StateEstimator, model::SimModel, _ , _ , _ )\n\nLeft estim.x̂0 estimate unchanged if model is not a LinModel.\n\n\n\n\n\ninit_estimate!(estim::InternalModel, model::LinModel, y0m, d0, u0)\n\nInit estim.x̂0/x̂d/x̂s estimate at steady-state for InternalModel.\n\nThe deterministic estimates estim.x̂d start at steady-state using u0 and d0 arguments:\n\n    mathbfx̂_d = mathbf(I - A)^-1 (B_u u_0 + B_d d_0 + f_op - x_op)\n\nBased on y0m argument and current stochastic outputs estimation mathbfŷ_s, composed of the measured mathbfŷ_s^m = mathbfy_0^m - mathbfŷ_d0^m and unmeasured  mathbfŷ_s^u = 0 outputs, the stochastic estimates also start at steady-state:\n\n    mathbfx̂_s = mathbf(I - Â_s)^-1 B̂_s ŷ_s\n\nThis estimator does not augment the state vector, thus mathbfx̂ = x̂_d. See init_internalmodel for details.\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.correct_estimate!","page":"State Estimators","title":"ModelPredictiveControl.correct_estimate!","text":"correct_estimate!(estim::SteadyKalmanFilter, y0m, d0)\n\nCorrect estim.x̂0 with measured outputs y0m and disturbances d0 for current time step.\n\nIt computes the corrected state estimate mathbfx̂_k(k). See the docstring of update_estimate!(::SteadyKalmanFilter, ::Any, ::Any) for the equations.\n\n\n\n\n\ncorrect_estimate!(estim::KalmanFilter, y0m, d0)\n\nCorrect estim.x̂0 and estim.cov.P̂ using the time-varying KalmanFilter.\n\nIt computes the corrected state estimate mathbfx̂_k(k) estimation covariance  mathbfP̂_k(k).\n\n\n\n\n\ncorrect_estimate!(estim::UnscentedKalmanFilter, y0m, d0)\n\nDo the same but for the UnscentedKalmanFilter.\n\n\n\n\n\ncorrect_estimate!(estim::ExtendedKalmanFilter, y0m, d0)\n\nDo the same but for the ExtendedKalmanFilter.\n\n\n\n\n\ncorrect_estimate!(estim::Luenberger, y0m, d0, _ )\n\nIdentical to correct_estimate!(::SteadyKalmanFilter) but using Luenberger.\n\n\n\n\n\ncorrect_estimate!(estim::MovingHorizonEstimator, y0m, d0)\n\nDo the same but for MovingHorizonEstimator objects.\n\n\n\n\n\ncorrect_estimate!(estim::InternalModel, y0m, d0)\n\nCompute the current stochastic output estimation ŷs for InternalModel.\n\n\n\n\n\n","category":"function"},{"location":"internals/state_estim/#ModelPredictiveControl.update_estimate!","page":"State Estimators","title":"ModelPredictiveControl.update_estimate!","text":"update_estimate!(estim::SteadyKalmanFilter, y0m, d0, u0)\n\nUpdate estim.x̂0 estimate with current inputs u0, measured outputs y0m and dist. d0.\n\nIf estim.direct == false, the SteadyKalmanFilter first corrects the state estimate with the precomputed Kalman gain mathbfK̂. Afterward, it predicts the next state with the augmented process model. The correction step is skipped if direct == true since it is already done by the user through the preparestate! function (that calls correct_estimate!). The correction and prediction step equations are provided below.\n\nCorrection Step\n\nmathbfx̂_k(k) = mathbfx̂_k-1(k) + mathbfK̂mathbfy^m(k) - mathbfĈ^m x̂_k-1(k)\n                                                                   - mathbfD̂_d^m d(k)    \n\nPrediction Step\n\nmathbfx̂_k(k+1) = mathbfÂ x̂_k(k) + mathbfB̂_u u(k) + mathbfB̂_d d(k) \n\n\n\n\n\nupdate_estimate!(estim::KalmanFilter, y0m, d0, u0)\n\nUpdate KalmanFilter state estim.x̂0 and estimation error covariance estim.cov.P̂.\n\nIt implements the classical time-varying Kalman Filter based on the process model described in SteadyKalmanFilter. If estim.direct == false, it first corrects the estimate before predicting the next state. The correction step is skipped if estim.direct == true since it's already done by the user. The correction and prediction step equations are provided below, see [2] for details.\n\nCorrection Step\n\nbeginaligned\n    mathbfM̂(k)     = mathbfĈ^m P̂_k-1(k)mathbfĈ^m + mathbfR̂                        \n    mathbfK̂(k)     = mathbfP̂_k-1(k)mathbfĈ^mmathbfM̂^-1(k)                       \n    mathbfŷ^m(k)   = mathbfĈ^m x̂_k-1(k) + mathbfD̂_d^m d(k)                            \n    mathbfx̂_k(k) = mathbfx̂_k-1(k) + mathbfK̂(k)mathbfy^m(k) - mathbfŷ^m(k)   \n    mathbfP̂_k(k) = mathbfI - K̂(k)mathbfĈ^mmathbfP̂_k-1(k)\nendaligned\n\nPrediction Step\n\nbeginaligned\n    mathbfx̂_k(k+1) = mathbfÂ x̂_k(k) + mathbfB̂_u u(k) + mathbfB̂_d d(k)      \n    mathbfP̂_k(k+1) = mathbfÂ P̂_k(k)mathbfÂ + mathbfQ̂\nendaligned\n\n[2]: \"Kalman Filter\", Wikipedia: The Free Encyclopedia,   https://en.wikipedia.org/wiki/Kalman_filter, Accessed 2024-08-08.\n\n\n\n\n\nupdate_estimate!(estim::UnscentedKalmanFilter, y0m, d0, u0)\n\nUpdate UnscentedKalmanFilter state estim.x̂0 and covariance estimate estim.cov.P̂.\n\nIt implements the unscented Kalman Filter based on the generalized unscented transform[3]. See init_ukf for the definition of the constants mathbfm̂ Ŝ and γ. The superscript in e.g. mathbfX̂_k-1^j(k) refers the vector at the jth column of  mathbfX̂_k-1(k). The symbol mathbf0 is a vector with zeros. The number of sigma points is n_σ = 2 n_mathbfx̂ + 1. The matrices sqrtmathbfP̂_k-1(k) and sqrtmathbfP̂_k(k) are the the lower triangular factors of cholesky results. The correction and prediction step equations are provided below. The correction step is skipped if estim.direct == true since it's already done by the user.\n\nCorrection Step\n\nbeginaligned\n    mathbfX̂_k-1(k) = biggbeginmatrix mathbfx̂_k-1(k)  mathbfx̂_k-1(k)  cdots  mathbfx̂_k-1(k)  endmatrixbigg + biggbeginmatrix mathbf0  γ sqrtmathbfP̂_k-1(k)  -γ sqrtmathbfP̂_k-1(k) endmatrixbigg \n    mathbfŶ^m(k)     = biggbeginmatrix mathbfĥ^mBig( mathbfX̂_k-1^1(k) Big)  mathbfĥ^mBig( mathbfX̂_k-1^2(k) Big)  cdots  mathbfĥ^mBig( mathbfX̂_k-1^n_σ(k) Big) endmatrixbigg \n    mathbfŷ^m(k)     = mathbfŶ^m(k) mathbfm̂ \n    mathbfX̄_k-1(k) = beginbmatrix mathbfX̂_k-1^1(k) - mathbfx̂_k-1(k)  mathbfX̂_k-1^2(k) - mathbfx̂_k-1(k)  cdots  mathbfX̂_k-1^n_σ(k) - mathbfx̂_k-1(k) endbmatrix \n    mathbfȲ^m(k)     = beginbmatrix mathbfŶ^m^1(k)     - mathbfŷ^m(k)      mathbfŶ^m^2(k)     - mathbfŷ^m(k)      cdots  mathbfŶ^m^n_σ(k)     - mathbfŷ^m(k)     endbmatrix \n    mathbfM̂(k)       = mathbfȲ^m(k) mathbfŜ mathbfȲ^m(k) + mathbfR̂ \n    mathbfK̂(k)       = mathbfX̄_k-1(k) mathbfŜ mathbfȲ^m(k) mathbfM̂^-1(k) \n    mathbfx̂_k(k)     = mathbfx̂_k-1(k) + mathbfK̂(k) big mathbfy^m(k) - mathbfŷ^m(k) big \n    mathbfP̂_k(k)     = mathbfP̂_k-1(k) - mathbfK̂(k) mathbfM̂(k) mathbfK̂(k) \nendaligned \n\nPrediction Step\n\nbeginaligned\n    mathbfX̂_k(k)     = biggbeginmatrix mathbfx̂_k(k)  mathbfx̂_k(k)  cdots  mathbfx̂_k(k) endmatrixbigg + biggbeginmatrix mathbf0  gamma sqrtmathbfP̂_k(k)  - gamma sqrtmathbfP̂_k(k) endmatrixbigg \n    mathbfX̂_k(k+1) = biggbeginmatrix mathbff̂Big( mathbfX̂_k^1(k) mathbfu(k) mathbfd(k) Big)  mathbff̂Big( mathbfX̂_k^2(k) mathbfu(k) mathbfd(k) Big)  cdots  mathbff̂Big( mathbfX̂_k^n_σ(k) mathbfu(k) mathbfd(k) Big) endmatrixbigg \n    mathbfx̂_k(k+1) = mathbfX̂_k(k+1)mathbfm̂ \n    mathbfX̄_k(k+1)   = beginbmatrix mathbfX̂_k^1(k+1) - mathbfx̂_k(k+1)  mathbfX̂_k^2(k+1) - mathbfx̂_k(k+1)  cdots  mathbfX̂_k^n_σ(k+1) - mathbfx̂_k(k+1) endbmatrix \n    mathbfP̂_k(k+1)   = mathbfX̄_k(k+1) mathbfŜ mathbfX̄_k(k+1) + mathbfQ̂\nendaligned\n\n[3]: Simon, D. 2006, \"Chapter 14: The unscented Kalman filter\" in \"Optimal State Estimation:   Kalman, H∞, and Nonlinear Approaches\", John Wiley & Sons, p. 433–459, https://doi.org/10.1002/0470045345.ch14,   ISBN9780470045343.\n\n\n\n\n\nupdate_estimate!(estim::ExtendedKalmanFilter, y0m, d0, u0)\n\nUpdate ExtendedKalmanFilter state estim.x̂0 and covariance estim.cov.P̂.\n\nThe equations are similar to update_estimate!(::KalmanFilter) but with the  substitutions mathbfĈ^m = Ĥ^m(k) and mathbfÂ = F̂(k), the Jacobians of the augmented process model:\n\nbeginaligned\n    mathbfĤ(k) = left fracmathbfĥ(mathbfx̂ mathbfd)mathbfx̂             right_mathbfx̂ = x̂_k-1(k) mathbfd = d(k)   \n    mathbfF̂(k) = left fracmathbff̂(mathbfx̂ mathbfu mathbfd)mathbfx̂ right_mathbfx̂ = x̂_k(k)   mathbfu = u(k) mathbfd = d(k)\nendaligned\n\nThe matrix mathbfĤ^m is the rows of mathbfĤ that are measured outputs. The Jacobians are computed with ForwardDiff by default. The correction and prediction step equations are provided below. The correction step is skipped if  estim.direct == true since it's already done by the user.\n\nCorrection Step\n\nbeginaligned\n    mathbfŜ(k)     = mathbfĤ^m(k)mathbfP̂_k-1(k)mathbfĤ^m(k) + mathbfR̂             \n    mathbfK̂(k)     = mathbfP̂_k-1(k)mathbfĤ^m(k)mathbfŜ^-1(k)                       \n    mathbfŷ^m(k)   = mathbfĥ^mBig( mathbfx̂_k-1(k) mathbfd(k) Big)                  \n    mathbfx̂_k(k) = mathbfx̂_k-1(k) + mathbfK̂(k)mathbfy^m(k) - mathbfŷ^m(k)      \n    mathbfP̂_k(k) = mathbfI - K̂(k)mathbfĤ^m(k)mathbfP̂_k-1(k)\nendaligned\n\nPrediction Step\n\nbeginaligned\n    mathbfx̂_k(k+1) = mathbff̂Big( mathbfx̂_k(k) mathbfu(k) mathbfd(k) Big)   \n    mathbfP̂_k(k+1) = mathbfF̂(k)mathbfP̂_k(k)mathbfF̂(k) + mathbfQ̂\nendaligned\n\n\n\n\n\nupdate_estimate!(estim::Luenberger, y0m, d0, u0)\n\nSame than update_estimate!(::SteadyKalmanFilter) but using Luenberger.\n\n\n\n\n\nupdate_estimate!(estim::MovingHorizonEstimator, y0m, d0, u0)\n\nUpdate MovingHorizonEstimator state estim.x̂0.\n\nThe optimization problem of MovingHorizonEstimator documentation is solved if estim.direct is false (otherwise solved in correct_estimate!). The prediction matrices are provided at init_predmat_mhe documentation. Once solved, the optimal estimate mathbfx̂_k(k+p) is computed by inserting the optimal values of  mathbfx̂_k(k-N_k+p) and mathbfŴ in the augmented model from j = N_k-1 to 0 inclusively. Afterward, if N_k = H_e, the arrival covariance for the next time step mathbfP̂_k-N_k(k-N_k+1) is estimated using estim.covestim object. It also stores u0 at estim.lastu0, so it can be added to the data window at the next time step in correct_estimate!.\n\n\n\n\n\nupdate_estimate!(estim::InternalModel, _ , d0, u0)\n\nUpdate estim.x̂0/x̂d/x̂s with current inputs u0, measured outputs y0m and dist. d0.\n\nThe InternalModel updates the deterministic x̂d and stochastic x̂s estimates with:\n\nbeginaligned\n    mathbfx̂_d(k+1) = mathbffBig( mathbfx̂_d(k) mathbfu(k) mathbfd(k) Big) \n    mathbfx̂_s(k+1) = mathbfÂ_s x̂_s(k) + mathbfB̂_s ŷ_s(k)\nendaligned\n\nThis estimator does not augment the state vector, thus mathbfx̂ = x̂_d. See  init_internalmodel for details. \n\n\n\n\n\nupdate_estimate!(estim::ManualEstimator, y0m, d0, u0)\n\nDo nothing for ManualEstimator.\n\n\n\n\n\n","category":"function"},{"location":"manual/nonlinmpc/#man_nonlin","page":"Nonlinear Design","title":"Manual: Nonlinear Design","text":"Pages = [\"nonlinmpc.md\"]","category":"section"},{"location":"manual/nonlinmpc/#Nonlinear-Model","page":"Nonlinear Design","title":"Nonlinear Model","text":"In this example, the goal is to control the angular position θ of a pendulum attached to a motor. Knowing that the manipulated input is the motor torque τ in Nm, the I/O vectors are:\n\nbeginaligned\n    mathbfu = τ \n    mathbfy = θ\nendaligned\n\nThe following figure presents the system:\n\n<p><img src=\"../../assets/pendulum.svg\" alt=\"pendulum\" width=200 style=\"background-color:white; \n    border:20px solid white; display: block; margin-left: auto; margin-right: auto;\"/></p>\n\nThe plant model is nonlinear:\n\nbeginaligned\n    dotθ(t) = ω(t) \n    dotω(t) = -fracgLsinbig( θ(t) big) - fracKm ω(t) + frac1m L^2 τ(t)\nendaligned\n\nin which g is the gravitational acceleration in m/s², L, the pendulum length in m, K, the friction coefficient at the pivot point in kg/s, and m, the mass attached at the end of the pendulum in kg, all bundled in the parameter vector mathbfp = beginsmallmatrix g  L  K  m endsmallmatrix. The NonLinModel constructor assumes by default that the state function f is continuous in time, that is, an ordinary differential equation system (like here):\n\nusing ModelPredictiveControl\nfunction f(x, u, _ , p)\n    g, L, K, m = p          # [m/s²], [m], [kg/s], [kg]\n    θ, ω = x[1], x[2]       # [rad], [rad/s]\n    τ  = u[1]               # [Nm]\n    dθ = ω\n    dω = -g/L*sin(θ) - K/m*ω + τ/m/L^2\n    return [dθ, dω]\nend\nh(x, _ , _ ) = [180/π*x[1]] # [°]\np_model = [9.8, 0.4, 1.2, 0.3]\nnu, nx, ny, Ts = 1, 2, 1, 0.1\nvu, vx, vy = [\"\\$τ\\$ (Nm)\"], [\"\\$θ\\$ (rad)\", \"\\$ω\\$ (rad/s)\"], [\"\\$θ\\$ (°)\"]\nmodel = setname!(NonLinModel(f, h, Ts, nu, nx, ny; p=p_model); u=vu, x=vx, y=vy)\n\nThe output function mathbfh converts the θ angle to degrees. Note that special characters like θ can be typed in the Julia REPL or VS Code by typing \\theta and pressing the <TAB> key. The parameter p can be of any type but use a mutable type like a vector of you want to modify it later. A 4th order RungeKutta method solves the differential equations by default. It is good practice to first simulate model using sim! as a quick sanity check:\n\nusing Plots\nu = [0.5]\nN = 35\nres = sim!(model, N, u)\nplot(res, plotu=false)\nsavefig(\"plot1_NonLinMPC.svg\"); nothing # hide\n\n(Image: plot1_NonLinMPC)\n\nThe setname! function allows customized Y-axis labels. The available plotting options are detailed in the documentation of the corresponding plot method.","category":"section"},{"location":"manual/nonlinmpc/#Nonlinear-Model-Predictive-Controller","page":"Nonlinear Design","title":"Nonlinear Model Predictive Controller","text":"An UnscentedKalmanFilter estimates the plant state :\n\nα=0.01; σQ=[0.1, 1.0]; σR=[5.0]; nint_u=[1]; σQint_u=[0.1]\nestim = UnscentedKalmanFilter(model; α, σQ, σR, nint_u, σQint_u)\n\nThe vectors σQ and σR are the standard deviations of the process and sensor noises, respectively. The value for the velocity ω is higher here (σQ second value) since dotω(t) equation includes an uncertain parameter: the friction coefficient K. Also, the argument nint_u explicitly adds one integrating state at the model input, the motor torque τ, with an associated standard deviation σQint_u of 0.1 N m. The estimator tuning is tested on a plant with a 25 % larger friction coefficient K:\n\np_plant = copy(p_model)\np_plant[3] = 1.25*p_model[3]\nplant = setname!(NonLinModel(f, h, Ts, nu, nx, ny; p=p_plant); u=vu, x=vx, y=vy)\nres = sim!(estim, N, [0.5], plant=plant, y_noise=[0.5])\nplot(res, plotu=false, plotxwithx̂=true)\nsavefig(\"plot2_NonLinMPC.svg\"); nothing # hide\n\n(Image: plot2_NonLinMPC)\n\nThe estimate x̂_3 is the integrating state on the torque τ that compensates for static errors. The Kalman filter performance seems sufficient for control.\n\nAs the motor torque is limited to -1.5 to 1.5 N m, we incorporate the input constraints in a NonLinMPC:\n\nHp, Hc, Mwt, Nwt = 20, 2, [0.5], [2.5]\nnmpc = NonLinMPC(estim; Hp, Hc, Mwt, Nwt, Cwt=Inf)\numin, umax = [-1.5], [+1.5]\nnmpc = setconstraint!(nmpc; umin, umax)\n\nThe option Cwt=Inf disables the slack variable ϵ for constraint softening. By default, NonLinMPC controllers use Ipopt and a direct SingleShooting transcription method to solve the optimal control problem. We test mpc performance on plant by imposing an angular setpoint of 180° (inverted position):\n\nusing JuMP; unset_time_limit_sec(nmpc.optim) # hide\nres_ry = sim!(nmpc, N, [180.0], plant=plant, x_0=[0, 0], x̂_0=[0, 0, 0])\nplot(res_ry)\nsavefig(\"plot3_NonLinMPC.svg\"); nothing # hide\n\n(Image: plot3_NonLinMPC)\n\nThe controller seems robust enough to variations on K coefficient. Starting from this inverted position, the closed-loop response to a step disturbances of 10° is also satisfactory:\n\nres_yd = sim!(nmpc, N, [180.0], plant=plant, x_0=[π, 0], x̂_0=[π, 0, 0], y_step=[10])\nplot(res_yd)\nsavefig(\"plot4_NonLinMPC.svg\"); nothing # hide\n\n(Image: plot4_NonLinMPC)\n\nSee sim! documentation for details on the possible simulation scenarios.","category":"section"},{"location":"manual/nonlinmpc/#Economic-Model-Predictive-Controller","page":"Nonlinear Design","title":"Economic Model Predictive Controller","text":"Economic MPC can achieve the same objective but with lower economical costs. For this case study, the controller will aim to reduce the energy consumed by the motor. The power in watt transmitted by the motor to the pendulum is:\n\nP(t) = τ(t) ω(t)\n\nThus, the work in joule done by the motor from t = t_0 to t_end is:\n\nW = int_t_0^t_end P(t) mathrmdt = int_t_0^t_end τ(t) ω(t) mathrmdt\n\nWith the sampling time T_s in s, the prediction horizon H_p, the limits defined as t_0 = k T_s and t_end = (k+H_p) T_s, and the left-endpoint rectangle method for the integral, we get:\n\nW  T_s sum_j=0^H_p-1 τ(k + j) ω(k + j)\n\nThe objective function will now include an additive term that penalizes the work done by the motor W to reduce the energy consumption. Notice that W is a function of the manipulated input τ and the angular speed ω, a state that is not measured (only the angle θ is measured here). As the arguments of NonLinMPC economic function JE do not include the states, the speed is now defined as an unmeasured output to design a Kalman Filter similar to the previous one (mathbfy^m = θ and mathbfy^u = ω):\n\nh2(x, _ , _ ) = [180/π*x[1], x[2]]\nnu, nx, ny = 1, 2, 2\nmodel2 = setname!(NonLinModel(f, h2, Ts, nu, nx, ny; p=p_model), u=vu, x=vx, y=[vy; vx[2]])\nplant2 = setname!(NonLinModel(f, h2, Ts, nu, nx, ny; p=p_plant), u=vu, x=vx, y=[vy; vx[2]])\nestim2 = UnscentedKalmanFilter(model2; σQ, σR, nint_u, σQint_u, i_ym=[1])\n\nThe plant2 object based on h2 is also required since sim! expects that the output vector of plant argument corresponds to the model output vector in mpc argument. We can now define the J_E function and the empc controller:\n\nfunction JE(Ue, Ŷe, _ , p)\n    Ts = p\n    τ, ω = Ue[1:end-1], Ŷe[2:2:end-1]\n    return Ts*sum(τ.*ω)\nend\nempc = NonLinMPC(estim2; Hp, Hc, Nwt, Mwt=[0.5, 0], Cwt=Inf, Ewt=3.5e3, JE=JE, p=Ts)\nempc = setconstraint!(empc; umin, umax)\n\nThe keyword argument Ewt weights the economic costs relative to the other terms in the objective function. The term must be large enough to be significant but a too high value can lead to a static error on the angle setpoint. The second element of Mwt is zero since the speed ω is not requested to track a setpoint. The closed-loop response to a 180° setpoint is similar:\n\nunset_time_limit_sec(empc.optim)    # hide\nres2_ry = sim!(empc, N, [180, 0], plant=plant2, x_0=[0, 0], x̂_0=[0, 0, 0])\nplot(res2_ry, ploty=[1])\nsavefig(\"plot5_NonLinMPC.svg\"); nothing # hide\n\n(Image: plot5_NonLinMPC)\n\nand the energy consumption is slightly lower:\n\nfunction calcW(res)\n    τ, ω = res.U_data[1, 1:end-1], res.X_data[2, 1:end-1]\n    return Ts*sum(τ.*ω)\nend\nDict(:W_nmpc => calcW(res_ry), :W_empc => calcW(res2_ry))\n\nAlso, for a 10° step disturbance:\n\nres2_yd = sim!(empc, N, [180; 0]; plant=plant2, x_0=[π, 0], x̂_0=[π, 0, 0], y_step=[10, 0])\nplot(res2_yd, ploty=[1])\nsavefig(\"plot6_NonLinMPC.svg\"); nothing # hide\n\n(Image: plot6_NonLinMPC)\n\nthe new controller is able to recuperate a little more energy from the pendulum (i.e. negative work):\n\nDict(:W_nmpc => calcW(res_yd), :W_empc => calcW(res2_yd))\n\nOf course, this gain is only exploitable if the motor electronic includes some kind of regenerative circuitry.","category":"section"},{"location":"manual/nonlinmpc/#Custom-Nonlinear-Inequality-Constraints","page":"Nonlinear Design","title":"Custom Nonlinear Inequality Constraints","text":"In addition to the torque limits, suppose that the motor can deliver a maximum of 3 watt:\n\nP(t) = τ(t) ω(t)  P_mathrmmax\n\nwith P_mathrmmax = 3 W. This inequality describes nonlinear constraints that can be implemented using the custom mathbfg_c function of NonLinMPC. The constructor expects a function in this form:\n\nmathbfg_c(mathbfU_e mathbfŶ_e mathbfD̂_e mathbfp ϵ)  mathbf0\n\nin which ϵ is the slack variable (scalar), an necessary feature to ensure feasibility when the nonlinear inequality constraints are active. There is also an additional LHS argument (\"left-hand side\" of the inequality above) for the in-place version:\n\nfunction gc!(LHS, Ue, Ŷe, _, p, ϵ)\n    Pmax = p\n    i_τ, i_ω = 1, 2\n    for i in eachindex(LHS)\n        τ, ω = Ue[i_τ], Ŷe[i_ω]\n        P = τ*ω \n        LHS[i] = P - Pmax - ϵ\n        i_τ += 1\n        i_ω += 2\n    end\n    return nothing\nend\nnothing # hide\n\nHere we implemented the custom nonlinear constraint function in the mutating form to reduce the computational burden (see NonLinMPC Extended Help for details). Note that similar mutating forms are also possible for the f and h functions of NonLinModel. We construct the controller by enabling relaxation with the Cwt argument, and also by specifying the number of custom inequality constraints nc:\n\nCwt, Pmax, nc = 1e5, 3, Hp+1\nnmpc2 = NonLinMPC(estim2; Hp, Hc, Nwt=Nwt, Mwt=[0.5, 0], Cwt, gc!, nc, p=Pmax)\nnmpc2 = setconstraint!(nmpc2; umin, umax)\nusing JuMP; unset_time_limit_sec(nmpc2.optim) # hide\nnmpc2 # hide\n\nIn addition to the 180° setpoint response:\n\nusing Logging # hide\nres3_ry = with_logger(ConsoleLogger(stderr, Error)) do # hide\nres3_ry = sim!(nmpc2, N, [180; 0]; plant=plant2, x_0=[0, 0], x̂_0=[0, 0, 0]);\nend # hide\nnothing # hide\n\na plot for the power P(t) is included below:\n\nfunction plotWithPower(res, Pmax)\n    t, τ, ω = res.T_data, res.U_data[1, :], res.X_data[2, :]\n    P, Pmax = τ.*ω, fill(Pmax, size(t))\n    plt1 = plot(res, ploty=[1])\n    plt2 = plot(t, P, label=raw\"$P$\", ylabel=raw\"$P$ (W)\", xlabel=\"Time (s)\", legend=:right)\n    plot!(plt2, t, Pmax, label=raw\"$P_\\mathrm{max}$\", linestyle=:dot, linewidth=1.5)\n    return plot(plt1, plt2, layout=(2,1))\nend\nplotWithPower(res3_ry, Pmax)\nsavefig(\"plot7_NonLinMPC.svg\"); nothing # hide\n\n(Image: plot7_NonLinMPC)\n\nThe controller is able to find a solution that does not violate the torque and power constraints.","category":"section"},{"location":"manual/nonlinmpc/#Model-Linearization","page":"Nonlinear Design","title":"Model Linearization","text":"Nonlinear MPC is more computationally expensive than LinMPC. Solving the problem should always be faster than the sampling time T_s = 01 s for real-time operation. This requirement is sometimes hard to meet on electronics or mechanical systems because of the fast dynamics. To ease the design and comparison with LinMPC, the linearize function allows automatic linearization of NonLinModel defaulting to ForwardDiff. We first linearize model at the point θ = π rad and ω = τ = 0 (inverted position):\n\nlinmodel = linearize(model, x=[π, 0], u=[0])\n\nA SteadyKalmanFilter and a LinMPC are designed from linmodel:\n\nskf = SteadyKalmanFilter(linmodel; σQ, σR, nint_u, σQint_u)\nmpc = LinMPC(skf; Hp, Hc, Mwt, Nwt, Cwt=Inf)\nmpc = setconstraint!(mpc, umin=[-1.5], umax=[+1.5])\n\nThe linear controller satisfactorily rejects the 10° step disturbance:\n\nres_lin = sim!(mpc, N, [180.0]; plant, x_0=[π, 0], y_step=[10])\nplot(res_lin)\nsavefig(\"plot9_NonLinMPC.svg\"); nothing # hide\n\n(Image: plot9_NonLinMPC)\n\nSolving the optimization problem of mpc with DAQP optimizer instead of the default OSQP solver can improve the performance here. It is indeed documented that DAQP can perform better on small/medium dense matrices and unstable poles[1], which is obviously the case here (absolute value of unstable poles are greater than one):\n\n[1]: Arnström, D., Bemporad, A., and Axehill, D. (2022). A dual active-set solver for embedded quadratic programming using recursive LDLᵀ updates. IEEE Trans. Autom. Contr., 67(8). https://doi.org/doi:10.1109/TAC.2022.3176430.\n\nusing LinearAlgebra; poles = eigvals(linmodel.A)\n\nTo install the solver, run:\n\nusing Pkg; Pkg.add(\"DAQP\")\n\nConstructing a LinMPC with DAQP:\n\nusing JuMP, DAQP\ndaqp = Model(DAQP.Optimizer, add_bridges=false)\nmpc2 = LinMPC(skf; Hp, Hc, Mwt, Nwt, Cwt=Inf, optim=daqp)\nmpc2 = setconstraint!(mpc2; umin, umax)\n\ndoes slightly improve the rejection of the step disturbance:\n\nres_lin2 = sim!(mpc2, N, [180.0]; plant, x_0=[π, 0], y_step=[10])\nplot(res_lin2)\nsavefig(\"plot10_NonLinMPC.svg\"); nothing # hide\n\n(Image: plot10_NonLinMPC)\n\nAdditionally, similar results are obtained by using a sparse MultipleShooting transcription, which is known to be more robust for unstable systems, with a solver that can explicilty handle sparsity like the default OSQP:\n\nmpc_ms = LinMPC(skf; Hp, Hc, Mwt, Nwt, Cwt=Inf, transcription=MultipleShooting())\nmpc_ms = setconstraint!(mpc_ms, umin=[-1.5], umax=[+1.5])\n\nSuperimposing the previous disturbance rejection to the newer one gives almost identical results:\n\nres_ms = sim!(mpc_ms, N, [180.0]; plant, x_0=[π, 0], y_step=[10])\nplot!(res_ms)\nsavefig(\"plot10b_NonLinMPC.svg\"); nothing # hide\n\n(Image: plot10b_NonLinMPC)\n\nThe closed-loop performances are still lower than the nonlinear controller, as expected, but computations are about 210 times faster (0.000071 s versus 0.015 s per time steps, on average). However, remember that linmodel is only valid for angular positions near 180°. For example, the 180° setpoint response from 0° is unsatisfactory since the predictions are poor in the first quadrant:\n\nres_lin3 = sim!(mpc2, N, [180.0]; plant, x_0=[0, 0])\nplot(res_lin3)\nsavefig(\"plot11_NonLinMPC.svg\"); nothing # hide\n\n(Image: plot11_NonLinMPC)\n\nMultiple linearized model and controller objects are required for large deviations from this operating point. This is known as gain scheduling. Another approach is adapting the model of the LinMPC instance based on repeated online linearization.","category":"section"},{"location":"manual/nonlinmpc/#Adapting-the-Model-via-Successive-Linearization","page":"Nonlinear Design","title":"Adapting the Model via Successive Linearization","text":"The setmodel! method allows online adaptation of a linear plant model. Combined with the automatic linearization of linearize, a successive linearization MPC can be designed with minimal efforts. The SteadyKalmanFilter does not support setmodel! so we need to use the time-varying KalmanFilter, and we initialize it with a linearization at θ = ω = τ = 0:\n\nlinmodel = linearize(model, x=[0, 0], u=[0])\nkf = KalmanFilter(linmodel; σQ, σR, nint_u, σQint_u)\nmpc3 = LinMPC(kf; Hp, Hc, Mwt, Nwt, Cwt=Inf, optim=daqp)\nmpc3 = setconstraint!(mpc3; umin, umax)\n\nWe create a function that simulates the plant and the adaptive controller:\n\nfunction sim_adapt!(mpc, nonlinmodel, N, ry, plant, x_0, x̂_0, y_step=[0])\n    U_data, Y_data, Ry_data = zeros(plant.nu, N), zeros(plant.ny, N), zeros(plant.ny, N)\n    setstate!(plant, x_0)\n    initstate!(mpc, [0], plant())\n    setstate!(mpc, x̂_0)\n    for i = 1:N\n        y = plant() + y_step\n        x̂ = preparestate!(mpc, y)\n        u = moveinput!(mpc, ry)\n        linmodel = linearize(nonlinmodel; u, x=x̂[1:2])\n        setmodel!(mpc, linmodel)\n        U_data[:,i], Y_data[:,i], Ry_data[:,i] = u, y, ry\n        updatestate!(mpc, u, y) # update mpc state estimate\n        updatestate!(plant, u)  # update plant simulator\n    end\n    res = SimResult(mpc, U_data, Y_data; Ry_data)\n    return res\nend\nnothing # hide\n\nThe setmodel! method must be called after solving the optimization problem with moveinput! and before updating the state estimate with updatestate!, that is, when both mathbfu(k) and mathbfx̂_k(k) are available as the new operating point. The SimResult object is for plotting purposes only. The adaptive LinMPC performances are similar to the nonlinear MPC, both for the 180° setpoint:\n\nx_0 = [0, 0]; x̂_0 = [0, 0, 0]; ry = [180]\nres_slin = sim_adapt!(mpc3, model, N, ry, plant, x_0, x̂_0)\nplot(res_slin)\nsavefig(\"plot12_NonLinMPC.svg\"); nothing # hide\n\n(Image: plot12_NonLinMPC)\n\nand the 10° step disturbance:\n\nx_0 = [π, 0]; x̂_0 = [π, 0, 0]; y_step = [10]\nres_slin = sim_adapt!(mpc3, model, N, ry, plant, x_0, x̂_0, y_step)\nplot(res_slin)\nsavefig(\"plot13_NonLinMPC.svg\"); nothing # hide\n\n(Image: plot13_NonLinMPC)\n\nThe computations of the successive linearization MPC are about 75 times faster than the nonlinear MPC on average, an impressive gain for similar closed-loop performances!","category":"section"},{"location":"public/state_estim/#Functions:-State-Estimators","page":"State Estimators","title":"Functions: State Estimators","text":"Pages = [\"state_estim.md\"]\n\nThis module includes many state estimators (or state observer), both for deterministic and stochastic systems. The implementations focus on control applications, that is, relying on the estimates to compute a full state feedback (predictive controllers, in this package). They all incorporates some kind of integral action by default, since it is generally desired to eliminate the steady-state error with closed-loop control (offset-free tracking).\n\nwarning: Warning\nIf you plan to use the estimators for other contexts than this specific package (e.g. : filter, parameter estimation, etc.), careful must be taken at construction since the integral action is not necessarily desired. The options nint_u=0 and nint_ym=0 disable it.\n\nThe estimators are all implemented in the current form (a.k.a. as filter form) by default to improve accuracy and robustness, that is, they all estimates at each discrete time k the states of the current period mathbfx̂_k(k)[1] (using the newest measurements, see Manual for examples). The predictor form (a.k.a. delayed form) is also available with the option direct=false. This allow moving the estimator computations after solving the MPC problem with moveinput!, for when the estimations are expensive (for instance, with the MovingHorizonEstimator).\n\n[1]: also denoted mathbfx̂_kk elsewhere.\n\ninfo: Info\nThe nomenclature in this page introduces the estimated state mathbfx̂ and output mathbfŷ vectors of respectively nx̂ and ny elements. Also, all the estimators support measured mathbfy^m (nym elements) and unmeasured mathbfy^u (nyu elements) model output, where mathbfy refers to all of them.","category":"section"},{"location":"public/state_estim/#StateEstimator","page":"State Estimators","title":"StateEstimator","text":"","category":"section"},{"location":"public/state_estim/#SteadyKalmanFilter","page":"State Estimators","title":"SteadyKalmanFilter","text":"","category":"section"},{"location":"public/state_estim/#KalmanFilter","page":"State Estimators","title":"KalmanFilter","text":"","category":"section"},{"location":"public/state_estim/#Luenberger","page":"State Estimators","title":"Luenberger","text":"","category":"section"},{"location":"public/state_estim/#UnscentedKalmanFilter","page":"State Estimators","title":"UnscentedKalmanFilter","text":"","category":"section"},{"location":"public/state_estim/#ExtendedKalmanFilter","page":"State Estimators","title":"ExtendedKalmanFilter","text":"","category":"section"},{"location":"public/state_estim/#MovingHorizonEstimator","page":"State Estimators","title":"MovingHorizonEstimator","text":"","category":"section"},{"location":"public/state_estim/#InternalModel","page":"State Estimators","title":"InternalModel","text":"","category":"section"},{"location":"public/state_estim/#ManualEstimator","page":"State Estimators","title":"ManualEstimator","text":"","category":"section"},{"location":"public/state_estim/#Default-Model-Augmentation","page":"State Estimators","title":"Default Model Augmentation","text":"","category":"section"},{"location":"public/state_estim/#ModelPredictiveControl.StateEstimator","page":"State Estimators","title":"ModelPredictiveControl.StateEstimator","text":"Abstract supertype of all state estimators.\n\n\n\n(estim::StateEstimator)(d=[]) -> ŷ\n\nFunctor allowing callable StateEstimator object as an alias for evaloutput.\n\nExamples\n\njulia> kf = KalmanFilter(setop!(LinModel(tf(3, [10, 1]), 2), yop=[20]), direct=false);\n\njulia> ŷ = kf() \n1-element Vector{Float64}:\n 20.0\n\n\n\n\n\n","category":"type"},{"location":"public/state_estim/#ModelPredictiveControl.SteadyKalmanFilter","page":"State Estimators","title":"ModelPredictiveControl.SteadyKalmanFilter","text":"SteadyKalmanFilter(model::LinModel; <keyword arguments>)\n\nConstruct a steady-state Kalman Filter with the LinModel model.\n\nThe steady-state (or asymptotic) Kalman filter is based on the process model:\n\nbeginaligned\n    mathbfx(k+1) = \n            mathbfÂ x(k) + mathbfB̂_u u(k) + mathbfB̂_d d(k) + mathbfw(k) \n    mathbfy^m(k) = mathbfĈ^m x(k) + mathbfD̂_d^m d(k) + mathbfv(k) \n    mathbfy^u(k) = mathbfĈ^u x(k) + mathbfD̂_d^u d(k)\nendaligned\n\nwith sensor mathbfv(k) and process mathbfw(k) noises as uncorrelated zero mean  white noise vectors, with a respective covariance of mathbfR̂ and mathbfQ̂.  The arguments are in standard deviations σ, i.e. same units than outputs and states. The  matrices mathbfÂ B̂_u B̂_d Ĉ D̂_d are model matrices augmented with the stochastic model, which is specified by the numbers of integrator nint_u and nint_ym (see Extended Help). Likewise, the covariance matrices are augmented with mathbfQ̂ = textdiag(Q  Q_int_u Q_int_ym) and mathbfR̂ = R. The Extended Help provide some guidelines on the covariance tuning. The matrices mathbfĈ^m D̂_d^m are the rows of  mathbfĈ D̂_d that correspond to measured outputs mathbfy^m (and unmeasured ones, for mathbfĈ^u D̂_d^u). The Kalman filter will estimate the current state with  the newest measurements mathbfx̂_k(k) if direct is true, else it will predict the state of the next time step mathbfx̂_k(k+1). This estimator is allocation-free.\n\nArguments\n\ninfo: Info\nKeyword arguments with emphasis are non-Unicode alternatives.\n\nmodel::LinModel : (deterministic) model for the estimations.\ni_ym=1:model.ny : model output indices that are measured mathbfy^m, the rest    are unmeasured mathbfy^u.\nσQ=fill(1/model.nx,model.nx) or sigmaQ : main diagonal of the process noise   covariance mathbfQ of model, specified as a standard deviation vector.\nσR=fill(1,length(i_ym)) or sigmaR : main diagonal of the sensor noise covariance   mathbfR of model measured outputs, specified as a standard deviation vector.\nnint_u=0: integrator quantity for the stochastic model of the unmeasured disturbances at   the manipulated inputs (vector), use nint_u=0 for no integrator (see Extended Help).\nnint_ym=default_nint(model,i_ym,nint_u) : same than nint_u but for the unmeasured    disturbances at the measured outputs, use nint_ym=0 for no integrator (see Extended Help).\nσQint_u=fill(1,sum(nint_u)) or sigmaQint_u : same than σQ but for the unmeasured   disturbances at manipulated inputs mathbfQ_int_u (composed of integrators).\nσQint_ym=fill(1,sum(nint_ym)) or sigmaQint_u : same than σQ for the unmeasured   disturbances at measured outputs mathbfQ_int_ym (composed of integrators).\ndirect=true: construct with a direct transmission from mathbfy^m (a.k.a. current  estimator, in opposition to the delayed/predictor form).\n\nExamples\n\njulia> model = LinModel([tf(3, [30, 1]); tf(-2, [5, 1])], 0.5);\n\njulia> estim = SteadyKalmanFilter(model, i_ym=[2], σR=[1], σQint_ym=[0.01])\nSteadyKalmanFilter estimator with a sample time Ts = 0.5 s:\n├ model: LinModel\n└ dimensions:\n  ├ 1 manipulated inputs u (0 integrating states)\n  ├ 3 estimated states x̂\n  ├ 1 measured outputs ym (1 integrating states)\n  ├ 1 unmeasured outputs yu\n  └ 0 measured disturbances d\n\nExtended Help\n\ndetails: Extended Help\nThe σR argument is generally fixed at the estimated standard deviations of the sensor noises. The σQ, σQint_u and σQint_ym arguments can be used to tune the filter response. Increasing them make the filter more responsive to disturbances but more sensitive to measurement noise.The model augmentation with nint_u vector adds integrators at model manipulated inputs, and nint_ym, at measured outputs. They create the integral action when the estimator is used in a controller as state feedback. By default, the method default_nint adds one integrator per measured output if feasible. The argument nint_ym can also be tweaked by following these rules on each measured output:Use 0 integrator if the model output is already integrating (else it will be unobservable)\nUse 1 integrator if the disturbances on the output are typically \"step-like\"\nUse 2 integrators if the disturbances on the output are typically \"ramp-like\" The function init_estimstoch builds the stochastic model for estimation.tip: Tip\nIncreasing σQint_u and σQint_ym values increases the integral action \"gain\".Custom stochastic model for the unmeasured disturbances (different than integrated white gaussian noise) can be specified by constructing a LinModel object with the augmented state-space matrices directly, and by setting nint_u=0 and nint_ym=0. See Disturbance-gallery for examples of other disturbance models.The constructor pre-compute the steady-state Kalman gain K̂ with the kalman function. It can sometimes fail, for example when model matrices are ill-conditioned. In such a case, you can try the alternative time-varying KalmanFilter.\n\n\n\n\n\nSteadyKalmanFilter(model, i_ym, nint_u, nint_ym, Q̂, R̂; direct=true)\n\nConstruct the estimator from the augmented covariance matrices Q̂ and R̂.\n\nThis syntax allows nonzero off-diagonal elements in mathbfQ̂ R̂.\n\n\n\n\n\n","category":"type"},{"location":"public/state_estim/#ModelPredictiveControl.KalmanFilter","page":"State Estimators","title":"ModelPredictiveControl.KalmanFilter","text":"KalmanFilter(model::LinModel; <keyword arguments>)\n\nConstruct a time-varying Kalman Filter with the LinModel model.\n\nThe process model is identical to SteadyKalmanFilter. The matrix mathbfP̂ is the estimation error covariance of model states augmented with the stochastic ones (specified by nint_u and nint_ym). Three keyword arguments specify its initial value with mathbfP̂_-1(0) = mathrmdiag mathbfP(0) mathbfP_int_u(0)  mathbfP_int_ym(0) . The initial state estimate mathbfx̂_-1(0) can be manually specified with setstate!, or automatically with initstate!. This estimator is allocation-free.\n\nArguments\n\ninfo: Info\nKeyword arguments with emphasis are non-Unicode alternatives.\n\nmodel::LinModel : (deterministic) model for the estimations.\ni_ym=1:model.ny : model output indices that are measured mathbfy^m, the rest    are unmeasured mathbfy^u.\nσP_0=fill(1/model.nx,model.nx) or sigmaP_0 : main diagonal of the initial estimate   covariance mathbfP(0), specified as a standard deviation vector.\nσQ=fill(1/model.nx,model.nx) or sigmaQ : main diagonal of the process noise   covariance mathbfQ of model, specified as a standard deviation vector.\nσR=fill(1,length(i_ym)) or sigmaR : main diagonal of the sensor noise covariance   mathbfR of model measured outputs, specified as a standard deviation vector.\nnint_u=0: integrator quantity for the stochastic model of the unmeasured disturbances at   the manipulated inputs (vector), use nint_u=0 for no integrator.\nnint_ym=default_nint(model,i_ym,nint_u) : same than nint_u but for the unmeasured    disturbances at the measured outputs, use nint_ym=0 for no integrator.\nσQint_u=fill(1,sum(nint_u)) or sigmaQint_u : same than σQ but for the unmeasured   disturbances at manipulated inputs mathbfQ_int_u (composed of integrators).\nσPint_u_0=fill(1,sum(nint_u)) or sigmaPint_u_0 : same than σP_0 but for the unmeasured   disturbances at manipulated inputs mathbfP_int_u(0) (composed of integrators).\nσQint_ym=fill(1,sum(nint_ym)) or sigmaQint_u : same than σQ for the unmeasured   disturbances at measured outputs mathbfQ_int_ym (composed of integrators).\nσPint_ym_0=fill(1,sum(nint_ym)) or sigmaPint_ym_0 : same than σP_0 but for the unmeasured   disturbances at measured outputs mathbfP_int_ym(0) (composed of integrators).\ndirect=true: construct with a direct transmission from mathbfy^m (a.k.a. current  estimator, in opposition to the delayed/predictor form).\n\nExamples\n\njulia> model = LinModel([tf(3, [30, 1]); tf(-2, [5, 1])], 0.5);\n\njulia> estim = KalmanFilter(model, i_ym=[2], σR=[1], σP_0=[100, 100], σQint_ym=[0.01])\nKalmanFilter estimator with a sample time Ts = 0.5 s:\n├ model: LinModel\n└ dimensions:\n  ├ 1 manipulated inputs u (0 integrating states)\n  ├ 3 estimated states x̂\n  ├ 1 measured outputs ym (1 integrating states)\n  ├ 1 unmeasured outputs yu\n  └ 0 measured disturbances d\n\n\n\n\n\nKalmanFilter(model, i_ym, nint_u, nint_ym, P̂_0, Q̂, R̂; direct=true)\n\nConstruct the estimator from the augmented covariance matrices P̂_0, Q̂ and R̂.\n\nThis syntax allows nonzero off-diagonal elements in mathbfP̂_-1(0) mathbfQ̂ R̂.\n\n\n\n\n\n","category":"type"},{"location":"public/state_estim/#ModelPredictiveControl.Luenberger","page":"State Estimators","title":"ModelPredictiveControl.Luenberger","text":"Luenberger(\n    model::LinModel; \n    i_ym = 1:model.ny, \n    nint_u  = 0,\n    nint_ym = default_nint(model, i_ym),\n    poles = 1e-3*(1:(model.nx + sum(nint_u) + sum(nint_ym))) .+ 0.5,\n    direct = true\n)\n\nConstruct a Luenberger observer with the LinModel model.\n\ni_ym provides the model output indices that are measured mathbfy^m, the rest are unmeasured mathbfy^u. model matrices are augmented with the stochastic model, which is specified by the numbers of integrator nint_u and nint_ym (see SteadyKalmanFilter Extended Help). The argument poles is a vector of model.nx + sum(nint_u) + sum(nint_ym) elements specifying the observer poles/eigenvalues (near z=05 by default). The observer is constructed with a direct transmission from mathbfy^m if direct=true (a.k.a.  current observers, in opposition to the delayed/prediction form). The method computes the observer gain K̂ with place function. This estimator is allocation-free.\n\nExamples\n\njulia> model = LinModel([tf(3, [30, 1]); tf(-2, [5, 1])], 0.5);\n\njulia> estim = Luenberger(model, nint_ym=[1, 1], poles=[0.61, 0.62, 0.63, 0.64])\nLuenberger estimator with a sample time Ts = 0.5 s:\n├ model: LinModel\n└ dimensions:\n  ├ 1 manipulated inputs u (0 integrating states)\n  ├ 4 estimated states x̂\n  ├ 2 measured outputs ym (2 integrating states)\n  ├ 0 unmeasured outputs yu\n  └ 0 measured disturbances d\n\n\n\n\n\n","category":"type"},{"location":"public/state_estim/#ModelPredictiveControl.UnscentedKalmanFilter","page":"State Estimators","title":"ModelPredictiveControl.UnscentedKalmanFilter","text":"UnscentedKalmanFilter(model::SimModel; <keyword arguments>)\n\nConstruct an unscented Kalman Filter with the SimModel model.\n\nBoth LinModel and NonLinModel are supported. The unscented Kalman filter is based on the process model :\n\nbeginaligned\n    mathbfx(k+1) = mathbff̂Big(mathbfx(k) mathbfu(k) mathbfd(k)Big) \n                        + mathbfw(k)                                                   \n    mathbfy^m(k) = mathbfĥ^mBig(mathbfx(k) mathbfd(k)Big) + mathbfv(k) \n    mathbfy^u(k) = mathbfĥ^uBig(mathbfx(k) mathbfd(k)Big)                 \nendaligned\n\nSee SteadyKalmanFilter for details on mathbfv(k) mathbfw(k) noises and mathbfR̂ mathbfQ̂ covariances. The two matrices are constructed from mathbfQ̂ = textdiag(Q Q_int_u Q_int_ym) and mathbfR̂ = R. The functions mathbff̂ ĥ are model state-space functions augmented with the stochastic model of the unmeasured disturbances, which is specified by the numbers of integrator nint_u and nint_ym (see Extended Help). Model parameters mathbfp are not argument of mathbff̂ ĥ functions for conciseness. The mathbfĥ^m function represents the measured outputs of mathbfĥ function (and unmeasured ones, for mathbfĥ^u). The matrix mathbfP̂ is the estimation error covariance of model state augmented with the  stochastic ones. Three keyword arguments specify its initial value with mathbfP̂_-1(0) =  mathrmdiag mathbfP(0) mathbfP_int_u(0) mathbfP_int_ym(0) . The  initial state estimate mathbfx̂_-1(0) can be manually specified with setstate!. This estimator is allocation-free if model simulations do not allocate.\n\nArguments\n\ninfo: Info\nKeyword arguments with emphasis are non-Unicode alternatives.\n\nmodel::SimModel : (deterministic) model for the estimations.\ni_ym=1:model.ny : model output indices that are measured mathbfy^m, the rest    are unmeasured mathbfy^u.\nσP_0=fill(1/model.nx,model.nx) or sigmaP_0 : main diagonal of the initial estimate   covariance mathbfP(0), specified as a standard deviation vector.\nσQ=fill(1/model.nx,model.nx) or sigmaQ : main diagonal of the process noise   covariance mathbfQ of model, specified as a standard deviation vector.\nσR=fill(1,length(i_ym)) or sigmaR : main diagonal of the sensor noise covariance   mathbfR of model measured outputs, specified as a standard deviation vector.\nnint_u=0: integrator quantity for the stochastic model of the unmeasured disturbances at   the manipulated inputs (vector), use nint_u=0 for no integrator (see Extended Help).\nnint_ym=default_nint(model,i_ym,nint_u) : same than nint_u but for the unmeasured    disturbances at the measured outputs, use nint_ym=0 for no integrator (see Extended Help).\nσQint_u=fill(1,sum(nint_u)) or sigmaQint_u : same than σQ but for the unmeasured   disturbances at manipulated inputs mathbfQ_int_u (composed of integrators).\nσPint_u_0=fill(1,sum(nint_u)) or sigmaPint_u_0 : same than σP_0 but for the unmeasured   disturbances at manipulated inputs mathbfP_int_u(0) (composed of integrators).\nσQint_ym=fill(1,sum(nint_ym)) or sigmaQint_u : same than σQ for the unmeasured   disturbances at measured outputs mathbfQ_int_ym (composed of integrators).\nσPint_ym_0=fill(1,sum(nint_ym)) or sigmaPint_ym_0 : same than σP_0 but for the unmeasured   disturbances at measured outputs mathbfP_int_ym(0) (composed of integrators).\nα=1e-3 or alpha : alpha parameter, spread of the state distribution (0  α  1).\nβ=2 or beta : beta parameter, skewness and kurtosis of the states distribution (β  0).\nκ=0 or kappa : kappa parameter, another spread parameter (0  κ  3).\ndirect=true: construct with a direct transmission from mathbfy^m (a.k.a. current  estimator, in opposition to the delayed/predictor form).\n\nExamples\n\njulia> model = NonLinModel((x,u,_,_)->0.1x+u, (x,_,_)->2x, 10.0, 1, 1, 1, solver=nothing);\n\njulia> estim = UnscentedKalmanFilter(model, σR=[1], nint_ym=[2], σPint_ym_0=[1, 1])\nUnscentedKalmanFilter estimator with a sample time Ts = 10.0 s:\n├ model: NonLinModel\n└ dimensions:\n  ├ 1 manipulated inputs u (0 integrating states)\n  ├ 3 estimated states x̂\n  ├ 1 measured outputs ym (2 integrating states)\n  ├ 0 unmeasured outputs yu\n  └ 0 measured disturbances d\n\nExtended Help\n\ndetails: Extended Help\nThe Extended Help of SteadyKalmanFilter details the tuning of the covariances and the augmentation with nint_ym and nint_u arguments. The default augmentation scheme is identical, that is nint_u=0 and nint_ym computed by default_nint. Note that the constructor does not validate the observability of the resulting augmented NonLinModel. In such cases, it is the user's responsibility to ensure that it is still observable.\n\n\n\n\n\nUnscentedKalmanFilter(\n    model, i_ym, nint_u, nint_ym, P̂_0, Q̂, R̂, α=1e-3, β=2, κ=0; direct=true\n)\n\nConstruct the estimator from the augmented covariance matrices P̂_0, Q̂ and R̂.\n\nThis syntax allows nonzero off-diagonal elements in mathbfP̂_-1(0) mathbfQ̂ R̂.\n\n\n\n\n\n","category":"type"},{"location":"public/state_estim/#ModelPredictiveControl.ExtendedKalmanFilter","page":"State Estimators","title":"ModelPredictiveControl.ExtendedKalmanFilter","text":"ExtendedKalmanFilter(model::SimModel; <keyword arguments>)\n\nConstruct an extended Kalman Filter with the SimModel model.\n\nBoth LinModel and NonLinModel are supported. The process model is identical to UnscentedKalmanFilter. By default, the Jacobians of the augmented model mathbff̂ ĥ are computed with ForwardDiff automatic differentiation. This estimator is allocation-free if model simulations do not allocate.\n\nwarning: Warning\nSee the Extended Help of linearize function if you get an error like:     MethodError: no method matching (::var\"##\")(::Vector{ForwardDiff.Dual}).\n\nArguments\n\ninfo: Info\nKeyword arguments with emphasis are non-Unicode alternatives.\n\nmodel::SimModel : (deterministic) model for the estimations.\ni_ym=1:model.ny : model output indices that are measured mathbfy^m, the rest    are unmeasured mathbfy^u.\nσP_0=fill(1/model.nx,model.nx) or sigmaP_0 : main diagonal of the initial estimate   covariance mathbfP(0), specified as a standard deviation vector.\nσQ=fill(1/model.nx,model.nx) or sigmaQ : main diagonal of the process noise   covariance mathbfQ of model, specified as a standard deviation vector.\nσR=fill(1,length(i_ym)) or sigmaR : main diagonal of the sensor noise covariance   mathbfR of model measured outputs, specified as a standard deviation vector.\nnint_u=0: integrator quantity for the stochastic model of the unmeasured disturbances at   the manipulated inputs (vector), use nint_u=0 for no integrator.\nnint_ym=default_nint(model,i_ym,nint_u) : same than nint_u but for the unmeasured    disturbances at the measured outputs, use nint_ym=0 for no integrator.\nσQint_u=fill(1,sum(nint_u)) or sigmaQint_u : same than σQ but for the unmeasured   disturbances at manipulated inputs mathbfQ_int_u (composed of integrators).\nσPint_u_0=fill(1,sum(nint_u)) or sigmaPint_u_0 : same than σP_0 but for the unmeasured   disturbances at manipulated inputs mathbfP_int_u(0) (composed of integrators).\nσQint_ym=fill(1,sum(nint_ym)) or sigmaQint_u : same than σQ for the unmeasured   disturbances at measured outputs mathbfQ_int_ym (composed of integrators).\nσPint_ym_0=fill(1,sum(nint_ym)) or sigmaPint_ym_0 : same than σP_0 but for the unmeasured   disturbances at measured outputs mathbfP_int_ym(0) (composed of integrators).\njacobian=AutoForwardDiff(): an AbstractADType backend for the Jacobians of the augmented   model, see DifferentiationInterface doc.\ndirect=true: construct with a direct transmission from mathbfy^m (a.k.a. current  estimator, in opposition to the delayed/predictor form).\n\nExamples\n\njulia> model = NonLinModel((x,u,_,_)->0.2x+u, (x,_,_)->-3x, 5.0, 1, 1, 1, solver=nothing);\n\njulia> estim = ExtendedKalmanFilter(model, σQ=[2], σQint_ym=[2], σP_0=[0.1], σPint_ym_0=[0.1])\nExtendedKalmanFilter estimator with a sample time Ts = 5.0 s:\n├ model: NonLinModel\n├ jacobian: AutoForwardDiff\n└ dimensions:\n  ├ 1 manipulated inputs u (0 integrating states)\n  ├ 2 estimated states x̂\n  ├ 1 measured outputs ym (1 integrating states)\n  ├ 0 unmeasured outputs yu\n  └ 0 measured disturbances d\n\n\n\n\n\nExtendedKalmanFilter(\n    model, i_ym, nint_u, nint_ym, P̂_0, Q̂, R̂; jacobian=AutoForwardDiff(), direct=true\n)\n\nConstruct the estimator from the augmented covariance matrices P̂_0, Q̂ and R̂.\n\nThis syntax allows nonzero off-diagonal elements in mathbfP̂_-1(0) mathbfQ̂ R̂.\n\n\n\n\n\n","category":"type"},{"location":"public/state_estim/#ModelPredictiveControl.MovingHorizonEstimator","page":"State Estimators","title":"ModelPredictiveControl.MovingHorizonEstimator","text":"MovingHorizonEstimator(model::SimModel; <keyword arguments>)\n\nConstruct a moving horizon estimator (MHE) based on model (LinModel or NonLinModel).\n\nIt can handle constraints on the estimates, see setconstraint!. Additionally,  model is not linearized like the ExtendedKalmanFilter, and the probability  distribution is not approximated like the UnscentedKalmanFilter. The computational costs are drastically higher, however, since it minimizes the following objective function at each discrete time k:\n\nmin_mathbfx̂_k(k-N_k+p) mathbfŴ ε   mathbfx̄ mathbfP̄^-1       mathbfx̄ \n                                            + mathbfŴ mathbfQ̂_N_k^-1 mathbfŴ  \n                                            + mathbfV̂ mathbfR̂_N_k^-1 mathbfV̂\n                                            + C ε^2\n\nin which the arrival costs are evaluated from the states estimated at time k-N_k:\n\nbeginaligned\n    mathbfx̄ = mathbfx̂_k-N_k(k-N_k+p) - mathbfx̂_k(k-N_k+p) \n    mathbfP̄ = mathbfP̂_k-N_k(k-N_k+p)\nendaligned\n\nand the covariances are repeated N_k times:\n\nbeginaligned\n    mathbfQ̂_N_k = textdiagmathbf(Q̂Q̂Q̂)  \n    mathbfR̂_N_k = textdiagmathbf(R̂R̂R̂) \nendaligned\n\nThe estimation horizon H_e limits the window length:\n\nN_k =                     begincases\n    k + 1     k  H_e    \n    H_e       k  H_e    endcases\n\nThe vectors mathbfŴ and mathbfV̂ respectively encompass the estimated process noises mathbfŵ(k-j+p) from j=N_k to 1 and sensor noises mathbfv̂(k-j+1) from j=N_k to 1. The Extended Help defines the two vectors, the slack variable ε, and the estimation of the covariance at arrival mathbfP̂_k-N_k(k-N_k+p). If the keyword argument direct=true (default value), the constant p=0 in the equations above, and the MHE is in the current form. Else p=1, leading to the prediction form.\n\nSee UnscentedKalmanFilter for details on the augmented process model and  mathbfR̂ mathbfQ̂ covariances. This estimator allocates a fair amount of memory  at each time step for the optimization, which is hard-coded as a single shooting transcription for now.\n\nwarning: Warning\nSee the Extended Help if you get an error like:     MethodError: no method matching (::var\"##\")(::Vector{ForwardDiff.Dual}).\n\nArguments\n\ninfo: Info\nKeyword arguments with emphasis are non-Unicode alternatives.\n\nmodel::SimModel : (deterministic) model for the estimations.\nHe=nothing : estimation horizon H_e, must be specified.\ni_ym=1:model.ny : model output indices that are measured mathbfy^m, the rest    are unmeasured mathbfy^u.\nσP_0=fill(1/model.nx,model.nx) or sigmaP_0 : main diagonal of the initial estimate   covariance mathbfP(0), specified as a standard deviation vector.\nσQ=fill(1/model.nx,model.nx) or sigmaQ : main diagonal of the process noise   covariance mathbfQ of model, specified as a standard deviation vector.\nσR=fill(1,length(i_ym)) or sigmaR : main diagonal of the sensor noise covariance   mathbfR of model measured outputs, specified as a standard deviation vector.\nnint_u=0: integrator quantity for the stochastic model of the unmeasured disturbances at   the manipulated inputs (vector), use nint_u=0 for no integrator (see Extended Help).\nnint_ym=default_nint(model,i_ym,nint_u) : same than nint_u but for the unmeasured    disturbances at the measured outputs, use nint_ym=0 for no integrator (see Extended Help).\nσQint_u=fill(1,sum(nint_u)) or sigmaQint_u : same than σQ but for the unmeasured   disturbances at manipulated inputs mathbfQ_int_u (composed of integrators).\nσPint_u_0=fill(1,sum(nint_u)) or sigmaPint_u_0 : same than σP_0 but for the unmeasured   disturbances at manipulated inputs mathbfP_int_u(0) (composed of integrators).\nσQint_ym=fill(1,sum(nint_ym)) or sigmaQint_u : same than σQ for the unmeasured   disturbances at measured outputs mathbfQ_int_ym (composed of integrators).\nσPint_ym_0=fill(1,sum(nint_ym)) or sigmaPint_ym_0 : same than σP_0 but for the unmeasured   disturbances at measured outputs mathbfP_int_ym(0) (composed of integrators).\nCwt=Inf : slack variable weight C, default to Inf meaning hard constraints only.\noptim=default_optim_mhe(model) : a JuMP.Model object with a quadratic or  nonlinear optimizer for solving (default to Ipopt,  or OSQP if model is a LinModel).\ngradient=AutoForwardDiff() : an AbstractADType backend for the gradient of the objective  function when model is not a LinModel, see DifferentiationInterface doc.\njacobian=AutoForwardDiff() : an AbstractADType backend for the Jacobian of the  constraints when model is not a LinModel, see gradient above for the options.\nhessian=false : an AbstractADType backend for the Hessian of the Lagrangian, see   gradient above for the options. The default false skip it and use the quasi-Newton   method of optim, which is always the case if oracle=false (see Extended Help).\noracle=JuMP.solver_name(optim)==\"Ipopt\" : a Bool to use the VectorNonlinearOracle  for efficient nonlinear constraints (not supported by most optimizers for now).\ndirect=true: construct with a direct transmission from mathbfy^m (a.k.a. current  estimator, in opposition to the delayed/predictor form).\n\nExamples\n\njulia> model = NonLinModel((x,u,_,_)->0.1x+u, (x,_,_)->2x, 10.0, 1, 1, 1, solver=nothing);\n\njulia> estim = MovingHorizonEstimator(model, He=5, σR=[1], σP_0=[0.01])\nMovingHorizonEstimator estimator with a sample time Ts = 10.0 s:\n├ model: NonLinModel\n├ optimizer: Ipopt \n├ gradient: AutoForwardDiff\n├ jacobian: AutoForwardDiff\n├ hessian: nothing\n├ arrival covariance: UnscentedKalmanFilter \n└ dimensions:\n  ├ 5 estimation steps He\n  ├ 0 slack variable ε (estimation constraints)\n  ├ 1 manipulated inputs u (0 integrating states)\n  ├ 2 estimated states x̂\n  ├ 1 measured outputs ym (1 integrating states)\n  ├ 0 unmeasured outputs yu\n  └ 0 measured disturbances d\n\nExtended Help\n\ndetails: Extended Help\nThe estimated process and sensor noises are defined as:mathbfŴ = \nbeginbmatrix\n    mathbfŵ(k-N_k+p+0)     \n    mathbfŵ(k-N_k+p+1)     \n    vdots                  \n    mathbfŵ(k+p-1)\nendbmatrix  quad\nmathbfV̂ =\nbeginbmatrix\n    mathbfv̂(k-N_k+1)     \n    mathbfv̂(k-N_k+2)     \n    vdots                  \n    mathbfv̂(k)\nendbmatrixbased on the augmented model functions mathbff̂ ĥ^m:beginaligned\n    mathbfv̂(k-j)     = mathbfy^m(k-j) - mathbfĥ^mBig(mathbfx̂_k(k-j) mathbfd(k-j)Big) \n    mathbfx̂_k(k-j+1) = mathbff̂Big(mathbfx̂_k(k-j) mathbfu(k-j) mathbfd(k-j)Big) + mathbfŵ(k-j)\nendalignedThe constant p equals to !direct. In other words, mathbfŴ and mathbfV̂ are shifted by one time step if direct==true. The non-default prediction form with p=1 is particularly useful for the MHE since it moves its expensive computations after the MPC optimization. That is, preparestate! will solve the optimization by default, but it can be postponed to updatestate! with direct=false.The Extended Help of SteadyKalmanFilter details the tuning of the covariances and the augmentation with nint_ym and nint_u arguments. The default augmentation scheme is identical, that is nint_u=0 and nint_ym computed by default_nint. Note that the constructor does not validate the observability of the resulting augmented NonLinModel. In such cases, it is the user's responsibility to ensure that it is still observable.The estimation covariance at arrival mathbfP̂_k-N_k(k-N_k+p) gives an uncertainty on the state estimate at the beginning of the window k-N_k+p, that is, in the past. It is not the same as the current estimate covariance mathbfP̂_k(k), a value not computed by the MHE (contrarily to e.g. the KalmanFilter). Three keyword arguments specify its initial value with mathbfP̂_i =  mathrmdiag mathbfP(0) mathbfP_int_u(0) mathbfP_int_ym(0) . The initial state estimate mathbfx̂_i can be manually specified with setstate!, or automatically  with initstate! for LinModel. Note the MHE with p=0 is slightly inconsistent with all the other estimators here. It interprets the initial values as mathbfx̂_i = mathbfx̂_-1(-1) and  mathbfP̂_i = mathbfP̂_-1(-1), an  a posteriori estimate[2] from the last time step. The MHE with p=1 is consistent, interpreting them as  mathbfx̂_i = mathbfx̂_-1(0) and mathbfP̂_i = mathbfP̂_-1(0).[2]: M. Hovd (2012), \"A Note On The Smoothing Formulation Of Moving Horizon Estimation\",   Facta Universitatis, Vol. 11 №2.The optimization and the update of the arrival covariance depend on model:If model is a LinModel, the optimization is treated as a quadratic program with a time-varying Hessian, which is generally cheaper than nonlinear programming. By default, a KalmanFilter estimates the arrival covariance (customizable).\nElse, a nonlinear program with dense ForwardDiff automatic differentiation (AD) compute the objective and constraint derivatives by default  (customizable). Optimizers generally benefit from exact derivatives like AD. However,  the f and h functions must be compatible with this feature. See the  JuMP documentation for common mistakes when writing these functions. Also, an UnscentedKalmanFilter estimates the arrival covariance by default.One exception about AD: the selected backend for the Hessian of the Lagrangian function with oracle=true and hessian=true options is sparse:AutoSparse(\n    AutoForwardDiff(); \n    sparsity_detector  = TracerSparsityDetector(), \n    coloring_algorithm = GreedyColoringAlgorithm(\n        (\n        NaturalOrder(),\n        LargestFirst(),\n        SmallestLast(),\n        IncidenceDegree(),\n        DynamicLargestFirst()\n        ), \n    postprocessing = true\n    )\n)that is, it will test many coloring orders at preparation and keep the best. The slack variable ε relaxes the constraints if enabled, see setconstraint!.  It is disabled by default for the MHE (from Cwt=Inf) but it should be activated for problems with two or more types of bounds, to ensure feasibility (e.g. on the estimated state mathbfx̂ and sensor noise mathbfv̂). Note that if Cwt≠Inf, the attribute nlp_scaling_max_gradient of Ipopt is set to  10/Cwt (if not already set),  to scale the small values of ε. Use the second constructor to specify the arrival covariance estimation method.\n\n\n\n\n\nMovingHorizonEstimator(\n    model, He, i_ym, nint_u, nint_ym, P̂_0, Q̂, R̂, Cwt=Inf;\n    optim=default_optim_mhe(model), \n    gradient=AutoForwardDiff(),\n    jacobian=AutoForwardDiff(),\n    oracle=JuMP.solver_name(optim)==\"Ipopt\",\n    direct=true,\n    covestim=default_covestim_mhe(model, i_ym, nint_u, nint_ym, P̂_0, Q̂, R̂; direct)\n)\n\nConstruct the estimator from the augmented covariance matrices P̂_0, Q̂ and R̂.\n\nThis syntax allows nonzero off-diagonal elements in mathbfP̂_i mathbfQ̂ R̂, where mathbfP̂_i is the initial estimation covariance, provided by P̂_0 argument. The keyword argument covestim also allows specifying a custom StateEstimator object for the estimation of covariance at the arrival mathbfP̂_k-N_k(k-N_k+p). The supported types are SteadyKalmanFilter, KalmanFilter,  UnscentedKalmanFilter and ExtendedKalmanFilter. A constant arrival covariance is supported with SteadyKalmanFilter, and by setting the P̂ argument  of setstate! at the desired value.\n\n\n\n\n\n","category":"type"},{"location":"public/state_estim/#ModelPredictiveControl.InternalModel","page":"State Estimators","title":"ModelPredictiveControl.InternalModel","text":"InternalModel(model::SimModel; i_ym=1:model.ny, stoch_ym=ss(I,I,I,I,model.Ts))\n\nConstruct an internal model estimator based on model (LinModel or NonLinModel).\n\ni_ym provides the model output indices that are measured mathbfy^m, the rest are  unmeasured mathbfy^u. model evaluates the deterministic predictions  mathbfŷ_d, and stoch_ym, the stochastic predictions of the measured outputs  mathbfŷ_s^m (the unmeasured ones being mathbfŷ_s^u=0). The predicted outputs sum both values : mathbfŷ = ŷ_d + ŷ_s. See the Extended Help for more details. This estimator is allocation-free if model simulations do not allocate.\n\nwarning: Warning\nInternalModel estimator does not work if model is integrating or unstable. The  constructor verifies these aspects for LinModel but not for NonLinModel. Uses any  other state estimator in such cases.\n\nExamples\n\njulia> estim = InternalModel(LinModel([tf(3, [30, 1]); tf(-2, [5, 1])], 0.5), i_ym=[2])\nInternalModel estimator with a sample time Ts = 0.5 s:\n├ model: LinModel\n└ dimensions:\n  ├ 1 manipulated inputs u\n  ├ 2 estimated states x̂\n  ├ 1 measured outputs ym\n  ├ 1 unmeasured outputs yu\n  └ 0 measured disturbances d\n\nExtended Help\n\ndetails: Extended Help\nstoch_ym is a TransferFunction or StateSpace object that models disturbances on mathbfy^m. Its input is a hypothetical zero mean white noise vector. stoch_ym  supposes 1 integrator per measured outputs by default, assuming that the current stochastic estimate mathbfŷ_s^m(k) = mathbfy^m(k) - mathbfŷ_d^m(k) is constant in the  future. This is the dynamic matrix control (DMC) strategy, which is simple but sometimes too aggressive. Additional poles and zeros in stoch_ym can mitigate this. The following block diagram summarizes the internal model structure.(Image: block diagram of the internal model structure)\n\n\n\n\n\n","category":"type"},{"location":"public/state_estim/#ModelPredictiveControl.ManualEstimator","page":"State Estimators","title":"ModelPredictiveControl.ManualEstimator","text":"ManualEstimator(model::SimModel; <keyword arguments>)\n\nConstruct a manual state estimator for model (LinModel or NonLinModel).\n\nThis StateEstimator type allows the construction of PredictiveController objects but turns off the built-in state estimation. The user must manually provides the  estimate mathbfx̂_k(k) or mathbfx̂_k-1(k) through setstate! at each time step k. The states in the estimator must obviously represent the same thing as in the controller, both for the deterministic and the stochastic model of the unmeasured disturbances (nint_u and nint_ym arguments). Calling preparestate! and  updatestate! on this object will do nothing at all. See Extended Help for usage  examples.\n\nArguments\n\nmodel::SimModel : (deterministic) model for the estimations.\ni_ym=1:model.ny : model output indices that are measured mathbfy^m, the rest    are unmeasured mathbfy^u.\nnint_u=0: integrator quantity for the stochastic model of the unmeasured disturbances at   the manipulated inputs (vector), use nint_u=0 for no integrator (see Extended Help).\nnint_ym=default_nint(model,i_ym,nint_u) : same than nint_u but for the unmeasured    disturbances at the measured outputs, use nint_ym=0 for no integrator (see Extended Help).\n\nExamples\n\njulia> model = LinModel([tf(3, [30, 1]); tf(-2, [5, 1])], 0.5);\n\njulia> estim = ManualEstimator(model, nint_ym=0) # disable augmentation with integrators\nManualEstimator estimator with a sample time Ts = 0.5 s:\n├ model: LinModel\n└ dimensions:\n  ├ 1 manipulated inputs u (0 integrating states)\n  ├ 2 estimated states x̂\n  ├ 2 measured outputs ym (0 integrating states)\n  ├ 0 unmeasured outputs yu\n  └ 0 measured disturbances d\n\nExtended Help\n\ndetails: Extended Help\nA first use case is a linear predictive controller based on nonlinear state estimation, for example a nonlinear MovingHorizonEstimator (MHE). Note that the model augmentation scheme with nint_u and nint_ym options must be identical for both StateEstimator objects (see SteadyKalmanFilter extended help for details on augmentation). The ManualEstimator serves as a wrapper to provide the minimal required information to construct any PredictiveController object:julia> function man_sim()\n           f(x,u,_,_) = 0.5*sin.(x + u)\n           h(x,_,_) = x\n           model = NonLinModel(f, h, 10.0, 1, 1, 1, solver=nothing)\n           linModel = linearize(model, x=[0], u=[0])\n           man = ManualEstimator(linModel, nint_u=[1])\n           mpc = LinMPC(man)\n           estim = MovingHorizonEstimator(model, nint_u=[1], He=5)\n           estim = setconstraint!(estim, v̂min=[-0.001], v̂max=[0.001])\n           initstate!(estim, [0], [0])\n           y_data, ŷ_data = zeros(5), zeros(5)\n           for i=1:5\n               y = model()                     # simulated measurement\n               x̂ = preparestate!(estim, y)     # correct nonlinear MHE state estimate\n               ŷ = estim()                     # nonlinear MHE estimated output\n               setstate!(mpc, x̂)               # update MPC with the MHE corrected state \n               u = moveinput!(mpc, [0])\n               y_data[i], ŷ_data[i] = y[1], ŷ[1]\n               updatestate!(estim, u, y)       # update nonlinear MHE estimation\n               updatestate!(model, u .+ 0.5)   # update simulator with load disturbance\n           end\n           return collect([y_data ŷ_data]')\n       end;\n\njulia> YandŶ = round.(man_sim(), digits=6)\n2×5 Matrix{Float64}:\n  0.0  0.239713  0.227556  0.157837  0.098629\n -0.0  0.238713  0.226556  0.156837  0.097629A second use case is to allow the user to manually provide the state estimate computed from an external source, e.g. an observer from LowLevelParticleFilters. A custom stochastic model for the unmeasured disturbances (other than integrated white  noise) can be specified by constructing a SimModel object with the augmented state-space matrices/functions directly, and by setting nint_u=0 and nint_ym=0. See Disturbance-gallery for examples of other disturbance models.\n\n\n\n\n\n","category":"type"},{"location":"public/state_estim/#ModelPredictiveControl.default_nint","page":"State Estimators","title":"ModelPredictiveControl.default_nint","text":"default_nint(model::LinModel, i_ym=1:model.ny, nint_u=0) -> nint_ym\n\nGet default integrator quantity per measured outputs nint_ym for LinModel.\n\nThe arguments i_ym and nint_u are the measured output indices and the integrator quantity on each manipulated input, respectively. By default, one integrator is added on each measured outputs. If mathbfÂ Ĉ matrices of the augmented model become unobservable, the integrator is removed. This approach works well for stable, integrating and unstable model (see Examples).\n\nExamples\n\njulia> model = LinModel(append(tf(3, [10, 1]), tf(2, [1, 0]), tf(4,[-5, 1])), 1.0);\n\njulia> nint_ym = default_nint(model)\n3-element Vector{Int64}:\n 1\n 0\n 1\n\n\n\n\n\ndefault_nint(model::SimModel, i_ym=1:model.ny, nint_u=0)\n\nOne integrator on each measured output by default for other cases e.g. NonLinModel.\n\nIf the integrator quantity per manipulated input nint_u ≠ 0, the method returns zero  integrator on each measured output.\n\nwarning: Warning\nTheres is no verification the augmented model remains observable. The resulting  StateEstimator object should be assessed separately with e.g.: sim!. \n\n\n\n\n\n","category":"function"},{"location":"func_index/#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"manual/linmpc/#man_lin","page":"Linear Design","title":"Manual: Linear Design","text":"Pages = [\"linmpc.md\"]","category":"section"},{"location":"manual/linmpc/#Linear-Model","page":"Linear Design","title":"Linear Model","text":"The example considers a continuously stirred-tank reactor (CSTR) with a cold and hot water inlet as a plant. The water flows out of an opening at the bottom of the tank. The manipulated inputs are the cold u_c and hot u_h water flow rates, and the measured outputs are the liquid level y_L and temperature y_T:\n\nbeginaligned\n    mathbfu = beginbmatrix u_c  u_h endbmatrix \n    mathbfy = beginbmatrix y_L  y_T endbmatrix\nendaligned\n\nThe following figure depicts the instrumentation installed on the CSTR:\n\n<p><img src=\"../../assets/cstr.svg\" alt=\"cstr\" width=275 style=\"background-color:white; \n    border:20px solid white; display: block; margin-left: auto; margin-right: auto;\"/></p>\n\nAt the steady-state operating points:\n\nbeginaligned\n    mathbfu_op = beginbmatrix 20  20 endbmatrix \n    mathbfy_op = beginbmatrix 50  30 endbmatrix \nendaligned\n\nthe following linear model accurately describes the plant dynamics:\n\nmathbfG(s) = fracmathbfy(s)mathbfu(s) =\nbeginbmatrix\n    frac19018s + 1  frac19018s + 1 3pt\n    frac-0748s + 1  frac0748s + 1\nendbmatrix\n\nWe first need to construct a LinModel objet with setop! to handle the operating points:\n\nusing ModelPredictiveControl, ControlSystemsBase\nG = [ tf(1.90, [18, 1]) tf(1.90, [18, 1]);\n      tf(-0.74,[8, 1])  tf(0.74, [8, 1]) ]\nTs = 2.0\nmodel = setop!(LinModel(G, Ts), uop=[20, 20], yop=[50, 30])\n\nThe model object will be used for two purposes : to construct our controller, and as a plant simulator to test the design. Its sampling time is 2 s thus the control period will be 2 s as well.","category":"section"},{"location":"manual/linmpc/#Linear-Model-Predictive-Controller","page":"Linear Design","title":"Linear Model Predictive Controller","text":"A linear model predictive controller (MPC) will control both the water level y_L and temperature y_T in the tank. The tank level should also never fall below 48:\n\ny_L  48\n\nWe design our LinMPC controllers by including the linear level constraint with setconstraint! (±Inf values should be used when there is no bound):\n\nmpc = LinMPC(model, Hp=10, Hc=2, Mwt=[1, 1], Nwt=[0.1, 0.1])\nmpc = setconstraint!(mpc, ymin=[48, -Inf])\n\nin which Hp and Hc keyword arguments are respectively the predictive and control horizons, and Mwt and Nwt, the output setpoint tracking and move suppression weights. By default, LinMPC controllers use OSQP and a direct SingleShooting transcription method to solve the optimal control problem, soft constraints on output predictions mathbfŷ to ensure feasibility, and a SteadyKalmanFilter to estimate the plant states[1]. An attentive reader will also notice that the Kalman filter estimates two additional states compared to the plant model. These are the integrating states for the unmeasured plant disturbances, and they are automatically added to the model outputs by default if observability is preserved (see SteadyKalmanFilter for details).\n\n[1]: As an alternative to state observer, we could have use an InternalModel structure with mpc = LinMPC(InternalModel(model), Hp=15, Hc=2, Mwt=[1, 1], Nwt=[0.1, 0.1]). It was tested on the example of this page and it gave similar results.\n\nBefore closing the loop, the actual plant input mathbfu and measurement mathbfy should initialize the estimates mathbfx̂ at the steady-state solution that leads to mathbfŷ(0) = mathbfy(0). This approach results in a bumpless transfer. The initstate! function finds this solution for LinModel. Since model simulates our plant here, its output will initialize the states. LinModel objects are callable for this purpose (an alias for evaloutput):\n\nu, y = model.uop, model() # or equivalently : y = evaloutput(model)\ninitstate!(mpc, u, y)\nnothing # hide\n\nWe can then close the loop and test mpc performance on the simulator by imposing step changes on output setpoints mathbfr_y and on a load disturbance u_l:\n\nfunction test_mpc(mpc, model)\n    N = 200\n    ry, ul = [50, 30], 0\n    u_data, y_data, ry_data = zeros(model.nu, N), zeros(model.ny, N), zeros(model.ny, N)\n    for i = 1:N\n        i == 51  && (ry = [50, 35])\n        i == 101 && (ry = [54, 30])\n        i == 151 && (ul = -20)\n        y = model() # simulated measurements\n        preparestate!(mpc, y) # prepare mpc state estimate for current iteration\n        u = mpc(ry) # or equivalently : u = moveinput!(mpc, ry)\n        u_data[:,i], y_data[:,i], ry_data[:,i] = u, y, ry\n        updatestate!(mpc, u, y) # update mpc state estimate for next iteration\n        updatestate!(model, u + [0; ul]) # update simulator with load disturbance\n    end\n    return u_data, y_data, ry_data\nend\nu_data, y_data, ry_data = test_mpc(mpc, model)\nt_data = Ts*(0:(size(y_data,2)-1))\nnothing # hide\n\nThe LinMPC objects are also callable as an alternative syntax for moveinput!. It is worth mentioning that additional information like the optimal output predictions mathbfŶ can be retrieved by calling getinfo after solving the problem. Also, calling preparestate! on the mpc object prepares the estimates for the current control period, and updatestate! updates them for the next one (the same logic applies for model). This is why preparestate! is called before the controller, and updatestate!, after.\n\nLastly, we plot the closed-loop test with the Plots package:\n\nusing Plots\nfunction plot_data(t_data, u_data, y_data, ry_data)\n    p1 = plot(t_data, y_data[1,:], label=\"meas.\", ylabel=\"level\")\n    plot!(p1, t_data, ry_data[1,:], label=\"setpoint\", linestyle=:dash, linetype=:steppost)\n    plot!(p1, t_data, fill(48,size(t_data)), label=\"min\", linestyle=:dot, linewidth=1.5)\n    p2 = plot(t_data, y_data[2,:], label=\"meas.\", legend=:topleft, ylabel=\"temp.\")\n    plot!(p2, t_data, ry_data[2,:],label=\"setpoint\", linestyle=:dash, linetype=:steppost)\n    p3 = plot(t_data,u_data[1,:],label=\"cold\", linetype=:steppost, ylabel=\"flow rate\")\n    plot!(p3, t_data,u_data[2,:],label=\"hot\", linetype=:steppost, xlabel=\"time (s)\")\n    return plot(p1, p2, p3, layout=(3,1))\nend\nplot_data(t_data, u_data, y_data, ry_data)\nsavefig(\"plot1_LinMPC.svg\"); nothing # hide\n\n(Image: plot1_LinMPC)\n\nCompared to the default setting, adding the integrating states at the model inputs may improve the closed-loop performance. Load disturbances are indeed very common in many real-life control problems. Constructing a LinMPC with input integrators:\n\nmpc2 = LinMPC(model, Hp=10, Hc=2, Mwt=[1, 1], Nwt=[0.1, 0.1], nint_u=[1, 1])\nmpc2 = setconstraint!(mpc2, ymin=[48, -Inf])\n\ndoes accelerate the rejection of the load disturbance and almost eliminates the level constraint violation:\n\nsetstate!(model, zeros(model.nx))\nu, y = model.uop, model()\ninitstate!(mpc2, u, y)\nu_data, y_data, ry_data = test_mpc(mpc2, model)\nplot_data(t_data, u_data, y_data, ry_data)\nsavefig(\"plot2_LinMPC.svg\"); nothing # hide\n\n(Image: plot2_LinMPC)","category":"section"},{"location":"manual/linmpc/#Moving-Horizon-Estimation","page":"Linear Design","title":"Moving Horizon Estimation","text":"The SteadyKalmanFilter is simple but it is not able to handle constraints at estimation. The MovingHorizonEstimator (MHE) can improve the accuracy of the state estimate mathbfx̂. It solves a quadratic optimization problem under a past time window H_e. Bounds on the estimated plant state mathbfx̂, estimated process noise mathbfŵ and estimated sensor noise mathbfv̂ can be included in the problem. This can be useful to add physical knowledge on the plant and its disturbances, and it does not require the installation of new physical sensors (e.g. a strictly positive concentration). The closed-loop performance of any state feedback controller, like here, depends on the accuracy of the plant state estimate.\n\nFor the CSTR, we will bound the innovation term mathbfy(k) - mathbfŷ(k) = mathbfv̂(k), and increase the hot water unmeasured disturbance covariance in mathbfQ_int_u to accelerate the estimation of the load disturbance:\n\nestim = MovingHorizonEstimator(model, He=10, nint_u=[1, 1], σQint_u = [1, 2])\nestim = setconstraint!(estim, v̂min=[-1, -0.5], v̂max=[+1, +0.5])\nmpc_mhe = LinMPC(estim, Hp=10, Hc=2, Mwt=[1, 1], Nwt=[0.1, 0.1])\nmpc_mhe = setconstraint!(mpc_mhe, ymin=[45, -Inf])\n\nThe rejection is indeed improved:\n\nsetstate!(model, zeros(model.nx))\nu, y, d = model.uop, model(), mpc_mhe.estim.model.dop\ninitstate!(mpc_mhe, u, y, d)\nu_data, y_data, ry_data = test_mpc(mpc_mhe, model)\nplot_data(t_data, u_data, y_data, ry_data)\nsavefig(\"plot3_LinMPC.svg\"); nothing # hide\n\n(Image: plot3_LinMPC)","category":"section"},{"location":"manual/linmpc/#Adding-Feedforward-Compensation","page":"Linear Design","title":"Adding Feedforward Compensation","text":"Suppose that the load disturbance u_l of the last section is in fact caused by a separate hot water pipe that discharges into the tank. Adding a new sensor to measure this flow rate allows us to incorporate feedforward compensation in the controller. The new plant model is:\n\nbeginbmatrix\n    y_L(s)  y_T(s)\nendbmatrix = \nbeginbmatrix\n    frac19018s + 1  frac19018s + 1  frac19018s + 1 3pt\n    frac-0748s + 1  frac0748s + 1   frac0748s + 1\nendbmatrix\nbeginbmatrix\n    u_c(s)  u_h(s)  u_l(s)\nendbmatrix\n\nWe need to construct a new LinModel that includes the measured disturbance mathbfd = u_l and the operating point mathbfd_op = 20:\n\nmodel_d = setop!(LinModel([G G[1:2, 2]], Ts, i_d=[3]), uop=[20, 20], yop=[50, 30], dop=[20])\n\nA LinMPC controller is constructed on this model:\n\nmpc_d = LinMPC(model_d, Hp=10, Hc=2, Mwt=[1, 1], Nwt=[0.1, 0.1])\nmpc_d = setconstraint!(mpc_d, ymin=[48, -Inf])\n\nA new test function that feeds the measured disturbance mathbfd to the controller is also required:\n\nfunction test_mpc_d(mpc_d, model)\n    N = 200\n    ry, ul = [50, 30], 0\n    dop = mpc_d.estim.model.dop\n    u_data, y_data, ry_data = zeros(model.nu, N), zeros(model.ny, N), zeros(model.ny, N)\n    for i = 1:N\n        i == 51  && (ry = [50, 35])\n        i == 101 && (ry = [54, 30])\n        i == 151 && (ul = -20)\n        d = ul .+ dop   # simulated measured disturbance\n        y = model()     # simulated measurements\n        preparestate!(mpc_d, y, d) # prepare estimate with the measured disturbance d\n        u = mpc_d(ry, d) # also feed the measured disturbance d to the controller\n        u_data[:,i], y_data[:,i], ry_data[:,i] = u, y, ry\n        updatestate!(mpc_d, u, y, d)    # update estimate with the measured disturbance d\n        updatestate!(model, u + [0; ul]) # update simulator\n    end\n    return u_data, y_data, ry_data\nend\nnothing # hide\n\nThe new feedforward compensation is able to almost perfectly reject the load disturbance:\n\nsetstate!(model, zeros(model.nx))\nu, y, d = model.uop, model(), mpc_d.estim.model.dop\ninitstate!(mpc_d, u, y, d)\nu_data, y_data, ry_data = test_mpc_d(mpc_d, model)\nplot_data(t_data, u_data, y_data, ry_data)\nsavefig(\"plot4_LinMPC.svg\"); nothing # hide\n\n(Image: plot4_LinMPC)\n\nNote that measured disturbances are assumed constant in the future by default but custom mathbfD̂ predictions are possible. The same applies for the setpoint predictions mathbfR̂_y.","category":"section"},{"location":"public/sim_model/#func_sim_model","page":"Plant Models","title":"Functions: Plant Models","text":"Pages = [\"sim_model.md\"]\n\nThe SimModel types represents discrete state-space models that can be used to construct StateEstimators and PredictiveControllers, or as plant simulators by calling evaloutput and updatestate! methods on SimModel instances (to test estimator/controller designs). For time simulations, the states mathbfx are stored inside SimModel instances. Use setstate! method to manually modify them.\n\ninfo: Info\nThe nomenclature in this page introduces the model manipulated input mathbfu, measured disturbances mathbfd, state mathbfx and output mathbfy, four vectors of nu, nd, nx and ny elements, respectively. The mathbfz vector combines the elements of mathbfu and mathbfd.","category":"section"},{"location":"public/sim_model/#SimModel","page":"Plant Models","title":"SimModel","text":"","category":"section"},{"location":"public/sim_model/#LinModel","page":"Plant Models","title":"LinModel","text":"","category":"section"},{"location":"public/sim_model/#NonLinModel","page":"Plant Models","title":"NonLinModel","text":"","category":"section"},{"location":"public/sim_model/#Set-Variable-Names","page":"Plant Models","title":"Set Variable Names","text":"","category":"section"},{"location":"public/sim_model/#Set-Operating-Points","page":"Plant Models","title":"Set Operating Points","text":"","category":"section"},{"location":"public/sim_model/#Linearize","page":"Plant Models","title":"Linearize","text":"","category":"section"},{"location":"public/sim_model/#Differential-Equation-Solvers","page":"Plant Models","title":"Differential Equation Solvers","text":"","category":"section"},{"location":"public/sim_model/#DiffSolver","page":"Plant Models","title":"DiffSolver","text":"","category":"section"},{"location":"public/sim_model/#RungeKutta","page":"Plant Models","title":"RungeKutta","text":"","category":"section"},{"location":"public/sim_model/#ForwardEuler","page":"Plant Models","title":"ForwardEuler","text":"","category":"section"},{"location":"public/sim_model/#ModelPredictiveControl.SimModel","page":"Plant Models","title":"ModelPredictiveControl.SimModel","text":"Abstract supertype of LinModel and NonLinModel types.\n\n\n\n(model::SimModel)(d=[]) -> y\n\nFunctor allowing callable SimModel object as an alias for evaloutput.\n\nExamples\n\njulia> model = NonLinModel((x,u,_,_)->-x + u, (x,_,_)->x .+ 20, 4, 1, 1, 1, solver=nothing);\n\njulia> y = model()\n1-element Vector{Float64}:\n 20.0\n\n\n\n\n\n","category":"type"},{"location":"public/sim_model/#ModelPredictiveControl.LinModel","page":"Plant Models","title":"ModelPredictiveControl.LinModel","text":"LinModel(sys::StateSpace[, Ts]; i_u=1:size(sys,2), i_d=Int[])\n\nConstruct a linear model from state-space model sys with sampling time Ts in second.\n\nThe system sys can be continuous or discrete-time (Ts can be omitted for the latter). For continuous dynamics, its state-space equations are (discrete case in Extended Help):\n\nbeginaligned\n    mathbfẋ(t) = mathbfA x(t) + mathbfB s(t) \n    mathbfy(t) = mathbfC x(t) + mathbfD s(t)\nendaligned\n\nwith the state mathbfx and output mathbfy vectors. The mathbfs vector  comprises the manipulated inputs mathbfu and measured disturbances mathbfd,  in any order. i_u provides the indices of mathbfs that are manipulated, and i_d,  the measured disturbances. The constructor automatically discretizes continuous systems, resamples discrete ones if Ts ≠ sys.Ts, computes a new balancing and minimal state-space realization, and separates the mathbfs terms in two parts (details in Extended Help).  The rest of the documentation assumes discrete models since all systems end up in this form.\n\nSee also ss\n\nExamples\n\njulia> model1 = LinModel(ss(-0.1, 1.0, 1.0, 0), 2.0) # continuous-time StateSpace\nLinModel with a sample time Ts = 2.0 s:\n└ dimensions:\n  ├ 1 manipulated inputs u\n  ├ 1 states x\n  ├ 1 outputs y\n  └ 0 measured disturbances d\n\njulia> model2 = LinModel(ss(0.4, 0.2, 0.3, 0, 0.1)) # discrete-time StateSpace\nLinModel with a sample time Ts = 0.1 s:\n└ dimensions:\n  ├ 1 manipulated inputs u\n  ├ 1 states x\n  ├ 1 outputs y\n  └ 0 measured disturbances d\n\nExtended Help\n\ndetails: Extended Help\nThe state-space equations are similar if sys is discrete-time:beginaligned\n    mathbfx(k+1) =  mathbfA x(k) + mathbfB s(k) \n    mathbfy(k)   =  mathbfC x(k) + mathbfD s(k)\nendalignedContinuous dynamics are internally discretized using c2d and :zoh for manipulated inputs, and :tustin, for measured disturbances. Lastly, if sys is discrete and the provided argument Ts ≠ sys.Ts, the system is resampled by using the aforementioned discretization methods.Note that the constructor transforms the system to its minimal and balancing realization using minreal for controllability/observability. As a consequence, the final state-space representation will be presumably different from the one provided in sys. It is also converted into a more practical form:beginaligned\n    mathbfx(k+1) =  mathbfA x(k) + mathbfB_u u(k) + mathbfB_d d(k) \n    mathbfy(k)   =  mathbfC x(k) + mathbfD_d d(k)\nendalignedUse the syntax LinModel{NT}(A, Bu, C, Bd, Dd, Ts) to force a specific state-space representation. It is assumed that mathbfD_u=0 (or sys is strictly proper) since otherwise the resulting discrete controller would be acausal in its implementation (≠ mathematical causality). Indeed, at each sampling instant k, the predictive controller will:sample an output mathbfy(k) from the plant\ncomputes an action mathbfu(k) and \napply the action on the plant. There is a causality paradox if mathbfu(k) impacts mathbfy(k) even before computing it.\n\n\n\n\n\nLinModel(sys::TransferFunction[, Ts]; i_u=1:size(sys,2), i_d=Int[])\n\nConvert to minimal realization state-space when sys is a transfer function.\n\nsys is equal to fracmathbfy(s)mathbfs(s) for continuous-time, and  fracmathbfy(z)mathbfs(z), for discrete-time.\n\nSee also tf\n\nExamples\n\njulia> model = LinModel([tf(3, [30, 1]) tf(-2, [5, 1])], 0.5, i_d=[2])\nLinModel with a sample time Ts = 0.5 s:\n└ dimensions:\n  ├ 1 manipulated inputs u\n  ├ 2 states x\n  ├ 1 outputs y\n  └ 1 measured disturbances d\n\n\n\n\n\nLinModel(sys::DelayLtiSystem, Ts; i_u=1:size(sys,2), i_d=Int[])\n\nDiscretize with zero-order hold when sys is a continuous system with delays.\n\nThe delays must be multiples of the sample time Ts.\n\n\n\n\n\nLinModel{NT}(A, Bu, C, Bd, Dd, Ts)\n\nConstruct the model from the discrete state-space matrices A, Bu, C, Bd, Dd directly.\n\nSee LinModel(::StateSpace) Extended Help for the meaning of the matrices. The arguments Bd and Dd can be the scalar 0 if there is no measured disturbance. This syntax do not modify the state-space representation provided in argument (minreal is not called). Care must be taken to ensure that the model is controllable and observable. The  optional parameter NT explicitly set the number type of vectors (default to Float64).\n\n\n\n\n\nLinModel(model::NonLinModel; x=model.x0+model.xop, u=model.uop, d=model.dop)\n\nCall linearize(model; x, u, d) and return the resulting linear model.\n\n\n\n\n\n","category":"type"},{"location":"public/sim_model/#ModelPredictiveControl.NonLinModel","page":"Plant Models","title":"ModelPredictiveControl.NonLinModel","text":"NonLinModel{NT}(f::Function,  h::Function,  Ts, nu, nx, ny, nd=0; <keyword arguments>)\nNonLinModel{NT}(f!::Function, h!::Function, Ts, nu, nx, ny, nd=0; <keyword arguments>)\n\nConstruct a nonlinear model from state-space functions f/f! and h/h!.\n\nBoth continuous and discrete-time models are supported. The default arguments assume  continuous dynamics. Use solver=nothing for the discrete case (see Extended Help). The functions are defined as:\n\nbeginaligned\n    mathbfẋ(t) = mathbffBig( mathbfx(t) mathbfu(t) mathbfd(t) mathbfp Big) \n    mathbfy(t) = mathbfhBig( mathbfx(t) mathbfd(t) mathbfp Big)\nendaligned\n\nwhere mathbfx, mathbfy, mathbfu, mathbfd and mathbfp are respectively the state, output, manipulated input, measured disturbance and parameter vectors. As a matter of fact, the parameter argument p can be any Julia objects but use a mutable type if you want to change them later e.g.: a vector. \n\nSee Extended Help if the dynamics are a function of  t or mathbfu appears in  mathbfh. The functions can be implemented in two possible ways:\n\nNon-mutating functions (out-of-place): define them as f(x, u, d, p) -> ẋ and h(x, d, p) -> y. This syntax is simple and intuitive but it allocates more memory.\nMutating functions (in-place): define them as f!(ẋ, x, u, d, p) -> nothing and h!(y, x, d, p) -> nothing. This syntax reduces the allocations and potentially the  computational burden as well.\n\ntip: Tip\nReplace the d or p argument with _ in your functions if not needed (see Examples below).\n\nThe rest of the documentation assumes discrete dynamics since all models end up in this  form. The optional parameter NT explicitly set the number type of vectors (default to  Float64).\n\nwarning: Warning\nThe two functions must be in pure Julia to use the model in NonLinMPC, ExtendedKalmanFilter, MovingHorizonEstimator and linearize, except if a finite difference backend is used (e.g. AutoFiniteDiff).\n\nSee also LinModel.\n\nArguments\n\nf::Function or f!: state function.\nh::Function or h!: output function.\nTs: sampling time of in second.\nnu: number of manipulated inputs.\nnx: number of states.\nny: number of outputs.\nnd=0: number of measured disturbances.\np=[]: parameters of the model (any type).\nsolver=RungeKutta(4): a DiffSolver object for the discretization of continuous dynamics, use nothing for discrete-time models (default to 4th order RungeKutta).\njacobian=AutoForwardDiff(): an AbstractADType backend when linearize is  called, see DifferentiationInterface doc.\n\nExamples\n\njulia> f!(ẋ, x, u, _ , p) = (ẋ .= p*x .+ u; nothing);\n\njulia> h!(y, x, _ , _ ) = (y .= 0.1x; nothing);\n\njulia> model1 = NonLinModel(f!, h!, 5.0, 1, 1, 1, p=-0.2)       # continuous dynamics\nNonLinModel with a sample time Ts = 5.0 s:\n├ solver: RungeKutta(4)\n├ jacobian: AutoForwardDiff\n└ dimensions:\n  ├ 1 manipulated inputs u\n  ├ 1 states x\n  ├ 1 outputs y\n  └ 0 measured disturbances d\n\njulia> f(x, u, _ , _ ) = 0.1x + u;\n\njulia> h(x, _ , _ ) = 2x;\n\njulia> model2 = NonLinModel(f, h, 2.0, 1, 1, 1, solver=nothing) # discrete dynamics\nNonLinModel with a sample time Ts = 2.0 s:\n├ solver: EmptySolver\n├ jacobian: AutoForwardDiff\n└ dimensions:\n  ├ 1 manipulated inputs u\n  ├ 1 states x\n  ├ 1 outputs y\n  └ 0 measured disturbances d\n\nExtended Help\n\ndetails: Extended Help\nState-space functions are similar for discrete dynamics:beginaligned\n    mathbfx(k+1) = mathbffBig( mathbfx(k) mathbfu(k) mathbfd(k) mathbfp Big) \n    mathbfy(k)   = mathbfhBig( mathbfx(k) mathbfd(k) mathbfp Big)\nendalignedwith two possible implementations as well:Non-mutating functions: define them as f(x, u, d, p) -> xnext and  h(x, d, p) -> y.\nMutating functions: define them as f!(xnext, x, u, d, p) -> nothing and h!(y, x, d, p) -> nothing.If the dynamics are a function of the time, simply add a measured disturbance defined as d(t) = t. This package does not support the mathbfu argument in mathbfh function, see the Extended Help of LinModel for the justification.\n\n\n\n\n\n","category":"type"},{"location":"public/sim_model/#ModelPredictiveControl.setname!","page":"Plant Models","title":"ModelPredictiveControl.setname!","text":"setname!(model::SimModel; u=nothing, y=nothing, d=nothing, x=nothing) -> model\n\nSet the names of model inputs u, outputs y, disturbances d, and states x.\n\nThe keyword arguments u, y, d, and x must be vectors of strings. The strings are used in the plotting functions.\n\nExamples\n\njulia> model = setname!(LinModel(tf(3, [10, 1]), 2.0), u=[\"\\$A\\$ (%)\"], y=[\"\\$T\\$ (∘C)\"])\nLinModel with a sample time Ts = 2.0 s:\n└ dimensions:\n  ├ 1 manipulated inputs u\n  ├ 1 states x\n  ├ 1 outputs y\n  └ 0 measured disturbances d\n\n\n\n\n\n","category":"function"},{"location":"public/sim_model/#ModelPredictiveControl.setop!","page":"Plant Models","title":"ModelPredictiveControl.setop!","text":"setop!(model; uop=nothing, yop=nothing, dop=nothing, xop=nothing, fop=nothing) -> model\n\nSet the operating points of model (both LinModel and NonLinModel).\n\nIntroducing deviations vectors around manipulated input uop, model output yop, measured disturbance dop, and model state xop operating points (a.k.a. nominal values):\n\nbeginalign*\n    mathbfu_0(k) = mathbfu(k) - mathbfu_op \n    mathbfd_0(k) = mathbfd(k) - mathbfd_op \n    mathbfy_0(k) = mathbfy(k) - mathbfy_op \n    mathbfx_0(k) = mathbfx(k) - mathbfx_op \nendalign*\n\nThe state-space description of LinModel around the operating points is:\n\nbeginaligned\n    mathbfx_0(k+1) = mathbfA x_0(k) + mathbfB_u u_0(k) + mathbfB_d d_0(k) \n                         + mathbff_op   - mathbfx_op                                              \n    mathbfy_0(k)   = mathbfC x_0(k) + mathbfD_d d_0(k) \nendaligned\n\nand, for NonLinModel:\n\nbeginaligned\n    mathbfx_0(k+1) = mathbffBig(mathbfx_0(k) mathbfu_0(k) mathbfd_0(k) mathbfpBig) \n                            + mathbff_op - mathbfx_op                                             \n    mathbfy_0(k)   = mathbfhBig(mathbfx_0(k) mathbfd_0(k) mathbfpBig)\nendaligned\n\nThe state xop and the additional fop operating points are frequently zero e.g.: when  model comes from system identification. The two vectors are internally used by linearize for non-equilibrium points.\n\nExamples\n\njulia> model = setop!(LinModel(tf(3, [10, 1]), 2.0), uop=[50], yop=[20])\nLinModel with a sample time Ts = 2.0 s:\n└ dimensions:\n  ├ 1 manipulated inputs u\n  ├ 1 states x\n  ├ 1 outputs y\n  └ 0 measured disturbances d\n\njulia> y = model()\n1-element Vector{Float64}:\n 20.0\n\n\n\n\n\n","category":"function"},{"location":"public/sim_model/#ModelPredictiveControl.linearize","page":"Plant Models","title":"ModelPredictiveControl.linearize","text":"linearize(model::SimModel; x=model.x0+model.xop, u=model.uop, d=model.dop) -> linmodel\n\nLinearize model at the operating points x, u, d and return the LinModel.\n\nThe arguments x, u and d are the linearization points for the state mathbfx, manipulated input mathbfu and measured disturbance mathbfd, respectively (not necessarily an equilibrium, details in Extended Help). By default, ForwardDiff automatically computes the Jacobians of mathbff and mathbfh functions. Modify the jacobian keyword argument at the construction of model to swap the backend.\n\nwarning: Warning\nSee Extended Help if you get an error like:     MethodError: no method matching (::var\"##\")(::Vector{ForwardDiff.Dual}).\n\nExamples\n\njulia> model = NonLinModel((x,u,_,_)->x.^3 + u, (x,_,_)->x, 0.1, 1, 1, 1, solver=nothing);\n\njulia> linmodel = linearize(model, x=[10.0], u=[0.0]); \n\njulia> linmodel.A\n1×1 Matrix{Float64}:\n 300.0\n\nExtended Help\n\ndetails: Extended Help\nWith the nonlinear state-space model:beginaligned\n    mathbfx(k+1) = mathbffBig(mathbfx(k) mathbfu(k) mathbfd(k) mathbfpBig)  \n    mathbfy(k)   = mathbfhBig(mathbfx(k) mathbfd(k) mathbfpBig)\nendalignedits linearization at the operating point mathbfx_op u_op d_op is:beginaligned\n    mathbfx_0(k+1)  mathbfA x_0(k) + mathbfB_u u_0(k) + mathbfB_d d_0(k)  \n                        + mathbff(x_op u_op d_op p) - mathbfx_op         \n    mathbfy_0(k)    mathbfC x_0(k) + mathbfD_d d_0(k) \nendalignedbased on the deviation vectors mathbfx_0 u_0 d_0 y_0 introduced in setop! documentation, and the Jacobian matrices:beginaligned\n    mathbfA   = left fracmathbff(x u d p)mathbfx right_mathbfx=x_op u=u_op d=d_op \n    mathbfB_u = left fracmathbff(x u d p)mathbfu right_mathbfx=x_op u=u_op d=d_op \n    mathbfB_d = left fracmathbff(x u d p)mathbfd right_mathbfx=x_op u=u_op d=d_op \n    mathbfC   = left fracmathbfh(x d p)mathbfx    right_mathbfx=x_op d=d_op             \n    mathbfD_d = left fracmathbfh(x d p)mathbfd    right_mathbfx=x_op d=d_op\nendalignedFollowing setop! notation, we find:beginaligned\n    mathbff_op = mathbff(x_op u_op d_op p) \n    mathbfy_op = mathbfh(x_op d_op p)\nendalignedNotice that mathbff_op - x_op = 0 if the point is an equilibrium. The  equations are similar if the nonlinear model has nonzero operating points.Automatic differentiation (AD) allows exact Jacobians. The NonLinModel f and h functions must be compatible with this feature though. See JuMP documentation for common mistakes when writing these functions.\n\n\n\n\n\n","category":"function"},{"location":"public/sim_model/#ModelPredictiveControl.linearize!","page":"Plant Models","title":"ModelPredictiveControl.linearize!","text":"linearize!(linmodel::LinModel, model::SimModel; <keyword arguments>) -> linmodel\n\nLinearize model and store the result in linmodel (in-place).\n\nThe keyword arguments are identical to linearize. The code is allocation-free if model simulations does not allocate.\n\nExamples\n\njulia> model = NonLinModel((x,u,_,_)->x.^3 + u, (x,_,_)->x, 0.1, 1, 1, 1, solver=nothing);\n\njulia> linmodel = linearize(model, x=[10.0], u=[0.0]); linmodel.A\n1×1 Matrix{Float64}:\n 300.0\n\njulia> linearize!(linmodel, model, x=[20.0], u=[0.0]); linmodel.A\n1×1 Matrix{Float64}:\n 1200.0\n\n\n\n\n\n","category":"function"},{"location":"public/sim_model/#ModelPredictiveControl.DiffSolver","page":"Plant Models","title":"ModelPredictiveControl.DiffSolver","text":"Abstract supertype of all differential equation solvers.\n\n\n\n\n\n","category":"type"},{"location":"public/sim_model/#ModelPredictiveControl.RungeKutta","page":"Plant Models","title":"ModelPredictiveControl.RungeKutta","text":"RungeKutta(order=4; supersample=1)\n\nCreate an explicit Runge-Kutta solver with optional super-sampling.\n\nThe argument order specifies the order of the Runge-Kutta solver, which must be 1 or 4. The keyword argument supersample provides the number of internal steps (default to 1 step). This solver is allocation-free if the f! and h! functions do not allocate.\n\n\n\n\n\n","category":"type"},{"location":"public/sim_model/#ModelPredictiveControl.ForwardEuler","page":"Plant Models","title":"ModelPredictiveControl.ForwardEuler","text":"ForwardEuler(; supersample=1)\n\nCreate a Forward Euler solver with optional super-sampling.\n\nThis is an alias for RungeKutta(1; supersample), see RungeKutta.\n\n\n\n\n\n","category":"function"},{"location":"public/predictive_control/#Functions:-Predictive-Controllers","page":"Predictive Controllers","title":"Functions: Predictive Controllers","text":"Pages = [\"predictive_control.md\"]\n\nAll the predictive controllers in this module rely on a state estimator to compute the predictions. The default LinMPC estimator is a SteadyKalmanFilter, and NonLinMPC with nonlinear models, an UnscentedKalmanFilter. For simpler and more classical designs, an InternalModel structure is also available, that assumes by default that the current model mismatch estimation is constant in the future (same approach as dynamic matrix control, DMC).\n\ninfo: Info\nThe nomenclature uses boldfaces for vectors or matrices, capital boldface letters for vectors representing time series (and also for matrices), and hats for the predictions (and also for the observer estimations).\n\nTo be precise, at the kth control period, the vectors that encompass the future measured disturbances mathbfd̂, model outputs mathbfŷ and setpoints mathbfr̂_y over the prediction horizon H_p are defined as:\n\n    mathbfD̂ = beginbmatrix\n        mathbfd̂(k+1)    mathbfd̂(k+2)    vdots   mathbfd̂(k+H_p)\n    endbmatrix   quad\n    mathbfŶ = beginbmatrix\n        mathbfŷ(k+1)    mathbfŷ(k+2)    vdots   mathbfŷ(k+H_p)\n    endbmatrix quad textand quad\n    mathbfR̂_y = beginbmatrix\n        mathbfr̂_y(k+1)  mathbfr̂_y(k+2)  vdots   mathbfr̂_y(k+H_p)\n    endbmatrix\n\nin which mathbfD̂, mathbfŶ and  mathbfR̂_y are vectors of nd*Hp, ny*Hp and ny*Hp elements, respectively. The vectors for the manipulated input mathbfu are shifted by one time step:\n\n    mathbfU = beginbmatrix\n        mathbfu(k+0)    mathbfu(k+1)    vdots   mathbfu(k+H_p-1)\n    endbmatrix quad textand quad\n    mathbfR̂_u = beginbmatrix\n        mathbfr̂_u(k+0)  mathbfr̂_u(k+1)  vdots   mathbfr̂_u(k+H_p-1)\n    endbmatrix\n\nin which mathbfU and mathbfR̂_u are both vectors of nu*Hp elements. Defining the manipulated input increment as mathbfΔu(k+j) = mathbfu(k+j) - mathbfu(k+j-1), the control horizon H_c enforces that mathbfΔu(k+j) = mathbf0 for j  H_c. For this reason, the vector that collects them is truncated up to k+H_c-1 (without any custom move blocking):\n\n    mathbfΔU =\n    beginbmatrix\n        mathbfΔu(k+0)  mathbfΔu(k+1)  vdots   mathbfΔu(k+H_c-1)\n    endbmatrix\n\nin which mathbfΔU is a vector of nu*Hc elements.","category":"section"},{"location":"public/predictive_control/#PredictiveController","page":"Predictive Controllers","title":"PredictiveController","text":"","category":"section"},{"location":"public/predictive_control/#LinMPC","page":"Predictive Controllers","title":"LinMPC","text":"","category":"section"},{"location":"public/predictive_control/#ExplicitMPC","page":"Predictive Controllers","title":"ExplicitMPC","text":"","category":"section"},{"location":"public/predictive_control/#NonLinMPC","page":"Predictive Controllers","title":"NonLinMPC","text":"","category":"section"},{"location":"public/predictive_control/#Move-Manipulated-Input-u","page":"Predictive Controllers","title":"Move Manipulated Input u","text":"","category":"section"},{"location":"public/predictive_control/#Direct-Transcription-Methods","page":"Predictive Controllers","title":"Direct Transcription Methods","text":"","category":"section"},{"location":"public/predictive_control/#TranscriptionMethod","page":"Predictive Controllers","title":"TranscriptionMethod","text":"","category":"section"},{"location":"public/predictive_control/#SingleShooting","page":"Predictive Controllers","title":"SingleShooting","text":"","category":"section"},{"location":"public/predictive_control/#MultipleShooting","page":"Predictive Controllers","title":"MultipleShooting","text":"","category":"section"},{"location":"public/predictive_control/#TrapezoidalCollocation","page":"Predictive Controllers","title":"TrapezoidalCollocation","text":"","category":"section"},{"location":"public/predictive_control/#ModelPredictiveControl.PredictiveController","page":"Predictive Controllers","title":"ModelPredictiveControl.PredictiveController","text":"Abstract supertype of all predictive controllers.\n\n\n\n(mpc::PredictiveController)(ry, d=[]; kwargs...) -> u\n\nFunctor allowing callable PredictiveController object as an alias for moveinput!.\n\nExamples\n\njulia> mpc = LinMPC(LinModel(tf(5, [2, 1]), 3), Nwt=[0], Hp=1000, Hc=1, direct=false);\n\njulia> u = mpc([5]); round.(u, digits=3)\n1-element Vector{Float64}:\n 1.0\n\n\n\n\n\n","category":"type"},{"location":"public/predictive_control/#ModelPredictiveControl.LinMPC","page":"Predictive Controllers","title":"ModelPredictiveControl.LinMPC","text":"LinMPC(model::LinModel; <keyword arguments>)\n\nConstruct a linear predictive controller based on LinModel model.\n\nThe controller minimizes the following objective function at each discrete time k:\n\nbeginaligned\nmin_mathbfZ ϵ    mathbf(R̂_y - Ŷ) mathbfM_H_p mathbf(R̂_y - Ŷ)\n                      + mathbf(ΔU)      mathbfN_H_c mathbf(ΔU)        \n                      + mathbf(R̂_u - U) mathbfL_H_p mathbf(R̂_u - U) \n                      + C ϵ^2\nendaligned\n\nsubject to setconstraint! bounds, and in which the weight matrices are repeated  H_p or H_c times by default:\n\nbeginaligned\n    mathbfM_H_p = textdiagmathbf(MMM)     \n    mathbfN_H_c = textdiagmathbf(NNN)     \n    mathbfL_H_p = textdiagmathbf(LLL)     \nendaligned\n\nTime-varying and non-diagonal weights are also supported. Modify the last block in  mathbfM_H_p to specify a terminal weight. The content of the decision vector mathbfZ depends on the chosen TranscriptionMethod (default to SingleShooting, hence mathbfZ = ΔU). The mathbfΔU includes the input increments mathbfΔu(k+j) = mathbfu(k+j) - mathbfu(k+j-1) from j=0 to H_c-1, the mathbfŶ vector, the output predictions mathbfŷ(k+j) from j=1 to H_p, and the mathbfU vector, the manipulated inputs mathbfu(k+j) from j=0 to H_p-1. The slack variable ϵ relaxes the constraints, as described in setconstraint! documentation. See Extended Help for a detailed nomenclature. \n\nThis method uses the default state estimator, a SteadyKalmanFilter with default arguments. This controller allocates memory at each time step for the optimization.\n\nArguments\n\nmodel::LinModel : model used for controller predictions and state estimations.\nHp::Int=10+nk : prediction horizon H_p, nk is the number of delays in model.\nHc::Union{Int, Vector{Int}}=2 : control horizon H_c, custom move blocking pattern is   specified with a vector of integers (see move_blocking for details).\nMwt=fill(1.0,model.ny) : main diagonal of mathbfM weight matrix (vector).\nNwt=fill(0.1,model.nu) : main diagonal of mathbfN weight matrix (vector).\nLwt=fill(0.0,model.nu) : main diagonal of mathbfL weight matrix (vector).\nM_Hp=Diagonal(repeat(Mwt,Hp)) : positive semidefinite symmetric matrix mathbfM_H_p.\nN_Hc=Diagonal(repeat(Nwt,Hc)) : positive semidefinite symmetric matrix mathbfN_H_c.\nL_Hp=Diagonal(repeat(Lwt,Hp)) : positive semidefinite symmetric matrix mathbfL_H_p.\nCwt=1e5 : slack variable weight C (scalar), use Cwt=Inf for hard constraints only.\ntranscription=SingleShooting() : SingleShooting or MultipleShooting.\noptim=JuMP.Model(OSQP.MathOptInterfaceOSQP.Optimizer) : quadratic optimizer used in the predictive controller, provided as a JuMP.Model object (default to  OSQP optimizer).\nadditional keyword arguments are passed to SteadyKalmanFilter constructor.\n\nExamples\n\njulia> model = LinModel([tf(3, [30, 1]); tf(-2, [5, 1])], 4);\n\njulia> mpc = LinMPC(model, Mwt=[0, 1], Nwt=[0.5], Hp=30, Hc=1)\nLinMPC controller with a sample time Ts = 4.0 s:\n├ estimator: SteadyKalmanFilter\n├ model: LinModel\n├ optimizer: OSQP\n├ transcription: SingleShooting\n└ dimensions:\n  ├ 30 prediction steps Hp\n  ├  1 control steps Hc\n  ├  1 slack variable ϵ (control constraints)\n  ├  1 manipulated inputs u (0 integrating states)\n  ├  4 estimated states x̂\n  ├  2 measured outputs ym (2 integrating states)\n  ├  0 unmeasured outputs yu\n  └  0 measured disturbances d\n\nExtended Help\n\ndetails: Extended Help\nManipulated inputs setpoints mathbfr_u are not common but they can be interesting for over-actuated systems, when nu > ny (e.g. prioritize solutions with lower  economical costs). The default Lwt value implies that this feature is disabled by default.The objective function follows this nomenclature:VARIABLE DESCRIPTION SIZE\nH_p prediction horizon (integer) ()\nH_c control horizon (integer) ()\nmathbfZ decision variable vector (excluding ϵ) var.\nmathbfΔU manipulated input increments over H_c (nu*Hc,)\nmathbfD̂ predicted measured disturbances over H_p (nd*Hp,)\nmathbfŶ predicted outputs over H_p (ny*Hp,)\nmathbfX̂ predicted states over H_p (nx̂*Hp,)\nmathbfU manipulated inputs over H_p (nu*Hp,)\nmathbfR̂_y predicted output setpoints over H_p (ny*Hp,)\nmathbfR̂_u predicted manipulated input setpoints over H_p (nu*Hp,)\nmathbfM_H_p output setpoint tracking weights over H_p (ny*Hp, ny*Hp)\nmathbfN_H_c manipulated input increment weights over H_c (nu*Hc, nu*Hc)\nmathbfL_H_p manipulated input setpoint tracking weights over H_p (nu*Hp, nu*Hp)\nC slack variable weight ()\nϵ slack variable for constraint softening ()\n\n\n\n\n\nLinMPC(estim::StateEstimator; <keyword arguments>)\n\nUse custom state estimator estim to construct LinMPC.\n\nestim.model must be a LinModel. Else, a NonLinMPC is required. See ManualEstimator for linear controllers with nonlinear state estimation.\n\nExamples\n\njulia> estim = KalmanFilter(LinModel([tf(3, [30, 1]); tf(-2, [5, 1])], 4), i_ym=[2]);\n\njulia> mpc = LinMPC(estim, Mwt=[0, 1], Nwt=[0.5], Hp=30, Hc=1)\nLinMPC controller with a sample time Ts = 4.0 s:\n├ estimator: KalmanFilter\n├ model: LinModel\n├ optimizer: OSQP\n├ transcription: SingleShooting\n└ dimensions:\n  ├ 30 prediction steps Hp\n  ├  1 control steps Hc\n  ├  1 slack variable ϵ (control constraints)\n  ├  1 manipulated inputs u (0 integrating states)\n  ├  3 estimated states x̂\n  ├  1 measured outputs ym (1 integrating states)\n  ├  1 unmeasured outputs yu\n  └  0 measured disturbances d\n\n\n\n\n\n","category":"type"},{"location":"public/predictive_control/#ModelPredictiveControl.ExplicitMPC","page":"Predictive Controllers","title":"ModelPredictiveControl.ExplicitMPC","text":"ExplicitMPC(model::LinModel; <keyword arguments>)\n\nConstruct an explicit linear predictive controller based on LinModel model.\n\nThe controller minimizes the following objective function at each discrete time k:\n\nbeginaligned\nmin_mathbfΔU   mathbf(R̂_y - Ŷ) mathbfM_H_p mathbf(R̂_y - Ŷ)     \n                   + mathbf(ΔU)      mathbfN_H_c mathbf(ΔU)        \n                   + mathbf(R̂_u - U) mathbfL_H_p mathbf(R̂_u - U) \nendaligned\n\nSee LinMPC for the variable definitions. This controller does not support constraints but the computational costs are extremely low (array division), therefore  suitable for applications that require small sample times. The keyword arguments are identical to LinMPC, except for Cwt, transcription and optim, which are not supported. It uses a SingleShooting transcription method and is allocation-free.\n\nThis method uses the default state estimator, a SteadyKalmanFilter with default arguments. \n\nExamples\n\njulia> model = LinModel([tf(3, [30, 1]); tf(-2, [5, 1])], 4);\n\njulia> mpc = ExplicitMPC(model, Mwt=[0, 1], Nwt=[0.5], Hp=30, Hc=1)\nExplicitMPC controller with a sample time Ts = 4.0 s:\n├ estimator: SteadyKalmanFilter\n├ model: LinModel\n└ dimensions:\n  ├  1 manipulated inputs u (0 integrating states)\n  ├  4 estimated states x̂\n  ├  2 measured outputs ym (2 integrating states)\n  ├  0 unmeasured outputs yu\n  └  0 measured disturbances d\n\n\n\n\n\nExplicitMPC(estim::StateEstimator; <keyword arguments>)\n\nUse custom state estimator estim to construct ExplicitMPC.\n\nestim.model must be a LinModel. Else, a NonLinMPC is required.\n\n\n\n\n\n","category":"type"},{"location":"public/predictive_control/#ModelPredictiveControl.NonLinMPC","page":"Predictive Controllers","title":"ModelPredictiveControl.NonLinMPC","text":"NonLinMPC(model::SimModel; <keyword arguments>)\n\nConstruct a nonlinear predictive controller based on SimModel model.\n\nBoth NonLinModel and LinModel are supported (see Extended Help). The  controller minimizes the following objective function at each discrete time k:\n\nbeginaligned\nmin_mathbfZ ϵ   mathbf(R̂_y - Ŷ) mathbfM_H_p mathbf(R̂_y - Ŷ)   \n                       + mathbf(ΔU)      mathbfN_H_c mathbf(ΔU)        \n                       + mathbf(R̂_u - U) mathbfL_H_p mathbf(R̂_u - U) \n                       + C ϵ^2  \n                       + E J_E(mathbfU_e mathbfŶ_e mathbfD̂_e mathbfp)\nendaligned\n\nsubject to setconstraint! bounds, and the custom inequality constraints:\n\nmathbfg_c(mathbfU_e mathbfŶ_e mathbfD̂_e mathbfp ϵ)  mathbf0\n\nwith the decision variables mathbfZ and slack ϵ. By default, a SingleShooting transcription method is used, hence mathbfZ=ΔU. The economic function J_E can penalizes solutions with high economic costs. Setting all the weights to 0 except E creates a pure economic model predictive controller (EMPC). As a matter of fact, J_E can be any nonlinear function as a custom objective, even if there is no economic interpretation to it. The arguments of J_E and mathbfg_c include the manipulated inputs, predicted outputs and measured disturbances, extended from k to k+H_p (inclusively, see Extended Help for more details):\n\n    mathbfU_e = beginbmatrix mathbfU       mathbfu(k+H_p-1)   endbmatrix   quad\n    mathbfŶ_e = beginbmatrix mathbfŷ(k)    mathbfŶ            endbmatrix   quad\n    mathbfD̂_e = beginbmatrix mathbfd(k)    mathbfD̂            endbmatrix\n\nThe argument mathbfp is a custom parameter object of any type, but use a mutable one if you want to modify it later e.g.: a vector. See LinMPC Extended Help for the definition of the other variables.\n\ntip: Tip\nReplace any of the arguments of J_E and mathbfg_c functions with _ if not needed (see e.g. the default value of JE below).\n\nThis method uses the default state estimator:\n\nif model is a LinModel, a SteadyKalmanFilter with default arguments;\nelse, an UnscentedKalmanFilter with default arguments. \n\nThis controller allocates memory at each time step for the optimization.\n\nwarning: Warning\nSee Extended Help if you get an error like:     MethodError: no method matching Float64(::ForwardDiff.Dual).\n\nArguments\n\nmodel::SimModel : model used for controller predictions and state estimations.\nHp::Int=10+nk : prediction horizon H_p, nk is the number of delays if model is a  LinModel (must be specified otherwise).\nHc::Union{Int, Vector{Int}}=2 : control horizon H_c, custom move blocking pattern is   specified with a vector of integers (see move_blocking for details).\nMwt=fill(1.0,model.ny) : main diagonal of mathbfM weight matrix (vector).\nNwt=fill(0.1,model.nu) : main diagonal of mathbfN weight matrix (vector).\nLwt=fill(0.0,model.nu) : main diagonal of mathbfL weight matrix (vector).\nM_Hp=Diagonal(repeat(Mwt,Hp)) : positive semidefinite symmetric matrix mathbfM_H_p.\nN_Hc=Diagonal(repeat(Nwt,Hc)) : positive semidefinite symmetric matrix mathbfN_H_c.\nL_Hp=Diagonal(repeat(Lwt,Hp)) : positive semidefinite symmetric matrix mathbfL_H_p.\nCwt=1e5 : slack variable weight C (scalar), use Cwt=Inf for hard constraints only.\nEwt=0.0 : economic costs weight E (scalar). \nJE=(_,_,_,_)->0.0 : economic or custom cost function J_E(mathbfU_e mathbfŶ_e  mathbfD̂_e mathbfp).\ngc=(_,_,_,_,_,_)->nothing or gc! : custom inequality constraint function   mathbfg_c(mathbfU_e mathbfŶ_e mathbfD̂_e mathbfp ϵ), mutating or   not (details in Extended Help).\nnc=0 : number of custom inequality constraints.\np=model.p : J_E and mathbfg_c functions parameter mathbfp (any type).\ntranscription=SingleShooting() : a TranscriptionMethod for the optimization.\noptim=JuMP.Model(Ipopt.Optimizer) : nonlinear optimizer used in the predictive  controller, provided as a JuMP.Model object (default to Ipopt optimizer).\ngradient=AutoForwardDiff() : an AbstractADType backend for the gradient of the objective  function, see DifferentiationInterface doc.\njacobian=default_jacobian(transcription) : an AbstractADType backend for the Jacobian  of the nonlinear constraints, see gradient above for the options (default in Extended Help).\nhessian=false : an AbstractADType backend or Bool for the Hessian of the Lagrangian,   see gradient above for the options. The default false skip it and use the quasi-Newton  method of optim, which is always the case if oracle=false (see Extended Help).\noracle=JuMP.solver_name(optim)==\"Ipopt\" : a Bool to use the VectorNonlinearOracle  for efficient nonlinear constraints (not supported by most optimizers for now).\nadditional keyword arguments are passed to UnscentedKalmanFilter constructor  (or SteadyKalmanFilter, for LinModel).\n\nExamples\n\njulia> model = NonLinModel((x,u,_,_)->0.5x+u, (x,_,_)->2x, 10.0, 1, 1, 1, solver=nothing);\n\njulia> mpc = NonLinMPC(model, Hp=20, Hc=10, transcription=MultipleShooting())\nNonLinMPC controller with a sample time Ts = 10.0 s:\n├ estimator: UnscentedKalmanFilter\n├ model: NonLinModel\n├ optimizer: Ipopt \n├ transcription: MultipleShooting\n├ gradient: AutoForwardDiff\n├ jacobian: AutoSparse (AutoForwardDiff, TracerSparsityDetector, GreedyColoringAlgorithm)\n├ hessian: nothing\n└ dimensions:\n  ├ 20 prediction steps Hp\n  ├ 10 control steps Hc\n  ├  1 slack variable ϵ (control constraints)\n  ├  1 manipulated inputs u (0 integrating states)\n  ├  2 estimated states x̂\n  ├  1 measured outputs ym (1 integrating states)\n  ├  0 unmeasured outputs yu\n  └  0 measured disturbances d\n\nExtended Help\n\ndetails: Extended Help\nNonLinMPC controllers based on LinModel compute the predictions with matrix  algebra instead of a for loop. This feature can accelerate the optimization, especially for the constraint handling, and is not available in any other package, to my knowledge.The economic cost J_E and custom constraint mathbfg_c functions receive the extended vectors mathbfU_e (nu*Hp+nu elements), mathbfŶ_e (ny+ny*Hp elements) and  mathbfD̂_e (nd+nd*Hp elements) as arguments. They all include the values from k to k + H_p (inclusively). The custom constraint also receives the slack ϵ (scalar), which is always zero if Cwt=Inf.More precisely, the last two time steps in mathbfU_e are forced to be equal, i.e. mathbfu(k+H_p) = mathbfu(k+H_p-1), since H_c  H_p implies that mathbfΔu(k+H_p) = mathbf0. The vectors mathbfŷ(k) and mathbfd(k) are the current state estimator output and measured disturbance, respectively, and  mathbfŶ and mathbfD̂, their respective predictions from k+1 to k+H_p.  If LHS represents the result of the left-hand side in the inequality  mathbfg_c(mathbfU_e mathbfŶ_e mathbfD̂_e mathbfp ϵ)  mathbf0, the function gc can be implemented in two possible ways:Non-mutating function (out-of-place): define it as gc(Ue, Ŷe, D̂e, p, ϵ) -> LHS. This syntax is simple and intuitive but it allocates more memory.\nMutating function (in-place): define it as gc!(LHS, Ue, Ŷe, D̂e, p, ϵ) -> nothing. This syntax reduces the allocations and potentially the computational burden as well.The keyword argument nc is the number of elements in LHS, and gc!, an alias for the gc argument (both gc and gc! accepts non-mutating and mutating functions). By default, the optimization relies on dense ForwardDiff automatic differentiation (AD) to compute the objective and constraint derivatives. Two exceptions: if transcription is not a SingleShooting, the jacobian argument defaults to this sparse backend:AutoSparse(\n    AutoForwardDiff(); \n    sparsity_detector  = TracerSparsityDetector(), \n    coloring_algorithm = GreedyColoringAlgorithm(\n        (\n        NaturalOrder(),\n        LargestFirst(),\n        SmallestLast(),\n        IncidenceDegree(),\n        DynamicLargestFirst()\n        ), \n    postprocessing = true\n    )\n)that is, it will test many coloring orders at preparation and keep the best. This is also the sparse backend selected for the Hessian of the Lagrangian function if  oracle=true and hessian=true, which is the second exception. Second order  derivatives are only supported with oracle=true option.Optimizers generally benefit from exact derivatives like AD. However, the NonLinModel  state-space functions must be compatible with this feature. See JuMP documentation for common mistakes when writing these functions.Note that if Cwt≠Inf, the attribute nlp_scaling_max_gradient of Ipopt is set to  10/Cwt (if not already set), to scale the small values of ϵ.\n\n\n\n\n\nNonLinMPC(estim::StateEstimator; <keyword arguments>)\n\nUse custom state estimator estim to construct NonLinMPC.\n\nExamples\n\njulia> model = NonLinModel((x,u,_,_)->0.5x+u, (x,_,_)->2x, 10.0, 1, 1, 1, solver=nothing);\n\njulia> estim = UnscentedKalmanFilter(model, σQint_ym=[0.05]);\n\njulia> mpc = NonLinMPC(estim, Hp=20, Cwt=1e6)\nNonLinMPC controller with a sample time Ts = 10.0 s:\n├ estimator: UnscentedKalmanFilter\n├ model: NonLinModel\n├ optimizer: Ipopt \n├ transcription: SingleShooting\n├ gradient: AutoForwardDiff\n├ jacobian: AutoForwardDiff\n├ hessian: nothing\n└ dimensions:\n  ├ 20 prediction steps Hp\n  ├  2 control steps Hc\n  ├  1 slack variable ϵ (control constraints)\n  ├  1 manipulated inputs u (0 integrating states)\n  ├  2 estimated states x̂\n  ├  1 measured outputs ym (1 integrating states)\n  ├  0 unmeasured outputs yu\n  └  0 measured disturbances d\n\n\n\n\n\n","category":"type"},{"location":"public/predictive_control/#ModelPredictiveControl.moveinput!","page":"Predictive Controllers","title":"ModelPredictiveControl.moveinput!","text":"moveinput!(mpc::PredictiveController, ry=mpc.estim.model.yop, d=[]; <keyword args>) -> u\n\nCompute the optimal manipulated input value u for the current control period.\n\nSolve the optimization problem of mpc PredictiveController and return the results mathbfu(k). Following the receding horizon principle, the algorithm discards the optimal future manipulated inputs mathbfu(k+1) mathbfu(k+2)  Note that the method mutates mpc internal data (it stores u - mpc.estim.model.uop at mpc.lastu0 for instance) but it does not modifies mpc.estim states. Call preparestate!(mpc, ym, d) before moveinput!, and updatestate!(mpc, u, ym, d) after, to update mpc state estimates. Setpoint and measured disturbance previews can be implemented with the R̂y, R̂u and D̂ keyword arguments. \n\nCalling a PredictiveController object calls this method.\n\nSee also LinMPC, ExplicitMPC, NonLinMPC.\n\nArguments\n\ninfo: Info\nKeyword arguments with emphasis are non-Unicode alternatives.\n\nmpc::PredictiveController : solve optimization problem of mpc.\nry=mpc.estim.model.yop : current output setpoints mathbfr_y(k).\nd=[] : current measured disturbances mathbfd(k).\nlastu=mpc.lastu0+mpc.estim.model.uop: last manipulated input mathbfu(k-1).\nD̂=repeat(d, mpc.Hp) or Dhat : predicted measured disturbances mathbfD̂, constant  in the future by default or mathbfd̂(k+j)=mathbfd(k) for j=1 to H_p.\nR̂y=repeat(ry, mpc.Hp) or Rhaty : predicted output setpoints mathbfR̂_y, constant  in the future by default or mathbfr̂_y(k+j)=mathbfr_y(k) for j=1 to H_p.\nR̂u=mpc.Uop or Rhatu : predicted manipulated input setpoints mathbfR̂_u, constant  in the future by default or mathbfr̂_u(k+j)=mathbfu_op for j=0 to H_p-1. \n\nExamples\n\njulia> mpc = LinMPC(LinModel(tf(5, [2, 1]), 3), Nwt=[0], Hp=1000, Hc=1);\n\njulia> preparestate!(mpc, [0]); ry = [5];\n\njulia> u = moveinput!(mpc, ry); round.(u, digits=3)\n1-element Vector{Float64}:\n 1.0\n\n\n\n\n\n","category":"function"},{"location":"public/predictive_control/#ModelPredictiveControl.TranscriptionMethod","page":"Predictive Controllers","title":"ModelPredictiveControl.TranscriptionMethod","text":"Abstract supertype of all transcription methods of PredictiveController.\n\nThe module currently supports SingleShooting, MultipleShooting and TrapezoidalCollocation transcription methods.\n\n\n\n\n\n","category":"type"},{"location":"public/predictive_control/#ModelPredictiveControl.SingleShooting","page":"Predictive Controllers","title":"ModelPredictiveControl.SingleShooting","text":"SingleShooting()\n\nConstruct a direct single shooting TranscriptionMethod.\n\nThe decision variable in the optimization problem is (excluding the slack ϵ and without any custom move blocking):\n\nmathbfZ = mathbfΔU =          beginbmatrix \n    mathbfΔu(k+0)                 \n    mathbfΔu(k+1)                 \n    vdots                           \n    mathbfΔu(k+H_c-1)            endbmatrix\n\nThis method computes the predictions by calling the augmented discrete-time model recursively over the prediction horizon H_p in the objective function, or by updating the linear coefficients of the quadratic optimization for LinModel. It is  generally  more efficient for small control horizon H_c, stable and mildly nonlinear plant model/constraints.\n\n\n\n\n\n","category":"type"},{"location":"public/predictive_control/#ModelPredictiveControl.MultipleShooting","page":"Predictive Controllers","title":"ModelPredictiveControl.MultipleShooting","text":"MultipleShooting(; f_threads=false, h_threads=false)\n\nConstruct a direct multiple shooting TranscriptionMethod.\n\nThe decision variable is (excluding ϵ):\n\nmathbfZ = beginbmatrix mathbfΔU  mathbfX̂_0 endbmatrix\n\nthus it also includes the predicted states, expressed as deviation vectors from the operating point mathbfx̂_op (see augment_model):\n\nmathbfX̂_0 = mathbfX̂ - X̂_op =            beginbmatrix \n    mathbfx̂_i(k+1)     - mathbfx̂_op      \n    mathbfx̂_i(k+2)     - mathbfx̂_op      \n    vdots                                       \n    mathbfx̂_i(k+H_p)   - mathbfx̂_op     endbmatrix\n\nwhere mathbfx̂_i(k+j) is the state prediction for time k+j, estimated by the observer at time i=k or i=k-1 depending on its direct flag. Note that  mathbfX̂_0 = X̂ if the operating point is zero, which is typically the case in practice for NonLinModel. \n\nThis transcription computes the predictions by calling the augmented discrete-time model in the equality constraint function recursively over H_p, or by updating the linear equality constraint vector for LinModel. It is generally more efficient for large control horizon H_c, unstable or highly nonlinear models/constraints. Multithreading with f_threads or h_threads keyword arguments can be advantageous if mathbff or  mathbfh in the NonLinModel is expensive to evaluate, respectively.\n\nSparse optimizers like OSQP or Ipopt and sparse Jacobian computations are recommended for this transcription method.\n\n\n\n\n\n","category":"type"},{"location":"public/predictive_control/#ModelPredictiveControl.TrapezoidalCollocation","page":"Predictive Controllers","title":"ModelPredictiveControl.TrapezoidalCollocation","text":"TrapezoidalCollocation(h::Int=0; f_threads=false, h_threads=false)\n\nConstruct an implicit trapezoidal TranscriptionMethod with hth order hold.\n\nThis is the simplest collocation method. It supports continuous-time NonLinModels only. The decision variables are the same as for MultipleShooting, hence similar computational costs. See the same docstring for descriptions of f_threads and h_threads keywords. The h argument is 0 or 1, for piecewise constant or linear manipulated  inputs mathbfu (h=1 is slightly less expensive). Note that the various DiffSolver  here assume zero-order hold, so h=1 will induce a plant-model  mismatch if the plant is simulated with these solvers. \n\nThis transcription computes the predictions by calling the continuous-time model in the equality constraint function and by using the implicit trapezoidal rule. It can handle moderately stiff systems and is A-stable. Note that the built-in StateEstimator will still use the solver provided at the construction of the NonLinModel to estimate the plant states, not the trapezoidal rule (see supersample option of  RungeKutta for stiff systems). See Extended Help for more details.\n\nSparse optimizers like Ipopt and sparse Jacobian computations are recommended for this transcription method.\n\nExtended Help\n\ndetails: Extended Help\nNote that the stochastic model of the unmeasured disturbances is strictly discrete-time, as described in ModelPredictiveControl.init_estimstoch. Collocation methods require continuous-time dynamics. Because of this, the stochastic states are transcribed separately using a MultipleShooting method. See con_nonlinprogeq! for more details.\n\n\n\n\n\n","category":"type"},{"location":"public/generic_func/#Functions:-Generic-Functions","page":"Generic Functions","title":"Functions: Generic Functions","text":"Pages = [\"generic_func.md\"]\n\nThis page contains the documentation of functions that are generic to SimModel, StateEstimator and PredictiveController types.","category":"section"},{"location":"public/generic_func/#Set-Constraint","page":"Generic Functions","title":"Set Constraint","text":"","category":"section"},{"location":"public/generic_func/#Evaluate-Output-y","page":"Generic Functions","title":"Evaluate Output y","text":"","category":"section"},{"location":"public/generic_func/#Change-State-x","page":"Generic Functions","title":"Change State x","text":"","category":"section"},{"location":"public/generic_func/#Prepare-State-x","page":"Generic Functions","title":"Prepare State x","text":"","category":"section"},{"location":"public/generic_func/#Update-State-x","page":"Generic Functions","title":"Update State x","text":"","category":"section"},{"location":"public/generic_func/#Init-State-x","page":"Generic Functions","title":"Init State x","text":"","category":"section"},{"location":"public/generic_func/#Set-State-x","page":"Generic Functions","title":"Set State x","text":"","category":"section"},{"location":"public/generic_func/#Set-Model-and-Weights","page":"Generic Functions","title":"Set Model and Weights","text":"","category":"section"},{"location":"public/generic_func/#Get-Additional-Information","page":"Generic Functions","title":"Get Additional Information","text":"","category":"section"},{"location":"public/generic_func/#Real-Time-Simulate-and-Control","page":"Generic Functions","title":"Real-Time Simulate and Control","text":"danger: Disclaimer\nThese utilities are for soft real-time applications. They are not suitable for hard real-time environnement like safety-critical processes.","category":"section"},{"location":"public/generic_func/#Save-current-time-t","page":"Generic Functions","title":"Save current time t","text":"","category":"section"},{"location":"public/generic_func/#Period-Sleep","page":"Generic Functions","title":"Period Sleep","text":"","category":"section"},{"location":"public/generic_func/#ModelPredictiveControl.setconstraint!","page":"Generic Functions","title":"ModelPredictiveControl.setconstraint!","text":"setconstraint!(estim::MovingHorizonEstimator; <keyword arguments>) -> estim\n\nSet the bound constraint parameters of the MovingHorizonEstimator estim.\n\nIt supports both soft and hard constraints on the estimated state mathbfx̂, process  noise mathbfŵ and sensor noise mathbfv̂:\n\nbeginalignat*3\n    mathbfx̂_min - c_x̂_min ε    mathbfx̂_k(k-j+p)  mathbfx̂_max + c_x̂_max ε qquad  j = N_k N_k - 1   0    \n    mathbfŵ_min - c_ŵ_min ε      mathbfŵ(k-j+p)  mathbfŵ_max + c_ŵ_max ε qquad  j = N_k N_k - 1   1    \n    mathbfv̂_min - c_v̂_min ε      mathbfv̂(k-j+1)  mathbfv̂_max + c_v̂_max ε qquad  j = N_k N_k - 1   1\nendalignat*\n\nand also ε  0. All the constraint parameters are vector. Use ±Inf values when there is no bound. The constraint softness parameters mathbfc, also called equal concern for relaxation, are non-negative values that specify the softness of the associated bound. Use 0.0 values for hard constraints (default for all of them). Notice that constraining the estimated sensor noises is equivalent to bounding the innovation term, since  mathbfv̂(k) = mathbfy^m(k) - mathbfŷ^m(k). See Extended Help for details on the constant p, on model augmentation and on time-varying constraints.\n\nArguments\n\ninfo: Info\nAll the keyword arguments have non-Unicode alternatives e.g. xhatmin or Vhatmax. The default constraints are mentioned here for clarity but omitting a keyword argument  will not re-assign to its default value (defaults are set at construction only).\n\nestim::MovingHorizonEstimator : moving horizon estimator to set constraints\nx̂min=fill(-Inf,nx̂) / x̂max=fill(+Inf,nx̂) : estimated state bound mathbfx̂_minmax\nŵmin=fill(-Inf,nx̂) / ŵmax=fill(+Inf,nx̂) : estimated process noise bound mathbfŵ_minmax\nv̂min=fill(-Inf,nym) / v̂max=fill(+Inf,nym) : estimated sensor noise bound mathbfv̂_minmax\nc_x̂min=fill(0.0,nx̂) / c_x̂max=fill(0.0,nx̂) : x̂min / x̂max softness weight mathbfc_x̂_minmax\nc_ŵmin=fill(0.0,nx̂) / c_ŵmax=fill(0.0,nx̂) : ŵmin / ŵmax softness weight mathbfc_ŵ_minmax\nc_v̂min=fill(0.0,nym) / c_v̂max=fill(0.0,nym) : v̂min / v̂max softness weight mathbfc_v̂_minmax\nall the keyword arguments above but with a first capital letter, e.g. X̂max or C_ŵmax:  for time-varying constraints (see Extended Help)\n\nExamples\n\njulia> estim = MovingHorizonEstimator(LinModel(ss(0.5,1,1,0,1)), He=3);\n\njulia> estim = setconstraint!(estim, x̂min=[-50, -50], x̂max=[50, 50])\nMovingHorizonEstimator estimator with a sample time Ts = 1.0 s:\n├ model: LinModel\n├ optimizer: OSQP\n├ arrival covariance: KalmanFilter\n└ dimensions:\n  ├ 3 estimation steps He\n  ├ 0 slack variable ε (estimation constraints)\n  ├ 1 manipulated inputs u (0 integrating states)\n  ├ 2 estimated states x̂\n  ├ 1 measured outputs ym (1 integrating states)\n  ├ 0 unmeasured outputs yu\n  └ 0 measured disturbances d\n\nExtended Help\n\ndetails: Extended Help\nThe constant p=0 if estim.direct==true (current form), else p=1 (prediction form). Note that the state mathbfx̂ and process noise mathbfŵ constraints are applied on the augmented model, detailed in SteadyKalmanFilter Extended Help. For variable constraints, the bounds can be modified after calling updatestate!, that is, at runtime, except for ±Inf bounds. Time-varying constraints over the estimation horizon H_e are also possible, mathematically defined as:beginalignat*3\n    mathbfX̂_min - C_x̂_min ε  mathbfX̂  mathbfX̂_max + C_x̂_max ε \n    mathbfŴ_min - C_ŵ_min ε  mathbfŴ  mathbfŴ_max + C_ŵ_max ε \n    mathbfV̂_min - C_v̂_min ε  mathbfV̂  mathbfV̂_max + C_v̂_max ε\nendalignat*For this, use the same keyword arguments as above but with a first capital letter:X̂min / X̂max / C_x̂min / C_x̂max : mathbfX̂ constraints (nx̂*(He+1),).\nŴmin / Ŵmax / C_ŵmin / C_ŵmax : mathbfŴ constraints (nx̂*He,).\nV̂min / V̂max / C_v̂min / C_v̂max : mathbfV̂ constraints (nym*He,).\n\n\n\n\n\nsetconstraint!(mpc::PredictiveController; <keyword arguments>) -> mpc\n\nSet the bound constraint parameters of the PredictiveController mpc.\n\nThe predictive controllers support both soft and hard constraints, defined by:\n\nbeginalignat*3\n    mathbfu_min  - c_u_min  ϵ        mathbfu(k+j)  mathbfu_max  + c_u_max  ϵ qquad  j = 0 1  H_p - 1 \n    mathbfΔu_min - c_Δu_min ϵ       mathbfΔu(k+j)  mathbfΔu_max + c_Δu_max ϵ qquad  j = 0 1  H_c - 1 \n    mathbfy_min  - c_y_min  ϵ        mathbfŷ(k+j)  mathbfy_max  + c_y_max  ϵ qquad  j = 1 2  H_p     \n    mathbfx̂_min  - c_x̂_min  ϵ      mathbfx̂_i(k+j)  mathbfx̂_max  + c_x̂_max  ϵ qquad  j = H_p\nendalignat*\n\nand also ϵ  0. The last line is the terminal constraints applied on the states at the end of the horizon (see Extended Help). See MovingHorizonEstimator constraints for details on bounds and softness parameters mathbfc. The output and terminal  constraints are all soft by default. See Extended Help for time-varying constraints.\n\nArguments\n\ninfo: Info\nThe keyword arguments Δumin, Δumax, c_Δumin, c_Δumax, x̂min, x̂max, c_x̂min, c_x̂max and their capital letter versions have non-Unicode alternatives e.g.  Deltaumin, xhatmax and C_DeltauminThe default constraints are mentioned here for clarity but omitting a keyword argument  will not re-assign to its default value (defaults are set at construction only).\n\nmpc::PredictiveController : predictive controller to set constraints\numin=fill(-Inf,nu) / umax=fill(+Inf,nu) : manipulated input bound mathbfu_minmax\nΔumin=fill(-Inf,nu) / Δumax=fill(+Inf,nu) : manipulated input increment bound mathbfΔu_minmax\nymin=fill(-Inf,ny) / ymax=fill(+Inf,ny) : predicted output bound mathbfy_minmax\nx̂min=fill(-Inf,nx̂) / x̂max=fill(+Inf,nx̂) : terminal constraint bound mathbfx̂_minmax\nc_umin=fill(0.0,nu) / c_umax=fill(0.0,nu) : umin / umax softness weight mathbfc_u_minmax\nc_Δumin=fill(0.0,nu) / c_Δumax=fill(0.0,nu) : Δumin / Δumax softness weight mathbfc_Δu_minmax\nc_ymin=fill(1.0,ny) / c_ymax=fill(1.0,ny) : ymin / ymax softness weight mathbfc_y_minmax\nc_x̂min=fill(1.0,nx̂) / c_x̂max=fill(1.0,nx̂) : x̂min / x̂max softness weight mathbfc_x̂_minmax\nall the keyword arguments above but with a first capital letter, except for the terminal constraints, e.g. Ymax or C_Δumin: for time-varying constraints (see Extended Help)\n\nExamples\n\njulia> mpc = LinMPC(setop!(LinModel(tf(3, [30, 1]), 4), uop=[50], yop=[25]));\n\njulia> mpc = setconstraint!(mpc, umin=[0], umax=[100], Δumin=[-10], Δumax=[+10])\nLinMPC controller with a sample time Ts = 4.0 s:\n├ estimator: SteadyKalmanFilter\n├ model: LinModel\n├ optimizer: OSQP\n├ transcription: SingleShooting\n└ dimensions:\n  ├ 10 prediction steps Hp\n  ├  2 control steps Hc\n  ├  1 slack variable ϵ (control constraints)\n  ├  1 manipulated inputs u (0 integrating states)\n  ├  2 estimated states x̂\n  ├  1 measured outputs ym (1 integrating states)\n  ├  0 unmeasured outputs yu\n  └  0 measured disturbances d\n\nExtended Help\n\ndetails: Extended Help\nTerminal constraints provide closed-loop stability guarantees on the nominal plant model. They can render an unfeasible problem however. In practice, a sufficiently large prediction horizon H_p without terminal constraints is typically enough for  stability. If mpc.estim.direct==true, the estimator computes the states at i = k  (the current time step), otherwise at i = k - 1. Note that terminal constraints are applied on the augmented state vector mathbfx̂ (see SteadyKalmanFilter for details on augmentation).For variable constraints, the bounds can be modified after calling moveinput!, that is, at runtime, but not the softness parameters mathbfc. It is not possible to modify ±Inf bounds at runtime.tip: Tip\nTo keep a variable unconstrained while maintaining the ability to add a constraint later at runtime, set the bound to an absolute value sufficiently large when you create the controller (but different than ±Inf).It is also possible to specify time-varying constraints over H_p and H_c  horizons. In such a case, they are defined by:beginalignat*3\n    mathbfU_min  - C_u_min  ϵ  mathbfU   mathbfU_max  + C_u_max  ϵ \n    mathbfΔU_min - C_Δu_min ϵ  mathbfΔU  mathbfΔU_max + C_Δu_max ϵ \n    mathbfY_min  - C_y_min  ϵ  mathbfŶ   mathbfY_max  + C_y_max  ϵ\nendalignat*For this, use the same keyword arguments as above but with a first capital letter:Umin  / Umax  / C_umin  / C_umax  : mathbfU constraints (nu*Hp,).\nΔUmin / ΔUmax / C_Δumin / C_Δumax : mathbfΔU constraints (nu*Hc,).\nYmin  / Ymax  / C_ymin  / C_ymax  : mathbfŶ constraints (ny*Hp,).\n\n\n\n\n\n","category":"function"},{"location":"public/generic_func/#ModelPredictiveControl.evaloutput","page":"Generic Functions","title":"ModelPredictiveControl.evaloutput","text":"evaloutput(model::SimModel, d=[]) -> y\n\nEvaluate SimModel outputs y from model.x0 states and measured disturbances d.\n\nIt returns model output at the current time step mathbfy(k). Calling a  SimModel object calls this evaloutput method.\n\nExamples\n\njulia> model = setop!(LinModel(tf(2, [10, 1]), 5.0), yop=[20]);\n\njulia> y = evaloutput(model)\n1-element Vector{Float64}:\n 20.0\n\n\n\n\n\nevaloutput(estim::StateEstimator, d=[]) -> ŷ\n\nEvaluate StateEstimator outputs ŷ from estim.x̂0 states and disturbances d.\n\nIt returns estim output at the current time step mathbfŷ(k). If estim.direct is true, the method preparestate! should be called beforehand to correct the state estimate. \n\nCalling a StateEstimator object calls this evaloutput method.\n\nExamples\n\njulia> kf = SteadyKalmanFilter(setop!(LinModel(tf(2, [10, 1]), 5), yop=[20]), direct=false);\n\njulia> ŷ = evaloutput(kf)\n1-element Vector{Float64}:\n 20.0\n\n\n\n\n\n","category":"function"},{"location":"public/generic_func/#ModelPredictiveControl.preparestate!","page":"Generic Functions","title":"ModelPredictiveControl.preparestate!","text":"preparestate!(model::SimModel) -> x\n\nDo nothing for SimModel and return the current model state mathbfx(k). \n\n\n\n\n\npreparestate!(estim::StateEstimator, ym, d=[]) -> x̂\n\nPrepare estim.x̂0 estimate with meas. outputs ym and dist. d for the current time step.\n\nThis function should be called at the beginning of each discrete time step. Its behavior depends if estim is a StateEstimator in the current/filter (1.) or  delayed/predictor (2.) formulation:\n\nIf estim.direct is true, it removes the operating points with remove_op!, calls correct_estimate!, and returns the corrected state estimate  mathbfx̂_k(k).\nElse, it does nothing and returns the current best estimate mathbfx̂_k-1(k).\n\nExamples\n\njulia> estim2 = SteadyKalmanFilter(LinModel(ss(0.1, 0.5, 1, 0, 4)), nint_ym=0, direct=true);\n\njulia> x̂ = round.(preparestate!(estim2, [1]), digits=2)\n1-element Vector{Float64}:\n 0.5\n\njulia> estim1 = SteadyKalmanFilter(LinModel(ss(0.1, 0.5, 1, 0, 4)), nint_ym=0, direct=false);\n\njulia> x̂ = preparestate!(estim1, [1])\n1-element Vector{Float64}:\n 0.0\n\n\n\n\n\npreparestate!(mpc::PredictiveController, ym, d=[]) -> x̂\n\nCall preparestate! on mpc.estim StateEstimator.\n\n\n\n\n\n","category":"function"},{"location":"public/generic_func/#ModelPredictiveControl.updatestate!","page":"Generic Functions","title":"ModelPredictiveControl.updatestate!","text":"updatestate!(model::SimModel, u, d=[]) -> xnext\n\nUpdate model.x0 states with current inputs u and meas. dist. d for the next time step.\n\nThe method computes and returns the model state for the next time step mathbfx(k+1).\n\nExamples\n\njulia> model = LinModel(ss(1.0, 1.0, 1.0, 0, 1.0));\n\njulia> x = updatestate!(model, [1])\n1-element Vector{Float64}:\n 1.0\n\n\n\n\n\nupdatestate!(estim::StateEstimator, u, ym, d=[]) -> x̂next\n\nUpdate estim.x̂0 estimate with current inputs u, measured outputs ym and dist. d. \n\nThis function should be called at the end of each discrete time step. It removes the  operating points with remove_op!, calls update_estimate! and returns the state estimate for the next time step mathbfx̂_k(k+1). The method preparestate! should be called prior to this one to correct the estimate when applicable (if estim.direct == true). Note that the MovingHorizonEstimator with the default direct=true option is not able to estimate mathbfx̂_k(k+1), the returned value is therefore the current corrected state mathbfx̂_k(k).\n\nExamples\n\njulia> kf = SteadyKalmanFilter(LinModel(ss(0.1, 0.5, 1, 0, 4.0))); u = [1]; ym = [0];\n\njulia> preparestate!(kf, ym);\n\njulia> x̂ = updatestate!(kf, u, ym) # x̂[2] is the integrator state (nint_ym argument)\n2-element Vector{Float64}:\n 0.5\n 0.0\n\n\n\n\n\nupdatestate!(mpc::PredictiveController, u, ym, d=[]) -> x̂next\n\nCall updatestate! on mpc.estim StateEstimator.\n\n\n\n\n\n","category":"function"},{"location":"public/generic_func/#ModelPredictiveControl.initstate!","page":"Generic Functions","title":"ModelPredictiveControl.initstate!","text":"initstate!(model::SimModel, u, d=[]) -> x\n\nInit model.x0 with manipulated inputs u and meas. dist. d steady-state.\n\nThe method tries to initialize the model state mathbfx at steady-state. It removes the operating points on u and d and calls steadystate!:\n\nIf model is a LinModel, the method computes the steady-state of current inputs u and measured disturbances d.\nElse, model.x0 is left unchanged. Use setstate! to manually modify it.\n\nExamples\n\njulia> model = LinModel(tf(6, [10, 1]), 2.0);\n\njulia> u = [1]; x = initstate!(model, u); y = round.(evaloutput(model), digits=3)\n1-element Vector{Float64}:\n 6.0\n \njulia> x ≈ updatestate!(model, u)\ntrue\n\n\n\n\n\ninitstate!(estim::StateEstimator, u, ym, d=[]) -> x̂\n\nInit estim.x̂0 states from current inputs u, measured outputs ym and disturbances d.\n\nThe method tries to find a good steady-state for the initial estimate mathbfx̂. It removes the operating points with remove_op! and call init_estimate!:\n\nIf estim.model is a LinModel, it finds the steady-state of the augmented model using u and d arguments, and uses the ym argument to enforce that  mathbfŷ^m(0) = mathbfy^m(0). For control applications, this solution produces a bumpless manual to automatic transfer. See init_estimate! for details.\nElse, estim.x̂0 is left unchanged. Use setstate! to manually modify it.\n\nIf applicable, it also sets the error covariance estim.cov.P̂ to estim.cov.P̂_0.\n\nExamples\n\njulia> estim = SteadyKalmanFilter(LinModel(tf(3, [10, 1]), 0.5), nint_ym=[2], direct=false);\n\njulia> u = [1]; y = [3 - 0.1]; x̂ = round.(initstate!(estim, u, y), digits=3)\n3-element Vector{Float64}:\n 10.0\n  0.0\n -0.1\n\njulia> x̂ ≈ updatestate!(estim, u, y)\ntrue\n\njulia> evaloutput(estim) ≈ y\ntrue\n\n\n\n\n\ninitstate!(mpc::PredictiveController, u, ym, d=[]) -> x̂\n\nInit the states of mpc.estim StateEstimator and warm start mpc.Z̃ at zero.\n\nIt also stores u - mpc.estim.model.uop at mpc.lastu0 for converting the input increments mathbfΔU to inputs mathbfU.\n\n\n\n\n\n","category":"function"},{"location":"public/generic_func/#ModelPredictiveControl.setstate!","page":"Generic Functions","title":"ModelPredictiveControl.setstate!","text":"setstate!(model::SimModel, x) -> model\n\nSet model.x0 to x - model.xop from the argument x. \n\n\n\n\n\nsetstate!(estim::StateEstimator, x̂[, P̂]) -> estim\n\nSet estim.x̂0 to x̂ - estim.x̂op from the argument x̂, and estim.cov.P̂ to P̂ if applicable. \n\nThe covariance error estimate P̂ can be set only if estim is a StateEstimator that computes it.\n\n\n\n\n\nsetstate!(mpc::PredictiveController, x̂[, P̂]) -> mpc\n\nCall setstate! on mpc.estim StateEstimator.\n\n\n\n\n\n","category":"function"},{"location":"public/generic_func/#ModelPredictiveControl.setmodel!","page":"Generic Functions","title":"ModelPredictiveControl.setmodel!","text":"setmodel!(estim::StateEstimator, model=estim.model; <keyword arguments>) -> estim\n\nSet model and covariance matrices of estim StateEstimator.\n\nAllows model adaptation of estimators based on LinModel at runtime. Modification  of NonLinModel state-space functions is not supported. New covariance matrices can be specified with the keyword arguments (see SteadyKalmanFilter documentation for the nomenclature). Not supported by Luenberger and SteadyKalmanFilter,  use the time-varying KalmanFilter instead. The MovingHorizonEstimator model is kept constant over the estimation horizon H_e. The matrix dimensions and sample time must stay the same. Note that the observability and controllability of the new augmented model is not verified (see Extended Help for more info).\n\nArguments\n\ninfo: Info\nKeyword arguments with emphasis are non-Unicode alternatives.\n\nestim::StateEstimator : estimator to set model and covariances.\nmodel=estim.model : new plant model (not supported by NonLinModel).\nQ̂=nothing or Qhat : new augmented model mathbfQ̂ covariance matrix.\nR̂=nothing or Rhat : new augmented model mathbfR̂ covariance matrix.\n\nExamples\n\njulia> kf = KalmanFilter(LinModel(ss(0.1, 0.5, 1, 0, 4.0)), σQ=[√4.0], σQint_ym=[√0.25]);\n\njulia> kf.model.A[], kf.cov.Q̂[1, 1], kf.cov.Q̂[2, 2] \n(0.1, 4.0, 0.25)\n\njulia> setmodel!(kf, LinModel(ss(0.42, 0.5, 1, 0, 4.0)), Q̂=[1 0;0 0.5]);\n\njulia> kf.model.A[], kf.cov.Q̂[1, 1], kf.cov.Q̂[2, 2] \n(0.42, 1.0, 0.5)\n\nExtended Help\n\ndetails: Extended Help\nUsing the default model augmentation computed by the default_nint method,  switching from a non-integrating plant model to an integrating one will produce an augmented model that is not observable. Moving the unmeasured disturbances at the  model input (nint_u parameter) can fix this issue.\n\n\n\n\n\nsetmodel!(mpc::PredictiveController, model=mpc.estim.model; <keyword arguments>) -> mpc\n\nSet model and objective function weights of mpc PredictiveController.\n\nAllows model adaptation of controllers based on LinModel at runtime. Modification of NonLinModel state-space functions is not supported. New weight matrices in the objective function can be specified with the keyword arguments (see LinMPC for the nomenclature). If Cwt ≠ Inf, the augmented move suppression weight is mathbfÑ_H_c = mathrmdiag(mathbfN_H_c C), else mathbfÑ_H_c = mathbfN_H_c. The StateEstimator mpc.estim cannot be a Luenberger observer or a SteadyKalmanFilter (the default estimator). Construct the mpc object with a time-varying KalmanFilter instead. Note that the model is constant over the prediction horizon H_p.\n\nArguments\n\ninfo: Info\nKeyword arguments with emphasis are non-Unicode alternatives.\n\nmpc::PredictiveController : controller to set model and weights.\nmodel=mpc.estim.model : new plant model (not supported by NonLinModel).\nMwt=nothing : new main diagonal in mathbfM weight matrix (vector).\nNwt=nothing : new main diagonal in mathbfN weight matrix (vector).\nLwt=nothing : new main diagonal in mathbfL weight matrix (vector).\nM_Hp=nothing : new mathbfM_H_p weight matrix.\nÑ_Hc=nothing or Ntilde_Hc : new mathbfÑ_H_c weight matrix (see def. above).\nL_Hp=nothing : new mathbfL_H_p weight matrix.\nadditional keyword arguments are passed to setmodel!(mpc.estim).\n\nExamples\n\njulia> mpc = LinMPC(KalmanFilter(LinModel(ss(0.1, 0.5, 1, 0, 4.0)), σR=[√25]), Hp=1, Hc=1);\n\njulia> mpc.estim.model.A[1], mpc.estim.cov.R̂[1], mpc.weights.M_Hp[1], mpc.weights.Ñ_Hc[1]\n(0.1, 25.0, 1.0, 0.1)\n\njulia> setmodel!(mpc, LinModel(ss(0.42, 0.5, 1, 0, 4.0)); R̂=[9], M_Hp=[10], Nwt=[0.666]);\n\njulia> mpc.estim.model.A[1], mpc.estim.cov.R̂[1], mpc.weights.M_Hp[1], mpc.weights.Ñ_Hc[1]\n(0.42, 9.0, 10.0, 0.666)\n\n\n\n\n\n","category":"function"},{"location":"public/generic_func/#ModelPredictiveControl.getinfo","page":"Generic Functions","title":"ModelPredictiveControl.getinfo","text":"getinfo(estim::MovingHorizonEstimator) -> info\n\nGet additional info on estim MovingHorizonEstimator optimum for troubleshooting.\n\nIf estim.direct==true, the function should be called after calling preparestate!. Otherwise, call it after updatestate!. It returns the dictionary info with the following fields:\n\ninfo: Info\nFields with emphasis are non-Unicode alternatives.\n\n:Ŵ or :What : optimal estimated process noise over N_k, mathbfŴ\n:ε or :epsilon : optimal slack variable, ε\n:X̂ or :Xhat : optimal estimated states over N_k+1, mathbfX̂\n:x̂ or :xhat : optimal estimated state, mathbfx̂_k(k+p)\n:V̂ or :Vhat : optimal estimated sensor noise over N_k, mathbfV̂\n:P̄ or :Pbar : estimation error covariance at arrival, mathbfP̄\n:x̄ or :xbar : optimal estimation error at arrival, mathbfx̄\n:Ŷ or :Yhat : optimal estimated outputs over N_k, mathbfŶ\n:Ŷm or :Yhatm : optimal estimated measured outputs over N_k, mathbfŶ^m\n:x̂arr or :xhatarr : optimal estimated state at arrival, mathbfx̂_k(k-N_k+p)\n:J   : objective value optimum, J\n:Ym  : measured outputs over N_k, mathbfY^m\n:U   : manipulated inputs over N_k, mathbfU\n:D   : measured disturbances over N_k, mathbfD\n:sol : solution summary of the optimizer for printing\n\nExamples\n\njulia> model = LinModel(ss(1.0, 1.0, 1.0, 0, 5.0));\n\njulia> estim = MovingHorizonEstimator(model, He=1, nint_ym=0, direct=false);\n\njulia> updatestate!(estim, [0], [1]);\n\njulia> round.(getinfo(estim)[:Ŷ], digits=3)\n1-element Vector{Float64}:\n 0.5\n\n\n\n\n\ngetinfo(mpc::PredictiveController) -> info\n\nGet additional info about mpc PredictiveController optimum for troubleshooting.\n\nThe function should be called after calling moveinput!. It returns the dictionary info with the following fields:\n\ninfo: Info\nFields with emphasis are non-Unicode alternatives.\n\n:ΔU or :DeltaU : optimal manipulated input increments over H_c, mathbfΔU\n:ϵ or :epsilon : optimal slack variable, ϵ\n:D̂ or :Dhat : predicted measured disturbances over H_p, mathbfD̂\n:ŷ or :yhat : current estimated output, mathbfŷ(k)\n:Ŷ or :Yhat : optimal predicted outputs over H_p, mathbfŶ\n:Ŷs or :Yhats : predicted stochastic output over H_p of InternalModel, mathbfŶ_s\n:R̂y or :Rhaty : predicted output setpoint over H_p, mathbfR̂_y\n:R̂u or :Rhatu : predicted manipulated input setpoint over H_p, mathbfR̂_u\n:x̂end or :xhatend : optimal terminal states, mathbfx̂_i(k+H_p)\n:J   : objective value optimum, J\n:U   : optimal manipulated inputs over H_p, mathbfU\n:u   : current optimal manipulated input, mathbfu(k)\n:d   : current measured disturbance, mathbfd(k)\n\nFor LinMPC and NonLinMPC, the field :sol also contains the optimizer solution summary that can be printed. Lastly, the economical cost :JE and the custom nonlinear constraints :gc values at the optimum are also available for NonLinMPC.\n\nExamples\n\njulia> mpc = LinMPC(LinModel(tf(5, [2, 1]), 3), Nwt=[0], Hp=1, Hc=1);\n\njulia> preparestate!(mpc, [0]); u = moveinput!(mpc, [10]);\n\njulia> round.(getinfo(mpc)[:Ŷ], digits=3)\n1-element Vector{Float64}:\n 10.0\n\n\n\n\n\n","category":"function"},{"location":"public/generic_func/#ModelPredictiveControl.savetime!","page":"Generic Functions","title":"ModelPredictiveControl.savetime!","text":"savetime!(model::SimModel) -> t\n\nSet model.t to time()  and return the value.\n\nUsed in conjunction with periodsleep for simple soft real-time simulations. Call this function before any other in the simulation loop.\n\n\n\n\n\nsavetime!(estim::StateEstimator) -> t\n\nCall savetime!(estim.model) and return the time t.\n\n\n\n\n\nsavetime!(mpc::PredictiveController) -> t\n\nCall savetime!(mpc.estim.model) and return the time t.\n\n\n\n\n\n","category":"function"},{"location":"public/generic_func/#ModelPredictiveControl.periodsleep","page":"Generic Functions","title":"ModelPredictiveControl.periodsleep","text":"periodsleep(model::SimModel, busywait=false) -> nothing\n\nSleep for model.Ts s minus the time elapsed since the last call to savetime!.\n\nIt calls sleep if busywait is false. Else, a simple  while loop implements busy-waiting. As a rule-of-thumb, busy-waiting should be used if  model.Ts < 0.1 s, since the accuracy of sleep is around 1 ms. Can be used to implement simple soft real-time simulations, see the example below.\n\nwarning: Warning\nThe allocations in Julia are garbage-collected (GC) automatically. This can affect the  timing. In such cases, you can temporarily stop the GC with GC.enable(false), and restart it at a convenient time e.g.: just before calling periodsleep.\n\nExamples\n\njulia> model = LinModel(tf(2, [0.3, 1]), 0.25);\n\njulia> function sim_realtime!(model)\n           t_0 = time()\n           for i=1:3\n               t = savetime!(model)      # first function called\n               println(round(t - t_0, digits=3))\n               updatestate!(model, [1])\n               periodsleep(model, true)  # last function called\n           end\n       end;\n\njulia> sim_realtime!(model)\n0.0\n0.25\n0.5\n\n\n\n\n\nperiodsleep(estim::StateEstimator, busywait=false) -> nothing\n\nCall periodsleep(estim.model).\n\n\n\n\n\nperiodsleep(mpc::PredictiveController, busywait=false) -> nothing\n\nCall periodsleep(mpc.estim.model).\n\n\n\n\n\n","category":"function"},{"location":"#ModelPredictiveControl.jl","page":"Home","title":"ModelPredictiveControl.jl","text":"An open source model predictive control package for Julia.\n\nThe package depends on ControlSystemsBase.jl for the linear systems, JuMP.jl for the optimization and DifferentiationInterface.jl for the derivatives.\n\nThe objective is to provide a simple, clear and modular framework to quickly design model predictive controllers (MPCs) in Julia, while preserving the flexibility for advanced real-time optimization. Modern MPCs based on closed-loop state estimators are the main focus of the package, but classical approaches that rely on internal models are also possible. The JuMP and DifferentiationInterface dependencies allows the user to test different optimizers and automatic differentiation (AD) backends easily if the performances of the default settings are not satisfactory.\n\nThe documentation is divided in two parts:\n\nManual — This section includes step-by-step guides to design predictive controllers on multiple case studies.\nFunctions — Documentation of methods and types exported by the package. The \"Internals\" section provides implementation details of functions that are not exported.","category":"section"},{"location":"#Manual","page":"Home","title":"Manual","text":"Depth = 2\nPages = [\n    \"manual/installation.md\",\n    \"manual/linmpc.md\",\n    \"manual/nonlinmpc.md\",\n    \"manual/mtk.md\"\n]","category":"section"},{"location":"#Functions:-Public","page":"Home","title":"Functions: Public","text":"Depth = 2\nPages = [\n    \"public/sim_model.md\",\n    \"public/state_estim.md\",\n    \"public/predictive_control.md\",\n    \"public/generic_func.md\",\n    \"public/plot_sim.md\",\n]","category":"section"},{"location":"#Functions:-Internals","page":"Home","title":"Functions: Internals","text":"Depth = 1\nPages = [\n    \"internals/sim_model.md\",\n    \"internals/state_estim.md\",\n    \"internals/predictive_control.md\",\n]","category":"section"},{"location":"internals/sim_model/#Functions:-SimModel-Internals","page":"Plant Models","title":"Functions: SimModel Internals","text":"Pages = [\"sim_model.md\"]","category":"section"},{"location":"internals/sim_model/#State-Space-Functions","page":"Plant Models","title":"State-Space Functions","text":"","category":"section"},{"location":"internals/sim_model/#Steady-State-Calculation","page":"Plant Models","title":"Steady-State Calculation","text":"","category":"section"},{"location":"internals/sim_model/#ModelPredictiveControl.f!","page":"Plant Models","title":"ModelPredictiveControl.f!","text":"f!(x0next, _ , model::LinModel, x0, u0, d0, _ ) -> nothing\n\nEvaluate x0next = A*x0 + Bu*u0 + Bd*d0 in-place when model is a LinModel.\n\n\n\n\n\nf!(x0next, k0, model::NonLinModel, x0, u0, d0, p)\n\nCompute x0next using the DiffSolver in model.solver and model.f!.\n\nThe method mutates x0next and k0 arguments in-place. The latter is used to store the intermediate stage values of the solver.\n\n\n\n\n\n","category":"function"},{"location":"internals/sim_model/#ModelPredictiveControl.h!","page":"Plant Models","title":"ModelPredictiveControl.h!","text":"h!(y0, model::LinModel, x0, d0, _ ) -> nothing\n\nEvaluate y0 = C*x0 + Dd*d0 in-place when model is a LinModel.\n\n\n\n\n\nh!(y0, model::NonLinModel, x0, d0, p)\n\nCompute y0 by calling model.h! directly for NonLinModel.\n\n\n\n\n\n","category":"function"},{"location":"internals/sim_model/#ModelPredictiveControl.steadystate!","page":"Plant Models","title":"ModelPredictiveControl.steadystate!","text":"steadystate!(model::LinModel, u0, d0)\n\nSet model.x0 to u0 and d0 steady-state if model is a LinModel.\n\nFollowing setop! notation, the method evaluates the equilibrium from:\n\n    mathbfx_0 = mathbf(I - A)^-1(B_u u_0 + B_d d_0 + f_op - x_op)\n\nwith constant manipulated inputs mathbfu_0 = u - u_op and measured disturbances mathbfd_0 = d - d_op. The Moore-Penrose pseudo-inverse computes  mathbf(I - A)^-1 to support integrating model (integrator states will be 0).\n\n\n\n\n\nDo nothing if model is a NonLinModel.\n\n\n\n\n\n","category":"function"}]
}
